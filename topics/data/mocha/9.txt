['ah ok its the && between cross-env and mocha command. this will make both commands run in different environments. if you remove the && and put the env value into single quotes it works for me"cross-env ts_node_compiler_options=\'{\\"module\\":\\"commonjs\\"}\' mocha --recursive --bail --opts config/mocha.opts"one test fails', "fix eperm exception that can occur when cleaning up temporary files. i get the following error when running tests for `electron-mocha` and when running tests with coverage for my own project.```{ error: eperm: operation not permitted. unlink 'c:\\users\\micros~1\\appdata\\local\\temp\\electron-mocha-aw5ldg\\gpucache\\data_0'    at object.fs.unlinksync (fs.js:1091:18)    at fixwinepermsync (s:\\projects\\_github\\electron-mocha\\node_modules\\fs-extra\\lib\\remove\\rimraf.js:169:13)    at rimrafsync (s:\\projects\\_github\\electron-mocha\\node_modules\\fs-extra\\lib\\remove\\rimraf.js:260:26)    at options.readdirsync.foreach.f (s:\\projects\\_github\\electron-mocha\\node_modules\\fs-extra\\lib\\remove\\rimraf.js:291:39)    at array.foreach (native)    at rmkidssync (s:\\projects\\_github\\electron-mocha\\node_modules\\fs-extra\\lib\\remove\\rimraf.js:291:26)    at rmdirsync (s:\\projects\\_github\\electron-mocha\\node_modules\\fs-extra\\lib\\remove\\rimraf.js:283:7)    at fixwinepermsync (s:\\projects\\_github\\electron-mocha\\node_modules\\fs-extra\\lib\\remove\\rimraf.js:167:5)    at rimrafsync (s:\\projects\\_github\\electron-mocha\\node_modules\\fs-extra\\lib\\remove\\rimraf.js:260:26)    at options.readdirsync.foreach.f (s:\\projects\\_github\\electron-mocha\\node_modules\\fs-extra\\lib\\remove\\rimraf.js:291:39)  errno: -4048.  code: 'eperm'.  syscall: 'unlink'.  path: 'c:\\\\users\\\\micros~1\\\\appdata\\\\local\\\\temp\\\\electron-mocha-aw5ldg\\\\gpucache\\\\data_0' }```this causes `electron-mocha` to fail to clean up temporary files. changing cleanup to happen on `exit` instead of `quit` fixes it. i'm not sure if there's any other implications from doing this.", "i don't think `app` emits an `exit` event at all: are you sure any clean-up happens when you make this change?we've repeatedly seen permission errors during clean-up. especially on windows: usually this happens if your tests have not released a resource properly. most common case is if you create windows (other than the one electron-mocha creates for `--renderer` tests) and don't close them again.there is. however. an issue with electron's `net` module at the moment (which holds references to cache files) -- because of this (and because this gets reported frequently) we could consider allowing to skip clean-up completely?", "ahh. you're right. i don't know why i thought there was an `exit` event. is there a way to discover what's holding on to a resource? i would think reporting that would be better than skipping.", "seems to be an issue with power shell. it works using git bash except the following error:```uncaughtexception:error: eperm: operation not permitted. unlink'c:\\users\\xxx\\appdata\\local\\temp\\electron-mocha-xyz\\gpucache\\data_0...at fixwinepermsync```//edit: checked the file - there's nothing special about it - was able to `rm` it in the console.", "about your first problem: if `require('electron')` yields the path to electron this means that you're likely not using electron's `require` and loading the `electron` module instead of the electron api. this shouldn't happen in electron-mocha unless you're using some kind of pre-processor to bundle your tests?about the second issue: normally. if the temp folder can't be removed (especially on windows) it means that some of your tests opened resources and did not release them again. in this case it's likely a window -- if any of your tests open windows you need to make sure to close them again otherwise the temp folder can't be cleared.", '> ```>   1) frontendcommandhandler defers "scriptparsed" events until "page.getresourcetree":>      error: timeout of 2000ms exceeded>       at null.<anonymous> (c:\\development\\nodist\\bin\\node_modules\\node-inspector\\node_modules\\mocha\\lib\\runnable.js:139:19)1>       at timer.listontimeout [as ontimeout] (timers.js:110:15)> ```a common reason for node inspector ui not showing up is when there are many files in the project being debugged. as the inspector backend is crawling the file system to list all files where you might want to set a breakpoint even before they are loaded.try to run node-inspector with `--no-preload` option. does it make any difference?however: since the problem seems to be in the websocket connection. `--no-preload` probably won\'t help here. do you have any plugins and or system services (antivirus. firewall) that could be intercepting websocket connections?', 'you can see [this]( tutorial. where in last part miroslav show how to debug `mocha` tests. i think it will be helpful in debugging gulp.send me result.', 'closing since our tests started to incorporate such toolings.', "renamed this to reflect that we should switch away from mocha (for a number of reasons: not working in browsers we need to shim is a big one. plus. not working in testling). and then once we're using tape. use testling-ci/browserify to do automatic browser testing.", 'mocha supports tape', 'sorry. not tape but tap -- test anything protocol. testling-ci / browserify should work great with it', "that's true - but it also requires es5 features. which makes it inappropriate to use in a library that targets es3 browsers as well.", 'question: do we actually want to support es3 browsers? their market share is like super low', "fwiw i'm happy to do the work to convert the tests :-) i've already got a branch in-progress with more than half of them converted anyways. it's not much of a burden to keep the support threshold super low. so we might as well. bdd-style test libs don't add much value imo anyways :-)", "i personally love bdd. it's very easy to read code. cscott ?", "update mocha/should dependencies.. tested that latest releases of mocha and should do not cause any problems with domino's test suite.", "i'm not a fan of grunt. but you don't really need make to hack on express either. just mocha", 'so you would have done "unit": "_mocha" instead?', "i'm using mocha and the test just throws an error. i can set up a simpler test to try and catch the error though i'm pretty sure its due to the fact that loginstub has no associations. queries on user that include loginstub work find.before i spend more time i wanted to verify the behavior of include. is it true that a single `user.hasmany(loginstub);` call will enable the `include` statement for both the `user` and `loginstub` models? e.g.``` jsloginstub.find({   include: [user].   where: { my_key: 'a_key' }}).complete(function(err. stub) { ...});```and``` jsuser.find({   include: [loginstub].   where: { my_key: 'a_key' }}).complete(function(err. user) { ...});```currently only the second one is working for me.", 'sonvert some tests to mocha. megawac. take a look at it.', 'heck yeah! thanks ezubarev!ping #849', 'cool. amazing!', "> another thing. i just noticed ava doesn't support browsers -- only jsdom.yes. but it runs on the tape protocol which works in the browser", 'convert the rest of tests to mocha. the remaining tests were ported. nodeunit was completely removed. have a look. resolves #849 megawac. aearly', "megawac. i replaced assert with expect in tests on asyncify. in other cases as i can see it's usage will not lead to less transparency in debugging. however i don't mind if anyone wants to make use of `chai.expect` somewhere else.", "i'm sure any confusing remaining ones will be fixes post merge. thanks a bunch ezubarev", "you're welcome.", "fix silently swallowed exceptions. when something goes wrong and neither a test suite nor a finishcallback are given.the processlistener in run.js swallows the error. this happens when you are usingmocha as a test runner and have a syntax error or throw an exception outside ofthe test suite (e.g. `require('./some-spec-helper')` while the file does not exist)", "> there are some es6 features we could take advantage of to make the code cleaner -- particularly arrow functionswhile i do agree upon this statement. it's worth noting that there are very minor side effects. for example. using arrow functions in mocha tests is discouraged (source:", 'moved back mocha to `dependencies` as suggested by kennethormandy which seems to have got lost in a rebase', "i think we'd still need to test the middleware using mocha but we can certainly use sass-spec for testing that we're correctly piping everything into libsass.", "use a mocha reporter that doesn't blank the screen. currently the build step uses the `min` reporter which blanks the screen which is unexpected and confusing.this switches to the `dot` reporter which prints a single dot for each test and does not blank the screen.", 'oh cool. thanks!', 'no luck. please close it :(', "hi. seems reasonable but wouldn't help if the asynchronous part of the test threw an error. i've also never seen this cause timeouts - i usually run my tests via mocha and the exception is handled for me. how are you running your tests?", 'apologies as i realized this should be reported at tapjs/tap-mocha-reporter#43', 'how to make unit test easier to integrate in a project ?. i really love sails and use it in a lot of project now.i just think it is quite painful when it comes to add some tests as gruntfile.js needs to be modified at several places to integrate mocha.could a mocha environment be integrated during project creation ?', 'thanks t3chnoboy; closing this in favor of the issue you linked to.', 'ease the usage of additional modules in the gruntfile. each time i use sails in a project. i need to modify the grunt file to add some lint / mocha / ... tasks for testing purposes. this setup is quite painful as it impacts several part of the gruntfile. is there an easier way such as the possibility to import some custom functionalities in the gruntfile ? my concern is more with the future updates of sails that could possibly modify the gruntfile.', 'thanks. that is a nice tip.', "hey kostyatretyak.thank you for opening this issue. from my understanding it looks like you found this wasn't a bug in either the restify-plugin or mocha repos.i'm going to close this for now as resolved. if i'm misunderstanding. please comment and i would be happy to re-open and discuss :heart:", 'the gmail account configuration should "**allow less secure apps: on**". then i got the mail in my gmailbut i still get the error:`error: timeout of 2000ms exceeded. for async tests and hooks. ensure "done()" is called; if returning a promise. ensure it resolves.`when testing the service with `mocha.js`', 'elichai a mocha test in the `test` directory. so that the functionality can be added to the test coverage. you can see the `pool` tests to see how to fake a message from a peer. the `addr` messages for example.', "added babel-core/register to mocha for es6 on server side unit tests. added this line so that we can use es6 on server side unit tests. tested in my local project that had this installed. babel-core is a requirement. and is listed in this electrode-archetype-react-app-dev's package.json.", 'btw: on the pr. all the tests passed on my local machine running `mocha`. so i was surprised to see it fail on travis ci.', "xunit reporter captures all tests output. i'm using the following grunt task:``` mochatest: {              test: {                options: {                  reporter: 'xunit'.                  capturefile: 'tmp/xunit-mochatest.xml'.                }.                src: ['test/**/*.js'].              }         }```so i'm trying to get xunit report. unfortunately. in this case all the output from the running tests (so also console.log) is written to the file specified in the capturefile option. i believe that there should be dist option added which would allow for capturing only the xunit reporter output.", "the capturefile option captures all the output on stdout - it would be impossible for the plugin to tell the difference between xunit output and other output. you would need to use a different reporter that captures it's own output if you need to mix in other output. personally i never have my tests output to console unless i'm debugging (which i then don't commit). note that stderr is not captured so deprecation warnings and such from node and other libraries do not get captured. you could potentially log your output to stderr if that's appropriate.i think there are mocha reporters available that output to files too. eg. mocha-jenkins-reporter", 'as a side note. if you are testing code that logs to the console then you may find it useful to inject a log function which in production would be console.log but in your tests is a spy function or something. i often use the sinon package for this kind of thing.', "hopefully this is enough to get you going - another trick. when you can't insert a log function. is to run the tests in a child process and capture the output to verify but this opens a whole load of other problems and i only do this for end to end integration tests (i'm also working on a generalized solution for this to capture coverage data from the child process)", "since this isn't closed. and because the name exactly matches what _i_ want. i'll (ab)use this thread: please passthrough the `slow` config option to mocha.", "when mocha-test part of task sequence . tasks after mocha-test were not executed . hello i have following question : i defined some alias grunt task  as following : grunt.registertask('new_task'. ['mocha-test'. 'other_task']);when i execute this new defined task with command line grunt new_task . only mocha-test task executed . other_task were not startedin the case when i define reverse order as following grunt.registertask('new_reverse_task'. ['other_task'.'mocha-test']); both tasks executedwhat can cause to the issue ? how can be caused to that both of tasks in the first case new_task will be executed ? your help will be valuable . thanks in advance", 'this would happen if the tests failed. can you post the output you get?', 'also it should be `mochatest` unless you also aliased that', 'hmm. you should get something like this at the end```done. without errors.```which signifies grunt exited cleanly.from your output it looks like the grunt process exited early for some reason. do you see the above when you reverse the order of the grunt tasks?my best guess is that there is something happening asynchronously to your tests that crashes the node process after the tests have completed.', "have you tried the slow option? as far as i can see this should already work as the mocha constructor already has this line:```  if (options.slow) this.slow(options.slow);``` and any options specified for `mochatest` are already passed to the mocha constructor. so assuming you don't set it to zero it should already work.", 'ugh. sorry. new to mocha. i just realized this seems to be a side-effect of logging in the testing environment.', "mshick  i'm having the same problem with mocha. what is the recommended fix / workaround? i don't seem to be able to use `expect(obj).to.eql(model)`. since it's showing the boolean as {}", 'ping. is it still not released? =^_^=', "fix mocha adapter not reporting all test results. i'm using testem with mocha. and noticed that sometimes `testem ci` outputs a report with lack of some test results. (ex. although the spec has 100 tests. testem's report only contains 90 results)this is because. by commit 6c890dc. reporting test result is delayed by `settimeout` asynchronously. which may cause inconsistent order of event emitting. such as `test-result` event after `all-test-results` event.this pr fixes the inconsistency and always emitting `all-test-results` event after all of `test-result` events have been fired. so that reporters can finalize their report properly.", 'airportyh how does it look? love to see your comment! :kissing_smiling_eyes:', 'kotas thanks! i am quite busy at the moment. will get to this next week.', 'thank you for your response. and oh. sorry for bothering you. never mind and keep going! :satisfied:', "i'm compiling directly in sass. since mocha trusts the sass results. it would be very strange if gulp/mocha explains the error. can you paste your relevant gulp setup. for me to try it locally here?", "yep. you can do:``` jsvar mocha = require('mocha');var mocha = new mocha();mocha.addfile('test.js');function runmocha(callback) {  mocha.run(function () {    callback();  });}runmocha(function () {  runmocha(function () {});});```", "yes it works for this simple example. but what if i don't have control over when mocha is instantiated (i.e. when using a grunt plugin) or i only want to execute a subset of the tests?btw: in your example i would expect the tests in 'test.js' to run twice on the second run. since i called addfile twice (and it will be contained twice in this.files in mocha.)", 'cool. wrong spot for the change tho. mocha.js is compiled from the real src files.', "if you use make you could just do `make -j 8 test` and glob files in different test dirs if you have some seperated out in dirs or just pass different file names. mocha itself doesn't have to do this.", 'alrighty - code attached. :smile: i wasn\'t super sure the best place to put the tests. so i made an acceptance test for them.  from what i could tell that\'s where the trickier "uhh. you kinda have to run the actual command to test this" tests go.one nice thing about this is if you use the `--bail` flag mocha will still exit after the first failure regardless of the event-loop being alive or not.please let me know if you\'d like me to modify or change this at all & i\'ll do so asap!', "wrong async tests with disabled timeout. let's consider the following test:```var assert = require('assert');describe('suite'. function () {  it('should be unfinished'. function (done) {  });  it('should be passed'. function () {    assert.equal(1. 1);  });});```test `should be unfinished` is wrong. because `done` callback  isn't called.running the test with `mocha --timeout 0 test/` outputs nothing.expected behavior: `should be unfinished` should be reported as failed and `should be passed` as passed.", 'that\'s great! i had been looking for this. for example to add a "table-of-contents" toggle switch to the markdown reporter.', 'tutorial?. does anyone know of any places where video tutorials about how to go about testing with mocha could be found?better yet. is there a tutorial about integrating mocha with node + grunt.js?', "(i know this isn't an issue with mocha itself. but i don't know where else to ask because i don't know anyone that uses mocha).", 'you dont really need grunt involved at all. just do `mocha test/*.js` etc (or just `mocha` which assumes the former)', "i just use grunt so i don't have to switch back and forth from code to terminal thereby saving screen real estate by using grunt to push results via growl notifications.> on nov 7. 2013. at 6:42 pm. tj holowaychuk notificationsgithub.com wrote:> > you dont really need grunt involved at all. just do mocha test/*.js etc> > --> reply to this email directly or view it on github.", 'work outstanding is actually replying to pull requests. or move on. a year already. time flies innit.', 'cool geekdave. closing this', "there's `mocha --watch` for that as well. the grunt stuff probably just calls that", "meh :p easy to delegate that and just do``` jsit('should work'. function(done){  co(function *(){    yield whatever;  })(done)})```similar to the promise argument. i think leaving mocha at the simplest level with regular old callbacks is the best way to go", "exclude console.log when '-r xunit' is used. because some of the codes under test use console.log for printing out message for runtime information.but i need the output file for integratin with jenkins. is there any possible ways that i can do it while `mocha r xunit > test-result.xml` if it's not possible. how about the alternative like `mocha -r tap`?thanks.", 'naturally you can pipe the results. but you want to only pipe your own logs?', 'i do not want the console.log from other developers shown up in the xml.i have tried something like `mocha -r xunit | grep  \'^<\' > xunit-result.xml` but this is unreliable because each line not necessarily starts with \'<testcase\'. (it is because i have "\\n" in 1 of the "describe")i\'m going to change the test description. though i still want a more "future-proof" approach.thanks for your promptly reply.', "remove the console.logs. replace them with a log function that doesn't output anything when in a test environment", 'what exactly is your problem you are experiencing? anything that stops you from using mocha to run your tests?', 'the problem is that running the above-mentioned test results in empty output:```$ mocha --timeout 0 test.js $```', 'travisjeffery ping- if the comments about testing mocha with mocha are blocking this i will make the desired changes... i still think this is the right way to test lower level mocha features.', 'i have the same problem with the "before all" hook. it graps the timeout that i specified globally in stead of the one in the function with `this.timeout(2000);`', '+1the `--debug` flag does nothing in the terminal; to debug on the server. the flag is. as prust notes. `debug`.', "lightsofapollo blocked partly because i'm not a fan of how those tests are written (side-note: integration tests = low level?). so ya if you could write these to use mocha and be like every other test that'd be great. the other part is making sure this is the right thing since there's a lot of other similar prs/issues related to this.", 'thanks for looking into it!i agree that "mocha never. ever exits" behavior is logical. but it isn\'t user-friendly.how would a user figure out the cause of forever running tests?it would be much better to see something like this:```$ mocha --timeout 0 test.jsfailed: should be unfinished (async callback is never called)passed: should be passed```', 'silent exit with no output is clearly a bug.but a timeout of 0 means "no timeout". why would it timeout. ever?', "yes. test 'should be unfinished' isn't timeout.it'd be nice if mocha detects such tests (that don't call async callback) and reports it in the console as failed with the reason.", '+1 to remove the spinner. i find it distracting and manually edit it out of the .js source files when using mocha.', "travisjeffery looks like tj's a little busy. would you mind reviewing this?", 'right. i was building the project rather than workspace. so now able to build. no luck with the test bit (detox test  --configuration ios.sim.release) though (same issue as described at the very beginning). my structure within e2e dir looks like this: pageobjects   init.js       my_test.spec.js mocha.opts', "no - that gulp task is a mocha test runner. sometimes it crashes when an error occurs and doesn't shut down selenium at all. then. imagine this: i fix the code and want to run the mocha tests again and then it complains that selenium is already running. in that case i have to `kill -9` the selenium process form the console and start the gulp task again.that's why the above patch of mine will help and make it a bit easier for the developer. throwing an error doesn't help and makes it probably worse.", 'please reopen if you find the root cause to be in `mocha-phantomjs` (and not phantomjs. your ci system. your tests. etc)', "i'm unclear on how this relates to `mocha-phantomjs`?", 'at pricematch we use:- mocha and chai for unit testing my views- casperjs with sinonjs for integration testing', 'access events hook in config.coffee. following #485. #617 and #727. i\'ve written some tests using `mocha-phantomjs` and would like to run them automatically every time brunch recompiles my files. i have read that a `oncompile` hook is available in the brunch plugin "framework" but i feel that it\'s overkill to write a plugin to simply run `mocha-phantomjs tests/index.html`. hence my question : are hooks available from `config.coffee` ? thus. one could write its own custom commands. making brunch an agnostic tool which gathers npm tools (which seems to be brunch purpose. isn\'t it?).', "current model of interaction between webdriver.io and allure doesn't give any chance to change anything there.you can either use `allure-mocha-reporter`. however. it doesn't work with parallel tests and requires more manual setup from you.second option will be an attempt to implement the feature here. i planned to have this working via `process.send` calls. somehow like this```jsprocess.send({  event: 'allure:attachment'.  name: 'test attachment'.  content: 'attachment content'});```reporter will be able to catch these events with the following code```jsthis.on('allure:attachment'. (event) => {  allure.getcurrenttest().addattachment(event.name. event.content);});```these two changes will be basically enough to have this working. but this should be more tested. of course.", "annotating allure tests. hi. there seems to be support for annotating tests when using allure-mocha. however. i can't seem to find any documentation on how to do that here. is this possible?", 'it is going to be supported very soon. close this as a duplicate of #37']