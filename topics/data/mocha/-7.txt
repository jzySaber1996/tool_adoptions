["re-read... this isn't against mochas repo.  this is the bower-mocha repo that **i created**..", "add devdependencies. i have several projects that use mocha. expectjs and othe stuff for testing.having the user to download these kind of dev/test dependencies seems wrong. but it would be great if bower also managed those for me. thats why npm supports the devdependencies.at the moment i'm using the npm to manage dev dependencies for me. this way i don't bloat the component.json with stuff the user doesn't need but its kind of ugly because i'm using two package managers..", "i've been thinking about this as well. i'm on the fence whether mocha and expectjs really should be available via bower as they're not actually web components. that said. there certainly _are_ web components that would be a good fit for devdependencies or optionaldependencies. for example. if you have a library that requires jquery _or_ zepto. you might put both of those in optionaldependencies. and one or both in devdependencies for testing.", 'jamesarosen exactly. if this has a go i can implement it.', "i'll help out however i can.", "i added dev deps to component(1) a while back. haven't converted mocha over to utilizing components but imo test frameworks would make great components. no easier way to install them than that!", "i certainly wouldn't complain about being able to merge my `package.json` (used only for `devdependencies`) into my `component.json` :)", "jprichardson have you had the time to look at this pr? what do you think about it?it raises the question of how to test a renderer view and not just a renderer script. from what i've understood of electron-mocha code there is nothing. as of now. that can be used to load a renderer view. do you think electron-mocha could be modified/extended to deal with this use case? would you be willing to? i could spend some time on this. should you agree. and give some directions on how you would like it to be.thanks!", "hrm.  good point.  that would just kick the can down the road.  i'd guess that in such a case. you could use project templates but that isn't dynamic in the fashion that could be useful for doing something silly like running test suites. ;)i've primarily iterated using the local event by specifying what i want _right now_ and working from there.  my test suites handle the rest by providing the specific event definitions that i want to call each function with.  because this more involved capability of mocha-chai-sinon serves my purposes better. i've seen event.json as a transitory debugging tool rather than something for extensive. planned. and structured use.", 'good point about using mocha-chai-sinon...i haven\'t actually looked much into that because i am so under the gun right now. but that sounds like it is probably worth a look for me atm.perhaps the right approach for serverless is to do the simplest thing. which would be to allow someone to sepcify an alternate .json on the cli and recommended "proper" testing be done my mocah-chai-sinon.', 'i\'m not sure how well i understand your question. so correct me if i\'m wrong. but you\'d like to know what content-type i\'m sending to serverless offline & what content-type is in the lambda function template. right?in my lambda s-function.json. there is this:``` "requesttemplates": {                "application/x-www-form-urlencoded": "{\\"payload\\": $input.json(\'$\'). \\"apiid\\": \\"$context.apiid\\". \\"stage\\": \\"$context.stage\\". \\"path\\": \\"$context.resourcepath\\". \\"method\\": \\"$context.httpmethod\\". \\"all-params\\" : \\"$input.params()\\"}"            }.```i have a mocha test case that uses request-promise (& co-mocha) like so:```var response = yield request({    method: \'post\'.    uri: urltotest.    form: body.    resolvewithfullresponse: true.     simple: false});```(this is somewhat sparse. i know. but the code is proprietary so i don\'t want to post anything revealing.)the test passes when i point it to the deployed api. but not when pointed to serverless offline.', 'adding basic test infrastructure. adds ability to use gulp test/typescript to run typescript mocha unit tests.', "i have helvetica neue on my box. it looks good. i do notice that the font in the other paragraphs is tiny. can i suggest bumping up to 14px for the 'open sans'? or at least comparable to the mocha.js site.", "using the inject loader doesn't work for me in combination with with babel and mocha loaders.right now i'm using sinon after importing and making sure my modules all export objects.", 'definitely  more control over the tests within a test file is wanted', "paulbjensen the problem with putting it in the same file is that we'd have to mock the global connect cookie parser middleware. which could affect rest of our tests which could affect rest of our tests. i'm not sure if there's a way around it since i'm not too familiar with mocha.", "i have a theory. i think something in one of your sub directories must be reseting the global scope. this would explain: a. why you couldn't reproduce with the 130 branchb. why you only get the error when running with --recursivewhat happens if you move `yadda.plugins.mocha.steplevelplugin.init();` down a few line to``` bashnew yadda.featurefilesearch('./test/features').each(function(file) {  yadda.plugins.mocha.steplevelplugin.init();  featurefile(file. function(feature) {```", "i finally got mocha to work. in windows it seems that `mocha test` is the one that works. not `make test`.i'll push the commit when i'm done testing. thanks for all the help aheckmann", "you can run one file at a time pretty easily. perhaps it's better to break your script out into separate files rather than trying to run something in the middle of a file.", 'use a test runner. mocha works in both browsers and node so might be a good one to use. tape with testling might be a good choice as well', 'yes. and also``` jsmodules: useaddons: true. false useforms: ... userouterbuild:   webpack  grunt  gulptest:  mocha/chai  nodeunitbackend:  express  :)```maybe backend is taking it to far', "help me out here if i'm thinking about this too crudely. right now to check for the `appdir` we use a naive(? for lack of better of a better word) implementation which checks where roosevelt is required and then keeps grabbing the parent until it finds the `roosevelt.js` and then goes two parents above that. so in regular app cases this is good. two parents above the `roosevelt.js` file is the `appdir` but when required outside of that level we have problems. for example. say two levels down in a test directory. can we not just use `process.env.pwd` since you will always be in the app directory when running commands. so `npm run dev` `process.env.pwd` will give the appdir. running npm test and using `process.env.pwd` will set the `appdir` correctly. then we don't have a hard-coded two step and roosevelt can be required anywhere.is there a flaw in this thought?", "pwd will be wrong because if you start the app from a directory that isn't the same as app.js. pwd will be set to whatever your current directory is.", "yeah good point didn't think of the case where you could be up a directory and call `somedir/app.js`. so we will have to use a walk to try and smartly find the appdir.", 'mathias. hi! thank you for tests and your effort. sorry. i have some work in the office this month and  very slow with answers.i think it is better to split original test one-by-one and add them to `test` directory to simplify the testing process with `mocha` library.', "now i switched to mocha (as it really more robust and convinient). i used jasmine as well it doesn't actually matter. and i use dependency management tool to load scripts (like requirejs - i use steal.js)custom page is testem specific (loads testem.js. test framework. test scripts) why use proxy for rendering it?", "+1. maybe i'll give this a try?", "doubt it has anything to do with mocha either unless it's the reference issue", '`--recursive` needs documenting. quick pull request here: #512', "+1 for supporting file options to html-cov. because i'm writing some testcases which makes http request to my developing services. and these services can't give me coverage results. i wrote my own coverage-write function. but mocha's reporter doesn't support arbitrary filenames...", "i've only seen this once and it was because i didn't have redis fired up and tried to run tests. so that makes me think we are only really getting this under similar conditions when mocha is not even really running yet. so we should re-throw to expose the original error and bail out of mocha", "although now i wonder if i'm doing this correctly... i'm new to node and am still running through tutorials. should mocha test and my node dev environment be listening on a different ports?", "you know they exist in every single respetable bdd/tdd/xunit framework. that's why you designed it like that in mocha. it just needs a small tweak heheh", "true jhnns thats what i'm doing so i can test it in ie.hopefully mocha adds it to its core.", 'i guess my main issue with this is that we\'re optimizing for the failure cases. which of course happen when testing. but i\'d prefer that we don\'t have to change how we code in order to get reasonable reporting. i dont think this is a terrible solution at all. imo it beats forcing everyone to use a mocha-specific assertion lib. the only other alternative really is that mocha provides a single `.assert(expr. msg)` method that others tap into conditionally. then mocha can of course _not_ throw and just deal with things appropriately. "real" uncaught exceptions would still be a problem', 'visionmedia imo one of my favorite things about mocha is that it uses no assertion libs itself. it has been a huge selling point when advocating the use of mocha.i just live without the stack in many of my libs ( i have at least 4-5 projects using mocha but only one using the done(fn) syntax). so it would not be a huge deal to live without it and just use it in new project (for me anyway)', "we're getting this error in ie10 as well.does anyone have any clue what's going on? is this a design problem in mocha using recursion to run tests. under a limited stack frame environment? or ???any help is appreciated. as we are running in to what looks like a limit of around 20 `it` blocks.the problem we're seeing is that the tests complete (pass or fail). and then trying to report the problem fails at line 1753:   `stack[0].appendchild(el);``stack` on this line is an empty array.", "for that single case? wtf. hard to say how mocha would have anything to do with that if it's within the function call. we'll have to profile", '"!" - could be used for pending"*" - for exclusiveor ("?" for pending and "!" for exclusive)some symbols could be chosen as defaults but  also made configurable via parameters and via mocha setup in browser.', "reduce test error output in console. is it possible to reduce test output in node console?use case:i have a huge object and expect it to have some property. if the property is not there. mocha spec reporter outputs in a console red error:expected {.. huge object on multiple screens... } to have proper ..huge error message. but i'd rather see just line about an error and some info that would allow to identify whats happens but not huge redundant output.", 'that part is up to the assertion lib', 'add -o --opts options support. sometimes we put testcases at `test` folder. but sometimes we put testcases at `unittest` folder. the mocha default support `test/mocha.opts` file. add this patch. we can execute it like `mocha -o unittest/mocha.opts`.', 'add error reason for test failing in growl notifications. hi i use mocha extensively throughout my node application and have it watching my directory to ensure that code is working as expected. it would be great if my growl notifications could display the reason for a failed test as well. if this is not a priority could u refer me to where i can perhaps learn how to implement this myself? thanks.', "the messages can get pretty massive though that's the problem", 'whitecolor thank you. but changing the source of mocha is not a solution for us. is this the only way?', 'hi. i would ideally like just the error. not the full stack trace. any suggestions?', "what we could do is truncate the msg if it's too long. for example object comparisons might be really large. i'd be fine with that. we can just trail with ...", 'tj. could you process this pull request.', 'changed my mind. this is too specific. just use `./test`', "because i need run automation testcases and unit testcases. it's not able to put them together.", 'i really need this feature. any alternative?', 'js examples next time please :p i can verify that it does work fine for me for test-cases. but yes if a hook fails mocha will pretty much bail immediately. though i suppose we could change that behaviour for after / before hooks only', "not the cases' issue. eg. the unit case need set 2000ms for timeout. but other cases need set 10000ms for timeout. the options not same.", 'so do```test-unit:  mocha --timeout 2stest-acceptance:  mocha --timeout 10s```', 'sounds good to me. also +1 on mocha being a little better for node.', 'work on tests (mocha) . too lazy now. will do in the future.', 'the tl;dr is if you need your reporter output separated. use a reporter that uses `process.stdout.write` and use the `--file` option to output it. and then you can pipe stdout from mocha-phantomjs wherever you want.', "hello.a) nope. i don't have `mocha-phantomjs.opts` file.b) i tried both `testrunner.html` and `./testrunner.html`. the result is the same. are you able to reproduce the problem. maybe it is something with my local setup.", "yeah i was thinking about the test. and it is tricky to implement as we do not have a dependency outside the box for the ci build. nor a server running during tests. also nor do we have tests for the existing functionality! i'll take a look at it later.also i did double-check and mocha uses `-i` to invert grep results. so we'll implement that when `-g` gets implemented (tracked in #145)", 'tl;dr - just pick anything that makes sense.names of args is hard :( which side do we lean too. i think there are seldom good answers and we should just be careful and cognitive. so first side (mocha) or (phantomjs) to implement the need is maybe our winner :)', 'mocha tests. add node tests running qunit_spec under mocha and revs the node package to the latest.', 'ok. makes sense.when i pulled your branch and reset this time. i ran this command instead:``` bashmocha -t 60000 -r spec test/functional/safari -g "findelement```this time the first test passed. but the logs show appium hanging after `info: shutting down appium session...`maybe something to do with the callback you added?', 'added ability to close tabs in safari when using safarilauncher . by changing the window.close() javascript call we can now close tabs for mobile safari on physical devices as well. this solution bypasses the rule that javascript can only close a tab opened by javascript.in addition we automatically connect to the latest window (rather than the first) as this is the one opened by safarilauncher.tested this on sim (ios6 and ios7) with:<i>mocha -t 60000 -r spec test/functional/safari -g "findelement"</i>and on physical ios6 (iphone) and ios7 ipad and i was able to close tabs and run safari tests.', 'great discovery. thanks!', 'jlipps. i think the travis build failed because i squashed the commits.', "travis is passing now. squashing wouldn't cause a build failure.", 'thanks!', 'npm test definition to facilitate contributions. `npm test` to runs mocha tests. including code coverage report.', 'great. thanks!', "looks awesome!i guess we need an mocha adapter so that testacular can read mocha's results", "actually. looks like this isn't related to mocha. but to brunch.  just got into the office and tried to build after a restart and it's still throwing this error.  any idea how to fix?  we're kicking off a massive multi-dev project today so any help would be appreciated.  i want to make sure there won't be any catches along the way", "btw +1 for `test-cli-helpers` and `test-browser-helpers`.this (separate mocha.js) is pretty strange. vojtajina maybe there is some low-level api so testacular will be able to use brunch' concatenated mocha? is it possible to make if there is no?", "and in the case of mocha. it's asynchronous.", "> the top-level source code example appears to be correct. though the line number referenced there is not correct (though the stack trace below is correct). so maybe an option would be best?probably not an issue. can't really do an option since the require injection stuff is done on require so it can be used like `$ mocha --require babel/register` and you can't override any of the `source-map-support` settings after initialisation.just to verify. would adding in your custom `uncaughtexception` handler before `babel/register` work? if not. i'll just merge this as-is and deal with the (minimal) consequences of having the first line number incorrect.", 'thanks.great work! :+1: the `mocha --compilers js:babel/register` also works.']