["i'm glad to see that old stuff go!  that was one of the first things i did on this library. just trying to get the mocha asserts to work in the browser so that we could get the same tests to run both client and server.  i never expected it to last.  (but i also never wanted to revisit it!)  thanks!", 'example updates and fixes. hi all.i just recently stumbled on this whole "functional programming" thing and shortly after that stumbled on ramda. seems really neat!i noticed an error or two in the examples. one thing lead to another. and i ended up writing a mocha test to compile and run all the examples. i went through and tried to get them all in working order. i changed some around slightly but mostly just little syntax fixes.this commit only includes my fixes to the examples. if you would like me to add the mocha test that compiles and runs the examples as well. let me know and i will issue a separate pull request. thanks!', 'this is fantastic. kedashoe!> if you would like me to add the mocha test that compiles and runs the examples as well. let me know and i will issue a separate pull request.i would _love_ to see this. :)', 'this looks good to me. apart from the notes davidchambers and i made on it. thanks for doing all this work!', 'commit updated with suggestions', 'lgtm!', 'agreed. looks good. thanks', "this is great stuff!  thank you very much!i'd also love to see your mocha test to run the examples. but as you can see in the comments to #338. i'm sceptical about overloading the use of comments.  (note. however. that i'm sceptical enough that i don't particularly like using them both to annotate the code for its developers and to generate api documentation; that's a battle i've long lost.)  so i'd love to see this. but am not guaranteeing that i would actually want to use it.", "sounds good. i won't have a ton of time the rest of the weekend but should have it up monday or tuesday (need to clean it up at least _a little_. i figured i may as well use this little exercise as a way to start learning this stuff.. you all can have a good laugh at my functional programming :)", "mocha test to compile and run ramda.js examples. alright. here is my frankenstein imperative/functional mocha test for the examples. there was really no hope i could write anything properly functional in a couple days so i just got what i had written to pass the lint checker and here it is.basic idea:- parse the function comments (and function declarations for mocha it() descriptions)- extract example. parse example so we can test the //=> 'eg' as assertions- inject our executable example source as a function in ramda (so that we can also run internal function examples)- run our example function. see what happensif you want to see all the assertions being run. you can just add `console.log(msg);` to `assertpairequal` (maybe grunt option for more verbose?)", 'did you consider using jsdoc programmatically (or falling back to esprima) to access the examples without resorting to gnarly regular expressions?', "i won't have time to look over the code until this evening.  but i'm looking forward to it.you should know. though. that it's failing the travis build -- it just seems to be hanging.  i haven't investigated any further.", "nicely done!i'm still not sure i'm a believer (doubts described in #338). but this in nice work. and as it's so unobtrusive. it seems well worth including for now.", 'cache clear documentation. for many use cases. the orm module cache needs to be manually cleared.this is useful in cases where you are bootstrapping mocha tests and need isolation. or are pooling resources on a server.this can be done by calling orm.singleton.clear().can someone update the documentation to reflect this?', "i built a mocha test to automate set generations for lower-tier (ru/nu/pu) pokemon as if it were a rain team. and the only pokemon that came up with bad sets in my first run (i only had each pokemon generate one set for now) were pyroar. lilligant. every mono-fire pokemon (rejected under rain automatically anyways) and pokemon that ended up with sunny day (which also get rejected). there might be more that i missed. of course.i think it's best if i took the pokemon that have the worst sets under sun/rain and hardcode them out as well.", "ac360 wouldn't this be a problem for loading devdependencies like mocha as npm expects them to be in a local node_modules folder? so when i want to execute the mocha binary will it be found?just tested it by installing mocha in a parent npm folder (and looked into the docs) and it seems like npm is then only loading dependencies in the node_modules folder in the same directory?to optimise your dependencies and remove dev dependencies you can also use `npm prune --production` which will remove all dev dependencies from your node_modules folder.or is this only for additional plugins for users? because i think the impact of only having support for plugins in other node_modules folders will be pretty minimal.", 'lardee i went with -f since it is the option used also by `deploy function` (and `serverless-mocha-plugin` command invoke test). this can be easily changed if `-n` is preferred.', 'usage of sinon and mocha toolings for tests. # this is a feature proposal## descriptionour current test codebase could be improved so that we e.g. use sinon sandboxes (rather than restoring our stubs by hand) or mocha helpers (e.g. to fake a "waiting 5 seconds" command).this also means that we should use `beforeeach` and `aftereach` more wisely for independent test setups and cleanups.', "make test discovery automatic. closes #1337 (maybe)## how did you implement it:uses globs to match instead of the require() files.i did not implement the random ordering. that's a much bigger problem to tackle and the linked issue in mocha has not made much traction yet.## how can we verify it:`npm test` hits the same number of tests (563 at the time of writing this) before and after these changes.## todos:- [x] write tests- [x] write documentation- [x] fix linting errors- [x] make sure code coverage hasn't dropped- [x] provide verification config/commands/resources- [x] change ready for review message below***is this ready for review?:*** yes", "then coverage decrease is because the 'require files' weren't being ignored from coverage ;)", "> move universal func-test's from xod-client-electron to xod-client. rewrite them with puppeteer.this part is done in #1015", "phantomjs is just a headless webkit.  that probably adds minimal value. above the node tests (since both are v8-based).  it would be better to use something which could actually test against mozilla. ie. etc.  testling seems to do that (but it's slow and a bit flakey).", "visionmedia thanks. i'll look into it.on the same computer. i'm able to run an express app and mocha test it without incident. maybe there's a config option that helps.", 'req.subdomains tests fail in windows. trace:```$ mocha test/req.subdomains.js  .....  x 3 of 5 tests failed:  1) req .subdomains when present should return an array:     error: expected \'["ferrets"."tobi"]\' response body. got \'[\\n  "ferrets".\\n  "tobi"\\n]\'      at test.assert (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\lib\\test.js:177:21)      at c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\lib\\test.js:124:10      at test.request.callback (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\node_modules\\superagent\\lib\\node\\index.js:575:3)      at test.<anonymous> (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\node_modules\\superagent\\lib\\node\\index.js:133:10)      at test.eventemitter.emit (events.js:95:17)      at incomingmessage.<anonymous> (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\node_modules\\superagent\\lib\\node\\index.js:703:12)      at incomingmessage.eventemitter.emit (events.js:117:20)      at _stream_readable.js:883:14      at process._tickcallback (node.js:415:13)  2) req .subdomains when subdomain offset is set when subdomain offset is zero should return an array with the whole domain:     error: expected \'["com"."example"."sub"."ferrets"."tobi"]\' response body. got \'[\\n "com".\\n  "example".\\n  "sub".\\n  "ferrets".\\n  "tobi"\\n]\'      at test.assert (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\lib\\test.js:177:21)      at c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\lib\\test.js:124:10      at test.request.callback (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\node_modules\\superagent\\lib\\node\\index.js:575:3)      at test.<anonymous> (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\node_modules\\superagent\\lib\\node\\index.js:133:10)      at test.eventemitter.emit (events.js:95:17)      at incomingmessage.<anonymous> (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\node_modules\\superagent\\lib\\node\\index.js:703:12)      at incomingmessage.eventemitter.emit (events.js:117:20)      at _stream_readable.js:883:14      at process._tickcallback (node.js:415:13)  3) req .subdomains when subdomain offset is set when present should return an array:     error: expected \'["ferrets"."tobi"]\' response body. got \'[\\n  "ferrets".\\n  "tobi"\\n]\'      at test.assert (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\lib\\test.js:177:21)      at c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\lib\\test.js:124:10      at test.request.callback (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\node_modules\\superagent\\lib\\node\\index.js:575:3)      at test.<anonymous> (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\node_modules\\superagent\\lib\\node\\index.js:133:10)      at test.eventemitter.emit (events.js:95:17)      at incomingmessage.<anonymous> (c:\\documents and settings\\apenneba\\desktop\\src\\express\\node_modules\\supertest\\node_modules\\superagent\\lib\\node\\index.js:703:12)      at incomingmessage.eventemitter.emit (events.js:117:20)      at _stream_readable.js:883:14      at process._tickcallback (node.js:415:13)```', "i'm using mocha. just like sequelize is.  that's why i'm confused that this doesn't show up in the normal run.i grep'ed through the code base for settings to disable global leak detection and didn't find anything.  after putting some console log()s in. the test suite is definitely running the code. but mocha isn't complaining.", "well. i managed to force mocha to check for global leaks by adding the --check-leaks command line param to the makefile.  i thought that was the default. but...  i don't know.  at least it complains now.should i add that change to the makefile to this pull request (along with other global fixes) or should i start a separate pull request?", "misterdjules yeah. i think just changing the `mochacli` `reporter` option to `reporter: grunt.option('reporter') || 'spec'` like you have it currently in this pr would get the job done.", "spec converter doesn't strip `.json` when building tags. as visible in e2e tests when running `mocha`. you will not see the proper descriptions for each tag because they don't match.", 'this requires an update in swagger-js.', 'how to use tags on mocha?', 'closing due to inactivity and also this is now possible with using mocha runner.', 'update mocha to use promises feature. ...so all the done()s could be removed.', 'feat(gen): unify testing framework. changes:- add prompt for jasmine or mocha- if mocha choosen. prompt for expect or should- use `<%= does() %>` to dynamically insert assertions (expect|should)- add mocha variants for protractor tests- add mocha options to protractor.conf- remove `test/fixtures/(bower|package).json` from repo- move rune2e functionality to runtest and simplify switch- comment generator test functionsnote:server-side jasmine test are needed to fully unify testing frameworks.once jasmine tests are included for server. mocha dep can be removedfully when selecting jasmine.', "jakxz. i know you don't have a lot of extra time. but i could use some server side jasmine tests to match the ones written in mocha. even a 'call' for tests would help. especially coming from a 'collaborator'. i need to adjust timeouts for protractor/mocha. but other than that; this pr simply lacks server side jasmine tests. my main issue is the differences in flow control such as before. beforeeach. after. aftereach. i'm not sure how to structure the before clauses in jasmine. also i'm pretty busy with several client's atm. but i'll try to do what i can. just wondering if i might be able to get some help on this one. thanks.", 'kingcody i hear you. committing to get you a pr on your feature branch soon.those who are familiar with jasmine. please feel free to contribute as well.', "updated the travis config so e2e tests should run on pull requests now. you'll need to merge canary back into your branch.edit: actually i spoke to soon. need to work on this a bit more to get it working for pull requests", "nope. it's for the mocha text diff feature. that way unexpected files show up as red in an error report.", "configuration. how do you configure it when used with mochaphantomjs?this is my gulp file: ``` jsgulp.task('test'. function () {    return gulp.src('tests/runner.html')        .pipe( mochaphantomjs({            reporter: 'mochawesome'        }) );});```what do i have to drop into runner.html to make it work?", 'boom. thanks for explanation.', 'any updates on this? i can submit a pr if you would like', "samzhao i am not sure why i took issue with sync ajax. i went ahead and disabled async and got it working. and that's really what matters.i'm not sure that i am forfeiting any feature by disabling the async. i am using yadda with the mocha plugin. so it feels a bit handicapped in spirit to not have async tests. but honestly. i'm just happy to have it working.", "if you're using the mocha plugin. you can use before. beforeeach. aftereach and after in the normal way", 'awesome! that works. so each mocha test corresponds to a scenario?', "when you use the steplevelplugin. each step in your scenario is executed inside a mocha `it` call. i.e. each step is a separate mocha test. this is generally better for output. because you see all the steps execute. with the scenariolevelplugin you only see the scenario title in the mocha output.to setup / teardown a database use mocha's `before` and `after` functions. however you need to take care where you position them in your test. make sure they're outside any calls to `feature` and they should execute before and after the yadda test suite.", 'this pr has nothing to do with mapreduce. on top of that i just used a previous test and added there some stuff. the double catch was there (i do not like it either). with the latest mocha you can completely get rid of it returning just the promise itself.', 'update mocha. suggested by valotas in #2068', 'so the rest have been merged so this can be rebased hmm the mocha thing is annoying. it should be ok to load mocha on demand as you said. not sure about adding phantom though. its adding a bit of complexity. some more deps and will bump up our test time. not sure its worth it?', 'could you try the dynamically loading mocha + the shims? i dont want to add both build time complexity (it would be nice to be able to switch browser tabs. one with shims one without). and polluting globals in the tests. (this works as it should. but writing the empty file on build and loading it is confusing)if theres something that makes that really annoying. then +1 for this. but would be nice to fix those before going in', 'what would be the difference between this and the --tag feature?', 'i want to be able to pass a line # for the feature. ruby cucumber has this baked in', 'this is a cucumber thing and not a pioneer thing', "not using `--recursive` causing problems?. hey there.thanks for making such a fantastic project! just a quick question -- i'm setting up a existing large project that formerly compiled code in order to get coverage so that it works with coffee-coverage. however. i'm finding that the report generated shows little to no actual coverage at all. while the compiled report was quite high and the project is tested thoroughly. i have followed instructions exactly. and it's not erroring out. just giving an incorrect report. the one thing i am not including is the `--recursive` flag. as it's not needed to run my test suite. i tried including this. but then mocha tried to run some of the fixtures included in the tests folder and errored.is the `--recursive` flag necessary to generate correct coverage? if not. what further information could i provide to make this incorrect coverage issue easier to shed light on? and if so. how do people typically deal with fixtures being run as tests with the recursive flag?thanks again!", "huh. very strange. thanks for investigating this. and glad it's not just me doing something stupid! if there's anything else i can help with here happy to do so. just let me know :grinning:", 'add new howto: use tape but not mocha. i hope this is something you can use. it sure would have saved me some time! :smile: this demonstrates how to use coffee-coverage with tape. or really with any basic command-line test harness.', "thanks. sir.  it's a holiday here today. but i'll try to remember to merge this tomorrow morning when i get to work.  :)", 'make sense. thanks for the examples.  i like the option of using supertest.  i guess the bottom line is that none of you actually spawn a separate process for the sails application; it seems that the sigint signal isn\'t correctly received by sails on kill(). which may be a node problem and not a sails problem (the code in sailsjs looked logical for shutdown).i\'ve tried the code here and it seems to work with the exception that mocha leak detection goes crazy.  have you noticed that?```  1) starting sails server with lift "before all" hook:  error: global leaks detected: config. [every model object]. _. async. sails. localappurl```are you just disabling leak detection in mocha?  i know it is used in the adapter tests.', "mikermcneil i was bit by this same lowercase issue; your commit 0b11e140863b57904c74dcfdef4ff2b25aa83135 fixes it for me.+1 to adding the test cases from miangraham's pr", 'hi polastre i am not sure where you have placed your `before()` and `after()` statements. do you know. that they are _place_ sensitive? that means: if you place the code block outside the `describe`element. it will only be started once during test (suite) run. if you place your blocks inside the `describe`element it should work as expected.i made a very easy test example for you. if you save this as an extra file in your test dictionary (folder) and run them all. you can see the according console log. hope that works for you.**filename: test.workflow.js**``` javascript// this is a small example about workflow in mochabefore(function () {  console.log("simple workflow test before all tests (suite) on start.")})after(function () {  console.log("simple workflow test after all tests (suite) on end.")})describe(\'simple workflow test\'. function () {  before(function () {    console.log("run before all (it) tests inside a section describe")  })  after(function () {    console.log("run after all (it) tests inside a section describe")  })  beforeeach(function () {    console.log("run before each (it) test")  })  aftereach(function () {    console.log("run after each (it) test")  })  it("test 1". function () {    console.log("run test 1")  }).  it("test 2". function () {    console.log("run test 2")  }).  it("test 3". function () {    console.log("run test 3")  })})```remark: you can use `before`. `beforeeach`. `after`. `aftereach` multiple times if you cascade the `describe` sections in your tests. they will all run in reverse order from inner to outer placements.greetingstomp.s.: i am not in knowledge in the moment how to start/stop the adapter correctly.', 'hi.i only call mocha like this:`bin/mocha --reporter spec --colors --recursive test``and get not such output as you.i do not use the option `--check-leaks`hopefully that helps.', "im going to try to add some testing docs soon (this week?). i have a working mocha + assert thing going now which tests a controller. i'll put that up. something is better than nothing :)", 'run tests. add tests to `mocha.opts` so travis runs them. also fix up tests so they all pass on travis.', 'xdissent thanks!  glad the tests actually mean things now :)', 'unit tests layout when a project gets created. it would be a really nice feature to have a /specs directory with either mocha or jasmine ready to go. then sails users could start doing tdd/bdd out of the box.', 'update mocha', "i'm not clear; if you are using phantomjs aren't you still really in a browser? you won't have access to the node apis required by filesystemloader.regardless. you can always construct the environment yourself and use `filesystemloader`:``` jsvar env = new nunjucks.environment(new filesystemloader('views. true));```", "thanks jlongster. i'm not sure if i explained myself correctly. but we basically need a way to load a template file in the browser. without using ajax. i'm not sure if this is actually possible.we're simply using phantomjs to look at an html file. not a server. as a result ajax requests don't work. as it is requesting a local file instead of a file on a server.", "the simple way to do that is precompile your templates. then you can just load them in when the page loads.there is simply no way to external data without ajax. you can't get access to the filesystem. i can't think of another way that you'd be able to get it. you have to precompile.", 'how do we run the mocha tests in the browser?', 'i can reproduce this with just:```shember new foo --yarncd fooember install ember-cli-mochaember serve```aexmachina thanks for the reproduction!', 'mocha:  2969 passing (5s)index.html: passes: 2943code review: skipped', 'solved: test vector that passes in node. but fails in browser/sjcl. there is some kind of problem either in bitcore or sjcl involving thedecodeuricomponent function. i discovered this issue while working on thenetwork protocol for copay.  decrypting binary data in sjcl produces problemsdue to the way sjcl is interpreting data as strings. i will have to investigatefurther tomorrow. for now i am producing this test vector to demonstrate theissue. this test passes in mocha node. but fails in mocha browser.', 'great job! reviewing', 'fixed by d77da1367ca2d24f52ded30f5f2203498460271a.', "i am experiencing a simmilar error during `ng serve` when installing `types/mocha`:```[error in [default] c:\\users\\user\\project\\node_modules\\types\\jasmine\\index.d.ts:9:17duplicate identifier 'describe'.error in [default] c:\\users\\user\\project\\node_modules\\types\\jasmine\\index.d.ts:11:17duplicate identifier 'xdescribe'.error in [default] c:\\users\\user\\project\\node_modules\\types\\jasmine\\index.d.ts:13:17duplicate identifier 'it'.error in [default] c:\\users\\user\\project\\node_modules\\types\\jasmine\\index.d.ts:15:17duplicate identifier 'xit'.error in [default] c:\\users\\user\\project\\node_modules\\types\\mocha\\index.d.ts:33:12duplicate identifier 'describe'.error in [default] c:\\users\\user\\project\\node_modules\\types\\mocha\\index.d.ts:34:12duplicate identifier 'xdescribe'.error in [default] c:\\users\\user\\project\\node_modules\\types\\mocha\\index.d.ts:39:12duplicate identifier 'it'.error in [default] c:\\users\\user\\project\\node_modules\\types\\mocha\\index.d.ts:40:12duplicate identifier 'xit'.](url)```i use mocha for unit testing my server side code. but the mocha typings shoulnt be included in any way in the client build.", 'update mocha', 'verified that mattwiller has signed the cla. thanks for the pull request!', 'still looking into this in a new branch `earlyexit`. still having problems replicating the problem in a test though', "i've added a test that uses a simplistic alternative mocha interface to prove that it works.", 'mocha-test + watch only runs once. i\'ve set up my gruntfile to use grunt-contrib-watch and launch mocha-test when it detects changes in my files.the first time i change a file. it runs the test as it should. if i save the file again. however. all i get is "0 passing (0ms)".is there some sort of internal state preventing it from being run on the same files again? and if so. is there any way to fix this?', 'i think i know what causes this. mocha works by requiring the test files and if you are still in the same process then it just hits the require cache the second time around and as such the tests are not reloaded. i have actually found this quite useful for running multiple reporters to generate both test and coverage data without rerunning tests and as such have never wanted to "fix" this - also the fix involves messing around with the require cache which i have found to be troublesome in the past.i haven\'t used watch in a while as my tests usually involve a compile step these days and i think i got used to a more manual style in which i like to watch the tests run :)anyway. i do know that grunt-contrib-watch has an option for spawning tests in child processes which by default is on. i am guessing that to run into this issue you have turned that option off?', 'oh awesome. i did indeed have "nospawn": true on - switching this off resulted in a slightly slower process. but does fix this problem!thanks for replying so quickly!', "you're welcome. in the future i may add an option to clear the require cache or maybe even add another task that can be inserted before each set of test runs so that we can get the best of both worlds", "thanks! i agree with the notion and i think this a good pr. but i am a little hesitant to make this the default behavior because i didn't find one unit test framework that behaves this way. i've looked at mocha for js. rspec for ruby. and unittest for python. all of them give an ok for when there are no tests. as you've mentioned. tap also behaves this way. so. i feel like i would be going against the grain. but. i would be okay with making this an option.it'd be good to have some discussion on this. so if you are listening please chime in.", 'cli spits a clean error when path/js input does not exist. <p>basically. a simple error message is presented to the cli user instead of fs thrown exception if the file or path to be tested does not exist. for example: <em>mocha dajlksdj</em> spits an error :).</p><p>i believe more cleanup work should be made in the cli area. we should consider adding some tests.', "is there a .mocha file where i can specify defaults such as --no-colors?. i'd like to set some defaults for mocha without having to type them each time. does mocha look for a config file / dotfile anywhere. as jshint looks for `.jshintrc` and npm looks for `package.json`?", "just sounds like you haven't run `npm install` in the mocha dir. i don't use `npm test`", 'running mocha without actual test. hi.mocha --reporter specthis usually runs also the test code. sometimes i just want to see the specs. possible to run it with test code? thanks.angelo', 'add alert and confirm to the list of non-enumerable globals. in my test i want to mock "alert" and when i do that. mocha tells me that i leak "alert".', 'you can whitelist them with `.globals(array)`. the ones in core are for bugs in firefox etc', 'sorry. i fail to see see why `window.alert` would be any different than `window.settimeout`.', '+1 wasted time trying to figure out why code was failing within mocha tests. when it was mocha itself causing issues', 'any plans to do this soon? it would be really helpful to be able to install mocha as a dev dependency.', "regular you can use it as a component dev dep already (it uses the build products). but i'd like to refactor mocha itself with it some day", "so i tried adding mocha to dev deps in a component but when i require it i'm just getting an empty object. i was thinking i'd just require it and start it up. is the idea to just point a script tag in my `test.html` to the `mocha` directory in my `components` directory? seems a little counter-intuitive.", "visionmedia. interesting. i wasn't aware that there is a global 'require' too. so there actually is no need to have chai.js and sinon.js and stuff lying around next to test.html like so many projects do.and now that i found the mocha.js target in the makefile. i finally understand where that file comes from. doh :)what do you think. would it be nice to be able to have components that bring their own tests compiled into build.js? i am thinking of widgets that can self-test even after deployment in a production environment (much like couchdb's tests for example). in such a scenario. global namespace pollution would not be acceptable. so i was thinking of making mocha's `exports` interface work with component's `require`. does that make sense?", 'we just need to wrap it and module.exports= mocha', "just having some connection issues. it's hard to read with that unformatted code but i can tell you that it's likely nothing to do with mocha so i'll have to close for now. probably not closing some servers or something in the tests. isolating with sub-procs instead of re-running with mocha's js api in the app process would keep state cleaner", 'for some reason. mocha ends up with a recursive structure. you can run the tests yourself. have a look at the link.', 'look here', "look at the different reports. i'm pretty sure there is something you need:", 'greelgorke thanks!', 'i might be wrong about this. but what i see is that even though i compile source maps for my code (and i checked that these source maps really work). if an exception is thrown. mocha reports only the bundle.js file which has the minified/concatenated code.', "that's not the concern of mocha though. you can compile source maps (or use sourceurl) if you're aggregating", "visionmedia i am sorry. but i don't understand your response. i mean i understand the meaning of it. but it seems to me. that you just repeated your last response and have not reponded to me. that or  i must be completely missing the point somewhere. and i am unaware of not just what it is. but where i am missing it. i am using mocha in the browser on a code which has to be browserified in order to work there. i use the browserify feature of compiling source maps for the code. and they work properly. as long as i am not trying to use the code with mocha. when i use it with mocha. the source maps go away. i only get the original file and line nr. references. not the source maps. which - i repeat the third time - are there. so please. if you do not mind taking the time. explain to me what else should i do so that i can use the compiled source maps with mocha?", '"mocha test/": 0 tests complete. i have to manually specify each test subdirectory in order for mocha to execute any tests. does mocha not run recursively by default?', "+1more specifically. could mocha look for `mocha.opts` files from the relevant directory all the way back up to home (`~`)?for example. my team would like to specify a timeout of six seconds (`-t 6000`) for all tests in our project. but we'd like to keep formatter settings in our personal directories (`--reporter spec`).", 'nope. lots of people use dirs like `test/fixtures`. `test/support` etc with libs in there. you can use `--recursive`', "add optional cooldown period between watch test runs. mocha's default watch behavior is a bit too indiscriminate. and will trigger re-runs of your test on any filesystem event. this is bad if you have other watch/guard-type services that modify the local filesystem. such as a coffeescript compiler. such cases can trigger a cascade of tests. which are at best redundant and at worst cause test failures (e.g. when near-simultaneous test runs attempt to bind the same socket. etc.).this commit adds an optional cooldown period between test runs. whichshould help eliminate redundancy.usage:```mocha -w --watch-cooldown 500 test/foobar.js```", 'visionmedia ah. okay. will `--recursive` still work well when `text/fixtures`. `test/support` libs etc. exist?', 'not if they have js in them. recursing is typically not a great idea imo. better to just do `mocha test/*.js test/unit/*.js` etc', "my use cases:i have suites where if one test fails. the rest of the tests in the suite are bound to fail.  these are rather slow integration tests that use remote apis.  however. i still care about subsequent suites.  it's nice to get a high level picture as fast as possible without grepping to suites that wont fail.  also. some of the subsequent tests in the suite might only fail due to the bad state left by the failing test.i also use mocha to do cross-browser functional testing. with a suite for each browser.  if something fails in ie. more things are likely to fail in ie. but i still want to run the chrome tests.  very useful when hooking up to ci or running full regressions. as well.", "doing `require('mocha')` just provides a global currently since it doesn't export. but we could easily patch that even without this component(1) refactor. to just check and do `module.exports` properly", "pre release hook. in this [video]( tj talked about pre-release hook to generate `mocha.js`. after that. don't you need to add this file to index and do another commit. or at least amend the previous commit?i couldn't find the hook you are referring to in the video in this repository. could you share the hooks you are using?", 'groups tape. expose the `geocoder_name` functionality to allow for sources on the same geographic level.this pull also optimizes reverse geocoding of multiple sources by checking the input against a sources `bounds` parameter. skipping if out of range. this also switches all of the tests to take instead of mocha.', "i tried do it yesterday.faced problem with karma (or mocha?). it's crashed on import es2015 modules.i cannot understand where and when test task executes during build task. and how fix it.also i think that if we switch tests to ava problem will be eliminated.", 'oh. i see. now i use `mochaphantomjs.run()` and all work right! thank you! i read this tip. but totally forgot where to use it :smile:', 'good to hear :) and good to hear my work to remove that need will be an improvement - the goal of `mocha-phantomjs` is that it just builds on your vanilla testing work. and that was the one thing not conforming to that.', '+1 would be nice to have. sometimes you just want to quick spin up tests without having to dig into build scripts.', "i can see that. one thing to note is that `mocha-phantomjs` can't know about what files you need to watch. but the same thing is true for browser sync that i've been using a lot lately. and i just pass it a glob of files to watch.", "closing as i think this is a bad idea. if you're fighting phantomjs this much you should test in real browsers (try firefox + xvbf. perhaps with slimerjs or karma). also `mocha-phantomjs` supports phantomjs 2 if you bring your own binary via `-p`.", 'closing as this is a bad idea since we can\'t aggregate the tests results in a meaningful way. it\'s much better to have one test runner and use the grep option (`-g`). otherwise like i mentioned above. this is just `find . -name "*.test.html" -exec mocha-phantomjs {} \\;` which you can do yourself if you wish.', 'uses `require.resolve` to get the realpath of mocha-phantomjs-core.js. to fixes #204', "sorry reading your post a bit more. i see you're trying to come up with a workaround. i think this is out of the scope of `mocha-phantomjs`'s responsibility. for example. you could change that dirty to monkey patch all `error#stack` to polyfill source map support and include it with your tests just as all users of phantomjs have to polyfill various other stuff. like `mutationobserver`. `promise`. etc.", 'helper function that reliably verifies if a given function is a view "class" (or view constructor). if we want to proceed with the suggestions given in issue #1846. this helper function is the first step. but i think it is quite useful by itself.it would allow us to have dynamic view classes (the view class would be obtained at run-time). the first place to use this would be in collectionview. but i see it being useful in other parts of marionette. unfortunately i don\'t have experience with mocha to write a tests. hope that will change shortly.', 'i was just thinking we would include this in the collectionview class. is there any reason to abstract it into a helper? also. would we want analogous methods for model. collection. object...etc.?', 'i see this functionality (choose the view to be used at runtime) being useful in other parts of marionette. for instance. to implement reusable component classes. i do pass view classes in those kind of classes. along with a region instance. as for analogous methods. yeah. we would need to have them for models and collections if this ends up being replicated for them. as for the rest. underscore provides utilities to check the kind of object.', 'fix handling of keystore creation. put the keystore management code in a `before` block. so as to stop abusing mocha. and make sure keystore is created before we try to use it in a test.', "publish normally. not shrinkwrap. for some reason you published using shrinkwrap and included all the devdependencies. i definitely don't need mocha in my production app.", "fixed the issue where shrinkwrap had the devdependencies in it.  still keeping the shrinkwrap though.  i've been burned by `nodemailer`'s non-strict dependency management one too many times to remove it.  more details on why in issue #39happy to hear an argument against it though.", 'thanks for the pull request!there are a few issues in the pr:- all changes should be made in the source files. (reside under `src/`)- all draw related issues should reside under an implementation of a `renderer`. which would be `canvasrenderer` in this case. the `nodeparser` does not rely on an implementation of `canvas` to be available. and it could be used to render onto a webgl context. or just a serialized json list of draw commands.- some (mocha) unit tests for the generation of list items would be nice', "there's a problem in the test suit. inside named-node-test.js the describe.only() is disabling all the other tests in the folder when called in a glob from mocha. i've changed it but you might wanna do that in master in the meanwhile.", 'remove .only() from namednode mocha test. :man_facepalming:merging this once tests pass.', 'raised in #170']