['assertion.add should defineproperty with configurable: true. without it. running mocha in continous mode (mocha -w) always fails with typeerror: cannot redefine property: on a defined custom assertion (when assertion is defined in separate file that is included with require on nodejs)', 'stevenvachon do you know if there is a way we can run these tests in an electron browserwindow? i am injecting some scripts into a browserwindow and need a way to test those.', "allow renderer process testing in electron-mocha. i couldn't find an easy way to unit test renderer process using electron mocha. is this available on electron-mocha? if so can anyone point me how this can be done?thanks.nischaljprichardson inukshuk", "either i misunderstood your question. or you're looking for `electron-mocha --renderer` :) it's well documented in the readme.", 'szwacz oh my bad! must have missed that one. i am actually using gulp-electron-mocha to run my tests. is there a programmatic way i could run this by using gulp-electron-mocha?', 'my apologies for not reading the documentation. i added `renderer: true` as one of the options in gulp-electron-mocha and i am now able to test some of the functions that run in the renderer process. thanks to szwacz for pointing it out.', "assert not caught in async tests. the following async tests run fine directly in mocha. whereas the error from the second test is not caught when running in electron-mocha instead:````jsvar assert = require('assert');describe('tests'. function(){it('test 1'. function(done){settimeout(function(){assert.ok(true);done();}. 100);});it('test 2'. function(done){settimeout(function(){assert.ok(false);done();}. 100);});});````", "> do you think it's ok to remove the handler? (mocha also listens for uncaught errors and matches them to the current test)yep. if mocha does this. i think it's redundant if we do as well.", "ok cool -- i'll try to fix this then (and will probably get rid of the handler in the process).", 'added more details to the readme.', 'dont works for me:"grunt dev > > local npm module "grunt-contrib-jade" not found. is it installed?> > local npm module "grunt-mocha" not found. is it installed?> > local npm module "grunt-replace" not found. is it installed?running "dev" taskwarning: task "jade" not found. use --force to continue.aborted due to warnings."and:"grunt test build> > local npm module "grunt-contrib-jade" not found. is it installed?> > local npm module "grunt-mocha" not found. is it installed?> > local npm module "grunt-replace" not found. is it installed?running "test" taskwarning: task "jade" not found. use --force to continue.aborted due to warnings."i think i wait for the next beta....', "dougmoscrop thank you!  you're rock and rolling!   unfortunately i have to close this pr as the refactoring in #2716 will add that as well  anyway. thank you for all the stuff you've done here and in the past and keep up the great work", "ok. this is a problem with `benderjs-mocha` plugin - i'll recreate the issue there.", "ie / object doesn't support property or method 'class'. i'm using chai-jquery with chaijs & mocha.works well in most browsers. chrome (linux & win). firefox (linux & win). opera(win) but in ie10. it shows this error:```typeerror: object doesn't support property or method 'class'```for this    expect($el).not.to.have.class('xyz')", "i'm also having this problem on ie10 :(", 'this is a chai-jquery issue; closing.', "fabianoleittes hi. i'm fine and thanks for using red bot.yes. i accept pull requests. redbot is still a work in progress so it's welcome a bit of coordination to avoid duplication of works.i generally use telegram for the development. it's easier to setup. this is also the reason many features for messenger are yet not implemented.yes i've tests. i use **mocha**. to test locally `npm test` and i lint the code before pushing it with `npm run lint`.nodes are generally very simple. all the code for the specific platform are in /lib/* and chatbot-*-receiver.js nodes.the general rule of thumb with nodered is that a node should do the minimum. don't let a node do a task that can be done with two nodes. the more granular are the nodes the easier is to compose the flows.i don't have a public roadmap yet. i'll open a wiki page in the next few days. for sure it includes facebook cards and buttons. slack support. email support and of course payment support.", "i'm wondering if it might be time to consider switching away from using casperjs and phantomjs for these tests. at the very least. i'm tempted to use the mocha-casperjs modules to try to make the format of our functional tests more consistent with the rest of the test suite.i am wondering if it wouldn't be better to use selenium webdriver. as long term it'd give us more flexibility.still casperjs does support running tests against phantomjs and slimerjs. i am also aware that there is a major rewrite of phantomjs (phantomjs 2) in progress. so perhaps we should just sit tight. still i'm not loving the 10minute slowdown of the tests or the random crashing.", "this is more a question than an issue. how do i set the report title that shows on to of the html page?right now it seems that reportname is really the name of the html page that will be outputted. for example if i put reportname='index'. it outputs index.htmlbut the title of the report on the actual page seem to always be the name of the root directory (i loko at your code and actually that is how you are getting the reporttitle)could you kindly update that to use reporttitle if specified with the reportoptions?that way we can do simply:mocha({        reporter: 'mochawesome'.        reporteroptions: {          reportdir: reportdir.          reportname: reportname.              reporttitle: reporttitle        }    }thank you so much for your greta work with this package!damiano", 'i think this is a valid option and worth adding.', 'thank you.', "maybe i am doing it wrong. let's say you want to try to reach a page on a browser : www.dev.mysite.com/runtest/. with your node server you want to run the test programmatically and then display the result on this page.(and you don't mind waiting for the test to complete does not have to be live) since it is async. the probleme is you cannot just return the html file because you don't really know when it will be done writing in the file(html.css.js). so i was thinking promise or a callback when everything is done so i can return the html file knowing its complete.it's only a proof of concept but look :var html =templates.mochawesome(obj);                savetofile(stringify(obj. null. 2). config.reportjsonfile. function() {});                savetofile(html. config.reporthtmlfile. function() {                    console.log('\\n[' + chalk.gray('mochawesome') + '] report saved to ' + config.reporthtmlfile + '\\n\\n');                    options.reporteroptions.callbackaftersave();                });i know it isn't clean code and fail proof because callbackaftersave() could be empty and race condition ... and it doesn't follow the logic of config and your param but it kinda work. it calls my function when its done writing the html. now i can safely return it.", 'the report gets saved to the `mochawesome-reports` directory which contains everything you need for offline viewing.', "so you're hitting a website that triggers the tests to run and you want the mochawesome report to display on that website when the tests are done? i'm not so sure this is a common use case. the tests themselves could take awhile to run leaving you to have a blank browser window while they run. it seems a better solution would be to employ a build server like jenkins to run your tests and then notify when they are complete. the build jobs can be configured to save the html report to a box somewhere when done and email out a link to the page. we have a similar setup where i work.", 'html reports problem. i am trying to run my mocha test cases and reporting output with mochawesome but i endup with a error 137 passing (184ms)24 pendingfatal error: call_and_retry_last allocation failed - process out of memoryaborted (core dumped)mochawesome-reports folder is generated and inside it i have css  fontsjsfolders but html reports are not generated.could you please suggest  me the solution i have tried spec.dot and various other reporter they are running perfectly over the stdout but i want html reports.', 'thanks. xeladotbe. that fixes the issue. i am surprised that calling the same mocha function from different locations changes its behavior. does mocha understand the context in which the function is being called?', "unfortunately it looks like this won't work. because mocha is not equipped to run in node-webkit.  it assumes it's in node (or something). which results in:```uncaught node.js error rangeerror: maximum call stack size exceeded    at window.require (eval at undefined. <anonymous>:1:26)    at window.require (eval at undefined. <anonymous>:1:112)    at window.require (eval at undefined. <anonymous>:1:112)    at window.require (eval at undefined. <anonymous>:1:112)    at window.require (eval at undefined. <anonymous>:1:112)    at window.require (eval at undefined. <anonymous>:1:112)    at window.require (eval at undefined. <anonymous>:1:112)    at window.require (eval at undefined. <anonymous>:1:112)    at window.require (eval at undefined. <anonymous>:1:112)    at window.require (eval at undefined. <anonymous>:1:112)```plus ```uncaught referenceerror: require is not defined```", "refactor to use admc/wd and testobject tests. * refactored all the tests to use admc/wd so that we can use remote appium servers (specifically testobject)* run a mocha script before tests that. when testobject_tests variable is set. overrides 'wd' and points the server to testobject servers to run remotely* added several endpoints to no_proxy that should have been there* added an appveyor.yml for future testobject ci (want to do it on appveyor instead of travis because it will lighten the travis load and we don't need a linux or mac box. windows is fine)", 'did you ever get this working. btw?', "nope. i've got it working with other projects. but not with this one :cry:", 'i think the `mocha.opts` file under the `test` directory has been taking care of this.  looking back through previous pull requests. all the tests have been running on travis.', "`mocha.opts` doesn't include a test pattern in master. travis does run them for development though. next time development is merged into master i expect it will bring the testing situation into parity across both branches.", "sorry about that. we're in the process of getting new maintainer.hope it'll be much faster soon.", 'guybedford can we run the mocha tests in the browser?', "unique fields aren't unique after list.model.collection.drop(). _this isn't a keystonejs' issue. it's just something about mongoose (or maybe mongodb) that you should be aware of._after a `list.model.collection.drop()` all data and indexes are gone and. for a short period of time. you can insert duplicated `unique: true` fields without any errors or warnings.i've discovered this running mocha tests. i dropped and redid the collections after every test and then uniqueness tests (trying to register/update users with an existing email. username) failed. _but_ only when they were in the middle of other tests. running alone they were fine.i was able to query a `find` with an unique field and i've receive two and three results. after some ~~mad~~ research i've found that the issue came from the `drop`. now i have replaced `list.model.collection.drop()` with `list.model.remove()`. more inefficient but safe in terms of model integrity.i haven't got the time to go really deep into it yet but i hope it helps someone._if it's a well known issue and i've forgot how to search on google properly. my apologies._", 'this sort of thing is really valuable. there are some other things i know of as well (jossmac found one earlier today with regards to mongodb indexes not being dropped)i think we should add a "tips & gotchas" section to the site that everyone can contribute to - will leave this open until then so we don\'t lose it.', "please. use:``` js   if(typeof exports != 'object') {...}```instead of:``` js   if(window) {...}```try to run `mocha .` in node.js now :)", ':+1: now if you run `mocha .` it opens the browser with empty page. how to eliminate this?', 'updated to latest generator and mocha', 'is included in pr #25', "taheilo there are a few issues with your code examples above:- in the first snippet instead of returning a new `promise` instance you can just `return currentsession().authenticate(...).then(...)` without the need for the `resolve()` call. if the second assertion fails you would otherwise have a `promise` that is never resolved. but also never rejected because `reject()` is not called anywhere.- in the second snippet you're mixing the `done` callback. ember's async `andthen()` helpers and the `promise` returned from the `authenticate()` method. i'd suggest to remove the `done()` and `return` the `authenticate()` result from the `andthen()` function. then it should hopefully work.as this doesn't seem to be an issue with `ember-cli-mocha` itself i'm closing this issue for now.", 'code: ackmocha: 3157 passing (7s)browser: passes: 3129', 'code: ack. i would add a test for a specific message and a specific key. asserting that the result is a specific signature.mocha: 3164 passing (5s)index.html: passes: 3136', 'mocha: 3164 passing (5s)index.html: passes: 3136code review: ack.', 'mocha: 3178 passing (5s)index.html: passes: 3150ack. good work!', "just stumbled upon this same issue.  i have a bunch of contract tests using mocha which submit multiple transactions in rapid succession.  i have to force it to wait 2 seconds between each tx which is frustrating.i agree with checking for pending tx's and then seal again.", 'feat(witharrayvalues): add witharrayvalues and ziparrayvalues. ### summarythis adds `witharrayvalues` and `ziparrayvalues` for mapping values from an array onto a stream.  in the case of `witharrayvalues`. for each event. the stream provides the time component. and the array provides the value component.  similarly for `ziparrayvalues`. except it accepts a function to compute the value component from the array value and incoming event value.### other changes- run flow on the whole test dir.  it will only check files with `flow` at the top. which for now. is only the new `witharrayvalues-test.js`.  but. i like the idea of using unit tests also to check types.  feedback welcome    - note that to do this. i had to give flow visibility into the top-level `node_modules` folder. since lerna is hoisting common dependencies (such as `mocha` and `briancavalier/assert`) to the top level.### todo:- [ ] deprecate `fromarray` and `fromiterable`', 'i really like having the tests type checked :+1:', 'i ran into a similar problem adding parallelism to mocha.  to prevent interleaved reporting. i had to buffer reporting events and replay them ( visionmedia/mocha#849 ).  i also had to run each parallel suite in a domain to make sure uncaught errors were handled by the proper suite.', 'inikulin no. i meant to stop the tests once the first break. exactly like mocha --bail', 'darlanmendonca oh. my bad. `mocha -- bail` fails whole task once there is an error in the test. i guess we can implement it. can you issue separate feature request. please?', 'stop test task on first failed test (`--bail`). ### are you requesting a feature or reporting a bug?feature### what is the current behavior?when a test fail. the process continues. will be good if have a option to stop to dont have an avalanche of test errors. just the first in focus (reference `mocha --bail`)### what is the expected behavior?fails whole task once there is an error in the test. like `mocha --bail`', "it's just a shell script in .git/hooks. with anything you want in it. i don't have the mocha one on this machine", 'thanks for the quick reply. indeed. hooks are just some scripts in `.git/hooks`. however. when i clone this repo. `.git/hooks` only contains some sample hooks. maybe you could add them to this repo?', "hello. i'm the maintainer of grunt-simple-mocha. i'd also like a way to do this via the api.- it seems inconsistent that mocha would allow you to `require` via the cli but not the programmatic interface.- mocha already has such a convenient place to hook into the test runner.- it feels like a hack to put it in the grunt plugin since the required file gets used _within_ the tests.thanks for maintaining mocha and your other work.", 'may i use mocha in this way `mocha --compilers coffee:"coffee-script --map"` to support source map?', '--require option does not work for absolute path value. there is a bug in "\\node_modules\\mocha\\bin_mocha" file. program.on(\'require\'. function(mod){..}); . line 150 - "if (abs) mod = join(cwd. mod);"it should be if (!abs) mod = join(cwd. mod);', "windows has some form of globbing no? i don't really want to butcher mocha just to support posix stuff on windows. there's no end to how many things break on windows", 'some rules in mocha.css seem too broad.. restricting css rules to the mocha container as necessary. should minimize interference with external styles', 'thanks man.', 'adds ability to load external interfaces. this adds support for loading additional interfaces with the `--ui` option. similar to how the `--reporter` option works.after this commit. you should be able use an alternate interface like this:`npm install somemochaui``mocha --ui somemochaui path/to/a/mochatest.js`', "you are right. this is an oversight on my part -- it didn't show up in my testing.  this can be solved by using domains. but then mocha will not run properly in the browser.   my fork of mocha would be node-only. or require explicit passing of the error to done().", "also just ran into an issue where mocha no longer exits with a non zero on test failure. seems to be related to nested runners but haven't dug very deep just yet.", "support node's --debug-brk=1234 syntax to have debugger listen on specif.... ...ic porti like to use a range of ports for each project so i can switch between projects at will without worrying about port conflicts. this is supported by node but was not supported by the mocha wrapper.", 'sorry :( i dont want to go down that road with mocha. "expresso" was fully parallel before and it causes nothing but issues. and in many cases it\'s not any faster. in most of my experience it usually results in slower tests (depending on case of course) due to thrashing of various kinds. consistency and predictability is definitely preferred here over slight performance gains. some people might be interested in a fork though i\'m not sure', "that wouldn't be right either. but i change it to use path.resolve", "arg haha watchers are nothing but trouble. every lib shouldn't be re-inventing / maintaining this sort of thing. i'd propose we get rid of --watch all together and someone writes a proper command-line tool to replace all watchers for all of these tools", 'well. despite my writing this pull request. i pretty much agree with you. could be that guard or watchr are good enough for this case. in which case maybe the best thing really _is_ to remove it and add an alternative to the readme.', 'i\'m having this problem too. wenn i try to start a mocha test in the browser that uses web worker. i get the following error:"error: an attempt was made to break through the security policy of the user agent."this same test works flawlessly in qunit. thanks', "visionmedia i can rebase the pull request. if you'd take a look at it afterwards. sinon.js accepted my web workers pr. and i'd really like to get it in mocha as well. so i can use it in dropbox.js.thanks so much!", "quite a bit to review. might be a while sorry. in general i'm not a huge fan of making big sweeping changes for such a small use-case. personally i'd test the web workers as a black box since it's the messaging that really matters", '+1 here. different enough environment that it needs to be tested individually.', 'why does the test runner need to be executed in the web worker? if your idea is to test code that runs in web workers. you can do message passing?', "closing unless there's a compelling reason to run mocha itself in the workers. it should be fine to test associated components outside of a web worker and then add some acceptance tests for the messages themselves", 'sorry for the late response. i dont want mocha to run inside a web worker. but rather have the tests be able to start worker threads. my code could be tested without workers. but since i do alot of multithreading it would decrease the code coverage quite a bit.', "going to close sorry. i don't have the capacity to maintain so many features for now. i'd like to keep mocha pretty simple and more abstract", "closing for now. i'd prefer to have ~/mocha.opts over env vars at least", 'too obscure', "can we brainstorm a bit about how we can round out mocha's code coverage tools to do suppression of blocks that do not require testing in a way that fits with your vision for the project? because honestly. i'm building large-scale backends with a team. and i'm finding code coverage tests to be a great way to ensure consistent quality. like you. i think 100% coverage is a fallacy and do not wish to waste anyone's time testing cases that just don't need test coverage. but as it stands. without code suppression. our coverage reports would have decreasing value as the size of the source tree increases.", "add a way to hint implementation-files to --watch. currently. `--watch` only re-runs your tests when _the test files themselves_ change. obviously. that's somewhat less than ideal.i'd love to see `--watch` take an optional _argument_. that being a glob of files or directories (other than the tests. which are already listed at the command-line) to subscribe to changes for.example:```mocha --watch source/ --reporter dot --watch test/*.js```", "fyi. i am finding that domains are not adequate to handle all asynchronous errors.  see joyent/node#3908it's frustrating. because i cannot create a simple test case that reproduces the error i get when running a complicated suite.  all the node core methods are fairly fastidious about binding their callbacks to the current domain.  i'm going to investigate using separate processes. but in the meantime. parallelism is better achieved outside of mocha itself.", 'cool! feel free to add a link in the mocha wiki', "you'll need to at least re merge this change.  also. with this change. if i ran `make` wouldn't the calls to `mocha` end up searching the path instead of finding the one in the local project's `bin/`?", "visionmedia  said: > i'm all down for failure tests but i'd definitely prefer to use node so we have some more flexibility with the assertions.hmm... the problem is that we need to cover cases where there are uncaught exceptions.   i guess i can go back to and write this in javascript. but really we don't want that - we want to know what happens when we call mocha from the command line.", 'the grunt-mocha-phantom was built on top of a hack. my vote is we expose using mocha.process.', 'heh. with `grunt test --verbose --force` i end up with```running "mochatest:test" (mochatest) taskverifying property mochatest.test exists in config...okfiles: test/node.coffeeoptions: reporter="spec". require="coffee-script">> mocha exploded!>> error: cannot find module \'underscore\'```', 'mocha generator should point to the right place. link was pointing to generator testing instead of mocha testing', 'good catch. thanks!', 'convert the trace agent to typescript (part 1). this change adds a new `gulp`-based build system for the trace agent. and does a superficial refactor of the code to work with this new build system.i\'ve separated this change into a few commits. each of which should be completely self-contained. i\'d recommend looking at each commit separately (almost all new code is in the first commit). here\'s a description of what each commit does:## `build: add typescript build files`this commit adds `tsconfig.json` and `gulpfile.js`. and amends other files to reflect build system changes.i\'ve written a new set of gulp tasks to exhaustively cover compilation. as well as all the ci functionality we had before:* unit tests (`gulp test`)* coverage reporting for unit tests (`gulp coverage`) (todo(kjin): verify this in ci)* system tests (`gulp system-test`)* linting (`gulp lint`)there are a lot of "helper" tasks -- the general rule being that `x.y` is a helper task for `x`.i also added a `test.single` task. which runs a mocha test in the same process as gulp. this should be useful for debugging.notably. there is a `--dev` flag that compilation-related tasks consume. this relaxes `tsconfig` compilation options. as files receive types in the next pr. this flag will go away.## `refactor: add convert-to-ts`adds a script as described below.## `refactor: run convert-to-ts`this commit is the result of running the `convert-to-ts` helper module. it\'s a purely mechanical operation which:* renames source and test files to have the `.ts` extension* removes `.js` from module requires* adds `export default {}` to the bottom of each renamed file (as `tsc` mistakes them for scripts otherwise)## `src: src changes`this commit sums up the minimum changes in `src` needed to make `gulp compile --dev` compile source files without any errors.## `test: test changes`this commit sums up the minimum changes in `test` needed to make `gulp test --dev` pass all unit tests.## `revert: remove convert-to-ts`this commit does exactly what it describes.', "ofrobots i'm going to move all build stuff out of the `gulpfile` and into a `scripts/` directory. which will get transpiled along with `src` and `test`. `gts` works for tasks such as lint/format checking and cleaning. but there are still things i would like to see as js (ts) scripts. such as installing fixtures.on a semi-related note. `index.ts` and `config.ts` currently reside outside `src`. i'm going to move them in `src`... ofrobots matthewloring let me know if you have any objections.", "i've added/changed some commits:`build: remove gulpfile` added`build: add new build scripts` added (build scripts in ts)`test: test changes` changed (to make `npm run compile` pass without errors)googlecloudplatform/node-team ptal", 'nathanboktae following on from resource loading. is requirejs supported? i seem to have a problem with mocha not being initialised when running from the cli. but working fine in a browser.', 'if the download bugs you. use `mocha-phantomjs-core` yourself directly.', "see nathanboktae/mocha-phantomjs-core#9 for require.js stuff and comment there if you have questions. it should be fine though if you aren't using require.js to load mocha (but even then. you should get a different error.", "ah. the issue is actually nathanboktae/mocha-phantomjs-core#12. sorry about that.but do what it says and call `window.initmochaphantomjs()` before calling `mocha.setup` or other setup functions```window.initmochaphantomjs && window.initmochaphantomjs()mocha.setup('bdd') // or whatever. mocha.ui('tdd'). mocha.slow(). etc etc...```", 'phantomjs terminated with signal sigsegv. when i run "mocha-phantomjs -r dot /test/file.html",it catch "phantomjs terminated with signal sigsegv". what caused this error?', "aroman i just run into the same problem in the past few days. i am using jasmine for my tests. and for some tests i needed mongoose mocked while for others i needed the real thing. here is how i solved it: for the tests that i required mongoose mocked. i did the mocking in the `beforeall()`block and then i cleared the require cache for mongoose in the `afterall()` block. this way. when the next test is coming. mongoose is required again. and it's returned unmocked. like this:```describe('my_test' function() {    var mockgoose = require('mockgoose');    var mongoose;    beforeall(function() {        var mongoose = require('mongoose');        mockgoose(mongoose);    });    afterall(function() {        delete require.cache[require.resolve('mongoose')];    });    it('my first spec'. function() {        ...    });});```", 'is this really necessary? seems like `_.isfunction` and documentation gives you more than doing this kind of strict type checking.', "yeah. i agree with thejameskyle. i don't think we need to pollute our helpers with li'l things like this. gonna close for now. thanks. though. paulovieira!", '> is this really necessary? it is necessary for any property that accepts a class as the value (to have the alternative function-that-returns-a-class form). currently this happens in `collectionview` only. but would be useful for user-defined classes.for people new to backbone/marionette it is not obvious how to do this kind of verification. the previous issues where this subject has been discussed prove it. thus it makes sense to bring this into the codebase. imo.thanks anyway for considering it!', 'just-boris it is not just cucumber. i face same the issue which is reported above in mocha framework also', "anarwal that's true.so. if you have example. how to reproduce this issue using mocha framework. welcome to #29 that issue will be focused on fixing integration with mocha.", 'this should do ```{  "extends": "standard".  "env": {    "mocha": true  }.  "globals": {    "tabulator": true.    "components": true  }.  "rules": {    "array-bracket-spacing": [      "error".      "always"    ].    "camelcase": "off".    "no-unused-vars": "warn"  }}```', "the mocha env part and the warnings about the globals are handled in the standard: globals section of `package.json`.in the case of `testhelper.kb.statementsmatching(undefined. undefined. lit).should.not.be.undefined` considered unused -- which part of it does it complain about being unused? we're widely using chai with standard across most our libs. and hasn't been a problem. to enforcing array spacing. or silencing unused warnings."]