['request to unregister "vero" and "verso". was looking at mocha and accidentally linked it to the wrong repo', "> pmuens i applied that. i've also added --no-exit to mocha setup. as without this. tests program would still be vulnerable to hidden errors issue. more info on that here -> mochajs/mocha#2879very nice! thanks for the updates medikoo !", 'probably what would be worthwhile in the sort-term is a mocha-test262 bridge. to allow mocha to run test262 test cases.  that would let us gradually convert test cases over. instead of having to do it all in one big lump.', '> probably what would be worthwhile in the sort-term is a mocha-test262 bridge. to allow mocha to run test262 test cases. that would let us gradually convert test cases over. instead of having to do it all in one big lump. yes. i am hoping to build something like that because the python console runner we are currently using for test262 is pretty limited.', "adds the ability to run tests. - moves to gulp from grunt. standard for mean- creates `gulp test` that runs mocha on './test` directory- sets `npm test` to run `gulp test`the current tests fail. but this is just meant to allow them to run.", 'looks like you removed the postinstall that installs the server stuff. like express?  admittedly not the best setup ever. but does express etc install now?', "yea. the postinstall got accidentally removed.  i didn't see the scripts section when i first opened the package.json. so made my own. then on some npm operation. probably mongoose. it moved my scripts definition up and on top of the existing one.i wonder what mechanism it is that enforces the order of the config file. anyway. replaced the postinstall.", 'ok. i think this tests coverage is not ready feature. because for better coverage report we need to rewrite tests in some way to use mocha with phantom.js instead of spec/specs.html.', 'added prettify from cdn too.had to update grunt-mocha package to fix npm test command.now the issue is that though every test passes when npm test is ran. spec/specs.html has 1 failing spec: `barsize option svg attributes should set width to options.barsize if possible`.everything else looks good to me :+1:', 'fix nyc/code-coverage testing. do not run sub-context tests under nyc.  nyc uses a separate contex to track code. so tests using a separate context fail under nyc with errors like the following:```1) parallel parallel call in another context:   referenceerror: __cov_glcsdg93mvwqrnbtqi1isfaseto is not defined    at evalmachine.<anonymous>:1:16    at evalmachine.<anonymous>:1:569    at contextifyscript.script.runinnewcontext (vm.js:18:15)    at object.exports.runinnewcontext (vm.js:49:17)    at context.<anonymous> (mocha_test/parallel.js:3:954)```this commit also removes the redundant `&& nyc report` from the end of the npm coverage script (nyc outputs the report by default).fixes #1225', 'use mocha tag for non-browser tests. fix asyncify promisified browser tests. removes browser checks in tests.  fixes asyncify promisified to run in browser (fixes #1235)', 'nice :exclamation:', "dx improvements. ### descriptionas a react ecosystem developer. i want to ensure my hocs work with rhl. right now it is hard to achieve.### actual behaviornothing helps react ecosystem developer to verify that rhl works with hocs they create.### expected behaviori would like to see some few improvements:* in-depth walk through rhl's life-cycle methods to understand how does it work in details* sort of sdk to mimic different rhl's life-cycle methods to ensure hocs works with it the way developers intend to (perhaps rhl-dev).* few recipes of sdk usage with different popular libraries and test runners (react-redux. react-intl. etc and mocha. ava. etc)", 'gaearon i agree. now that the project is stable. we have to make it cleaner. and to do it we have to make changes in react.', "does the project currently add any custom hooks to components beyond the react api? i noticed something called `componentdidrender` and wasn't sure what that is.", "just after writing down how it works. i've point a few moments which may no longer work as i expect. or should work differently.", 'thekashey thanks for this', "i'm also having this issue - i've tried multiple variations of setting mocha as the test runner in `nightwatch.json`. but it just hangs in the same way as described above.", 'add test task with watch option. writing tests often requires them to be run multiple times before they pass. it can be a hassle switching focus back and forth between your editor/ide (to write code) and terminal (to init test task). by running this npm task the mocha instance will watch for changes in files and automatically re-run the test task. saving you time and energy.it is run like `npm run test:watch`.', 'simeg really nice this feature. thanks!', 'code block empty. hi there!i love the report :100: . but one of its really useful features. "show code". doesn\'t work in my project.i think it might be related to the fact i\'m using `gulp-mocha` and not `mocha` directly.would you have any idea?', 'can you elaborate on this? what do you mean by "doesn\'t work"? i assume you mean that you are not seeing your source code and instead seeing an empty box. the report generates a json file which is used to render the html. if you look at the json each test should have a `code` property. do you see your code in there?what leads you to think it could be related to `gulp-mocha` vs `mocha`? if you can provide some example of your usage i can better try to help.', "sure. thanks for taking the time.the `code` attribute is an empty string for each test.i have no complete understanding of how the `gulp` streaming process works. but i wonder if the fact that it's streaming content and not writing files on disk might be the reason `mochawesome` can't extract the code.", "i've successfully tested mochawesome running against `mocha`. `gulp-mocha` and `gulp-spawn-mocha`. i don't believe that would be the issue. without seeing some of your test code and setup i can't really diagnose this.", "i'm sorry i didn't follow up on this issue lately. thanks for the quick fix adamgruber !", 'fwiw. here is a simplified fragment of my mocha test. with the expect statement that fails:```// update that uses replaced_component in the update argumentvar mongoose_query = this.model.update(conditions. update);mongoose_query.lean().exec().then(    function(updated_part) => {        var component_after_update = updated_part.components[0];        expect(component).to.deep.equal(replaced_component);```', 'increase timeout for mocha tests because sometimes tests fail on travis .... ...due to taking too long', 'the problem is some closing logic routine in levelup. you are not supposed to close the database within an event generated by a readstream.in the tests. you can solve it by closing the db in the aftereach mocha  thing.', "no. `t.fail(msg)` just prints a failing assertion.  (it's the inverse of `t.pass(message)`.)> it is not a very intuitive limitation that you need to manually end the test inside a synchronous function; that is not how other libs like ava workwell. that's not how _ava_ works.  most other test frameworks in node.js either sniff the test function to see if it takes an argument (ie. mocha and lab) and if so. pass in a `done` callback. or (tap. tape. and a few others) provide an object that has to be manually ended. or don't really support asynchrony with callbacks or objects at all (mostly very old test runners. like nodeunit and a few others). so every test has to be 100% synchronous.automatically ending tests with sync functions would be a _huge_ change in tap.  there's a massive number of tests out there that do things like:```jst.test('foo'. t => {  getsomefoo(a. b. c. (er. data) => {    if (er)      throw er    t.match(data.  {some: 'thing'})    t.end()  })})```those tests would auto-end and cause a lot of problems if i did what you're suggesting.  ava started life by doing `t.test.cb(..)` for that use case. but tap follows a different pattern.", 'mikermcneil if have finished implementing this (with backward-compatibility) und mocha-test for skipper run without a error. i updated skipper (in a fork) and also skipper-disk. should i send you all together as a zip or make 2 prs? i worry that its difficulty to understand if you dont have both changes together.', "securingsincity i've added some mocha test for debounce function & props. let me know if there is anything else", "the ci build failed. that's quite strange :-(  the test passed on my machine.and the details of the ci building process showed that the failure occurred in the plugin `gulp-mocha`. anybody could help me? thanks.", '> the changes however would have to go into ember-mocha itself nowthat is correct. due to this i will close this pr. but feel free to reopen on the other repo.', 'slothbag have you successfully removed your delay in between transactions for unit tests? i too am using mocha and i have to have a delay or parity cannot take the test load. causing the time to fall behind in solidity and generally. intermittent transaction failures.', 'trigger tests from an html file by opening it in a browser. is it possible to include `wd` in a browser and run the tests by opening a web page. kind of like how mocha can be triggered from a browser. i put the following code alongwith my test case js file and it executes them in a browser. i was wondering if i can also include wd\'s js file below.```<script src="mocha.js"></script><script>   mocha.setup(\'bdd\')   mocha.run();</script>```the advantage is that i can easily include my existing libraries in the browser & use them for unit/functional testing (all of which aren\'t compatible with node.js environment).', "it's not designed for that. maybe you can try [browserify]().", "that was the first thing i tried. i'm using jquery. jqueryui. bootstrap and other plugins which aren't easy to browserify without a lot of 'not so elegant' glue code. i'm closing this though.", 'um? bump? :+1:', 'store a reference to settimeout when loading mocha adapter. fixes a problem where the test execution hangs. if a test helper (e.g.sinon.usefaketimers). has swapped out the global timeout function.', "chrisopedia can you provide a bit more context for what you're trying to achieve? `gulp-mocha` requires a .js file passed directly to it. so true works by setting up your tests in that js file and then running it with mocha. as far as i'm aware. there isn't a good way to combine it such that the sass files are run through true directly from the gulpfile.", "> so i've come around to the idea that tap is a terrible format and you need some kind of json object format.tap is a human-readable format. json isn't. it's a good reason to use tap.", "it doesn't need to be readable. it just needs to be an intermediate data format. which json is very good at. no reason to use tap for this", "well okay. i'm mostly concerned about interoperability with `node-tap`. since i'm trying to maintain npm fork and stuck with its tests for the time being (at least output can be changed...).anyway. what information does mocha provide that isn't supported by tap? pending tests? duration? hmm... maybe you're right. *starting to read tap spec*", "in your ci. add a step that greps for onlys before your tests run. this doesn't need to be in mocha.", 'allow `--compilers` to specify plugins without an extension. i\'m creating a little module that adds syntactic sugar to test declarations. defining test levels ("smoke". "full" etc) inline in the code. and skips with reasons (broken. todo. etc).one nice way to load this would be to use the existing `--compilers` flag in mocha.i can specify `--compilers=:mymodule` and it works great. but it appends that empty string to the regex pattern of extensions to look for.i could put a bogus extension in there like `--compilers=zzz:mymodule`. but that seems silly.using `--compilers=plugin` to load plugins between mocha and test files seems like a nice elegant solution.thank you for considering this pr and for all your great work on mocha.', 'when in node space. using json is the sane thing to do.', "i just noticed #1102 and for obvious reasons the two would conflict as written now. i didn't really consider that anyone would want to use xunit from within the browser. so my patch will obviously only work on node.js.if this is something mocha needs to support. then it would be trivial to incorporate the meat of #1102 into this pr. but before putting any more time into this. i'd like to see some indication as to what its fate will be.are there any concerns that are blocking you from merging it?", "sorry. i think it's major overkill. mocha is bloated enough as-is. if there was a lot more interest then perhaps it would be worth the maintenance burden.", "can't you just use the `--require` option?", 'easy. already implemented:```describe("conditional suite". function() {  this.pending = shouldthisbepending(); // true or false  it("is a pending test conditionally". function() {    throw "this test failed";  });});```', "you need to get whatever dir the files are in and replace kirby with that. in any case. this isn't a mocha issue.", 'slashgrin it looks like #1106 also switches from `console.log` to `process.stdout.write` as a side effect. does it work for you?', "with --watch. the process exits on compiler errors. using `mocha --watch --compilers coffee:coffee-script/register`. if you save a syntax error at any point while you're working on your code. the mocha process exits. which is annoying. it would be nice if mocha could catch compiler errors. print them out and then continue watching.", "i installed mocha locally but then even i get 'mocha' command not found stderror. whereas if i install it using 'npm -g' then it works.", 'add to reporter mocha instance to get access to original options. i am writing reporter and i need to get access to original options (colors. files and diff) and i am not using base reporter. base reporter also does not contain file list.', 'sorry for bothering. travisjeffery. is it ok?', "there'd be less coupling if instead of passing the mocha instance we passed an options object", "travisjeffery or visionmedia: any comments on the fate of this or #897? i'd really like to be able to get us off of our private fork. this would also seem to address the gist of #469 .", '+1 big time - would love this feature', "filename in test object would be quite useful - imagine a large project with thousands of tests. how do you know. from looking at the name of the test suite. which file contains the one that failed?  it may not always be intuitive especially when projects get large with many people working on them.  if the test is asynchronous. the stack trace might not contain the test filename.it would also be very useful for tooling. for example some tools. when a test fails. lets you click on the failed test to take you to that test.  without a test name. it can't implement this.", 'jroper :( write little modules and build apps with those!', "i am in the process of making detox work on travis.i constantly get `referenceerror: device is not defined`. like 1 in 10 gets through.i have got that error locally as well. maybe because i'm using jest but not mocha.", 'i migrated my tests to use **mocha** and i found that mocha works perfectly. this an expected behavior?', "hmm. simply replacing `mocha` with `electron-mocha` didn't solve the issue in test.", "mocha pokazyvala razlichaiushchiesia kuski ob'ektov", 'increase mocha test timeout. as the mocha tests on appveyor failed on many pull requests because of timeouts i increased the timeout for the `mochatest` to 5 seconds.', 'increase mochatest timeout to 5s. as the mocha tests on appveyor failed on many pull requests because of timeouts i increased the timeout for the mochatest to 5 seconds.', 'thanks!', "> btw. don't use --silent - that was a bad idea as it would break usual ui with promptscan you elaborate?> better implement a global flag like yeoman_muteyou mean env variable?", "i don't like the `--silent` as it cannot be useful for end users.so we'd need either an env variable - or a global. imo. a global is allright and less error prone (no chances someone mute all his yeoman generators by error).", "sboudrias from what i can remember from the last meeting. you too don't want globals and it should rather be built into the interface or something. can you expand on that?", 'there was a suggestion for `this.mute()` kind of implementation.', "yeah. it might be less error prone to call `this.mute()` and `this.unmute()` method on the generator (or the ui adapter) to manage the mute state.this is more secure as we're sure that no dependency author that we use will one day push an update setting `global.yeoman_mute = true;`.the problem with using a `mute` method though is that it is sometime hard to get a hold of the generator instance as it is almost always used through the environment facade. but it is definitively doable - and should be eventually integrated in the `run-context` testing facade.---anoter solution. maybe we could allow user to provide a stream to write to. so then. you just need to pass a mute stream - but that'd allow you to assert stuff against the outputted string buffer on the dummy stream...", 'sboudrias as this issue speaks specifically for testing. should we start pawing at `run-context` first?', 'hemanth it is about testing. but it relate mostly to the ui adapter module. this is where the work should be done first.', 'sboudrias was wondering the same.', "> anoter solution. maybe we could allow user to provide a stream to write to. so then. you just need to pass a mute stream - but that'd allow you to assert stuff against the outputted string buffer on the dummy stream...i like this.", ">  this project was more an experiment in how it> could work together.don't speak on behalfof this project if your not a contributor. because that is not true at all.`mocha-phantomjs-core` has been supporting phantomjs 2 for a year now and sliders as of recently. the gulp and grunt plugins got switched over too.long term plans are to incorporate the client functionality into core which will then eclipse this project.`mocha-phantomjs` is simpler to setup than karma and gives you full control over the test runner html. but if you want to test other browsers beyond firefox and phantomjs. go with karma.", 'nathanboktae does that mean this issue doesn\'t need to stay open anymore?as for my particular usecase. one of our files used es6 syntax functions. i.e.:```...  render() { // should have been "render: function() {" for phantom    ...  }....```but mocha-phantom was only able to state the syntaxerror. not in which file it found it. or the line of code that triggered it; if that\'s a fixable thing that\'s probably worth fixing.', 'i\'m using fixable loosely - seeing the line in question and the file it was signalled in is just as good of course. the problem i had was seeing the equivalent of "something went wrong" without any additional information. so if phantom generates more data (file+line number for instance) but mocha-phantom right now doesn\'t proxy that to the console. that would be quite valueable to fix', 'wait for event loop to drain. resolves #889 copied documentation and interface from', '`"test": "mocha --compilers js:babel-register"` works fine so maybe ignore/exclude is still broken', 'i am considering this feature as "pull-requests are welcome".to be honest. at my work i am mostly using `allure-mocha` package and its api. so i don\'t have a clear vision. how this api should look like.if anybody wants to have this feature. do not hesitate to submit any code. that shows your expected result. i will help to make the code working.']