['seems like it was completely unrelated; just a mixup of the new ipc module names. fixed by #32 above.', 'going to pass on this now. may reconsider later. thanks for your interest.', "if it works. i'll accept it into `electron-mocha`.", "15 seconds is a looooong time! the tests run super fast for me when run locally on my mac or windows machines. on vagrant they take a lot longer. i think it's all to do with the environment and load. travis fails a lot some times and then is fine other times.we do have to run all of the tests in travis. but we could still split out the db-reliant tests from everything else in terms of folder structure and 2 different tasks. it would provide some benefits in terms of clarity - that it is an integration test timing out not a unit test etc. and making running the tests when dev'ing easier.can certainly be a separate issue to this one though - i'm gonna merge this :)", "deedubs looks like a solid option.i also know that endangeredmassa has a project he's been working on that _as i recall_ allows you to use mocha-style syntax on top of selenium. but execute your tests in a synchronous fashion. since i think the majority of our issues are due to time outs. synchronous functional testing might be a dream come true for us. that's not to mention the fact that our unit tests are done in mocha as well.all in all the easier it is to write and maintain the functional tests the better. we may need to evaluate several options before we can really resolve this.", "there is also a library that allows for using mocha and should style syntax with casperjs.i'm in two minds - one the one hand using webdriverjs would open up some more possibilities for us. it's more mature and works with things like appium. on the other hand. i really love the casperjs project. and want to support it - plus it has such an epic name ;). perhaps it would be worth asking n1k0 to wade in here and see if he can point out any ways we're using casperjs incorrectly?i don't think it's the framework that's necessarily at fault in the problem i reported. just a test which is intermittently failing in various ways. and i think we'll get that with any js test framework.", "robconery i know who you are. i'm a big fan of this developers life and your [presentation laced with daft punk and mocha]( is what turned me on to being a node developer after 7 years of c#.  :beer:but. let's be clear. it's not _us_ making a requirement that people do something extra. that's azure.  also. if people don't want to make a web.config. they can make a single line server.js like you did.  i don't think that's an internal detail for us. it's a very specific hosting platforms oddity.i feel like this is a slippery slope; a server.js here. a procfile over here. a shinynewplatform.bison over here.  why should hosting platforms dictate what code goes in our repo?", 'add mocha do devdeps. currently missing. `npm test` errors post fresh install', 'also add `chai` to devdeps. and `jsdoc`.', 'fixed. closing.', '+1', 'here is another option... i use nodemon. this ensures that the process is restarted each time the test runs:$ nodemon --exec "mocha -r min" test', "focused specs. is it possible to run one spec only? i had a look at the docs but didn't find any info about it. `jasmine` has a concept of focused specs `fit`. mocha provides an `only` method. i like tap much and such feature would make my work easier in some cases.i can have a look at it and create a pr if it's in scope of the project.", '> correct test starter to return appropriate exit codesorry. but your code doesn\'t do this. instead. you set an environment to be `testres=mocha` and run `-r list --ui exports ./tests.js ./no_proxy.js` command which would fail of course.> however yapm test run freaks out unnecessarily given that it\'s a testwhat do you mean by "freaks out"?', 'so we dont stringify error objects. thats just overriding tostring because for some reason mocha wasnt being nice about printing them. checking .error === true should always work for detecting errorswe changed our errors to be more javascript compatible than identical to couchdb. being identical to couch isnt a goal in itself. just being able to make sure users get compatable errors when using couchdb as a backend or idb etc', 'also. when you run tests. why does glob run twice?? mine only runs once:```192:node-fsplusgit nkallen$ mocha -g glob  .  1 passing (197ms)```', '(would probably be good to. at some point. implement a similar helper for ember-cli-mocha)', "the instructions 404'd :-(", "ok. i added the registry hack:```  aftereach(() => {    // tear down    application.registry.unregister('session:main');    application.registry.unregister('session-store:test');    destroyapp(application);    server.shutdown();  });```but. now i'm also getting the ```typeerror: app.testhelpers.wait is not a function```problem.:-(does this mean that the test helpers aren't being loaded properly?i think there is something funky with acceptance testing and mocha right now. :-\\any ideas?", "i'm just running mocha with  test/local/window-frame-test.js and i'm seeing the window sizing tests pass on chrome and firefox.on mar 1. 2013. at 9:48 am. meanwhilemedia notificationsgithub.com wrote:> jlipps. can you tell me what browser you were using when the tests were passing?> > --> reply to this email directly or view it on github.", 'any updates? stoked to be able to use this from mocha.js without the separate library.', 'add `var` to definition of `process` variable in browser environment.. i use global `process` variable in browser (to provide environment similar to node.js). but mocha overrides it with `process = {};` statement.maybe it should be changed to `var process = {};` ?', 'we can just do a typeof and leave it otherwise', "fix leak of listeners for process. when i run `mocha --watch` and after 11th running. the following message wasshown:```(node) warning: possible eventemitter memory leak detected. 11 listenersadded. use emitter.setmaxlisteners() to increase limit.```it seems that 'uncaughtexception' listener is not released.because. the listener to be released is different from listened one.to fix this issue. i gave the same listener to `process.on` and`process.removelistener`.", 'i think this is not related to `mocha` project.', 'lol. this is for the ruby "mocha" mocking/stub library', 'why not use directory globs?```mocha test/**/*.js```', 'mocha runs only once in the browser. calling mocha.run() again after running tests has finished has no effect.being able to run tests multiple times without refreshing the page would beuseful for me for adding some input fields in my testing page that must beset by the user of the tests (for testing file upload). i need to run the testsagain after setting these since i want to always run the tests. when page isloaded anyway.', "we would need some kind of cleanup event for browser reporters. it's not something i personally want but im not against it at all unless it bloats things a lot (it should be fine)", 'allow directories to be passed to bin/mocha.. when i started using mocha today. i was confused by the fact that running `mocha spec` (my specs are in a folder called "spec") threw an exception right away. after digging into what it was doing. i discovered that the cli assumes that all non-option arguments are files.this patch updates the file list parsing and generation code in the cli to allow both files and directories as arguments to `mocha`. it also reuses the same functionality to default to a "test" folder if no non-option arguments are supplied. just as it does now.i also added some more user-friendly error messages when attempting to run mocha against a non-existent directory.', "-1 from me. i like the simplicity of files only - it's easy to glob what you need. and changes like this open the doors for recursive support and weird grepping. the shell does this stuff for us", 'windows also does not expand globs. fwiw. this makes writing cross-platform `npm test` scripts with mocha difficult; you need to create some kind of `runtests.js` file that does the globbing. then programmatically runs mocha against the results. and pipes the output (and thus. on windows. loses the colors). it would be great to get this built in.', "that's something wrong with backbone or your jquery usage. mocha doesn't touch a single thing in jquery. as far as jquery's api for cors stuff i have no clue", 'ah boo windows :(', "even with windows that's still something `glob` could/should/probably does handle. but i'll think about it", "right glob is definitely necessary but it's just a question of whether mocha will use glob or i'll have to write a custom `runtests.js` that delegates to glob and then to mocha.", 'it would be awkward for mocha to support it ootb imo. `mocha "test/*.js"` instead of just `mocha test/*.js` etc. so we would need `mocha --glob "test/*.js"` or something but that\'s kinda lame', 'hmm yeah i see the problem. you could do hacks like "if filename contains a `*` then we must be on windows/posix with glob expansion turned off" but yeah. icky.', 'i think isaac\'s glob module supports brace expansion as well so that\'s another edge-case. not that people name files "foo{bar}.js" etc haha. but i dont want to run glob on every argument', "> after further investigation. though. i kind of feel like this is more a problem with node's child_process rather than mocha. +1. the whole `child_process` cross-platform clusterfuck leaves me confused and hurt on a daily basis. (semi-related: isaacs/npm#2479)", "node's exec() is a `sh -c`. spawn() just passes the executable to execvp so that's why you get shell features there", "walking dirs now. i dont think it's elegant to do this but meh 282ed72", 'now you can do your `mocha spec` instead of `mocha spec/*`. or `mocha --recursive spec`', 'thank you :). your faithful windows users appreciate it.', "i tried using mocha --debug-brk test.js and i could connect via node-inspector but my test script files did not show up in chromes debugger.anyone else have this issue?p.s. i'm on windows", "only object gets extended when running `'mocha --require should'`. global variable 'should' does not get exposed. if you want that. you should add:``` javascriptvar should = require('should');```", "you can do this instead (coffeescript):``` coffeescript    # test setup    mocha.setup      ui: 'bdd'      globals: [ 'jade' ]```", 'you could just setup a helper function that does all your setup. and then call it inside your test. this way. you explicitely test your setup. and it would be included in the time measurements.', 'feature request: complete output of mocha using ant. i\'m using ant on a ci server to run all my tests using mocha. unfortunately. the output while executing mocha is incomplete. indeed. when all tests complete. we only see "......" and nothing more. also. when a test fails. the output using ant is :....oPSu 1 of 7 tests failed:...it would be nice to see the complete output of mocha like when we call "mocha test" if it\'s possible.maybe i\'m doing something wrong and if it\'s the case. please let me know how i can do this.thank you very much!', "im not sure what ant does internally. it's just regular stdio though i dont see how they could mess that up. maybe they're not reporting stderr? :s", 'it looks like this problem is only under windows. because i resolve my problem. i close this issue.thanks for the clue!', '+1 from meemilecantin: well. that makes the beforeeach function obsolete ;)', 'andihit: not really. before / beforeeach is for setup that is outside of the scope of your test case. it aims to provide an environment in which you can then run your test. if your setup is relevant to the success / failure / performance of your test. then it belongs in the test...', '> if your setup is relevant to the success / failure / performance of your test. then it belongs in the test...in what case is the setup not relevant for the success/failure of the test?> typically i put the most time intensive stuff in my beforeeach (setting up the fixture. dom. whatever)> and then run my assertions against that which takes virtually no time by comparison.same here ;)', "> in what case is the setup not relevant for the success/failure of the test?for example. when i am testing an object's methods. the instantiation of said object is not relevant; it's not what i test. instantiation is part of another. unrelated test.", "technically it **is** relevant that your object is initialized when you test methods of it.but i get what you mean. it's not what you test in a particular test.maybe we want a second badge of each test which shows the duration of the beforeeach (and aftereach)? or show detailed information on hover (before. beforeeach. test. aftereach. after durations)?", "i think detailed information on hover would be a nice addition. while i don't think beforeeach / aftereach timings shouldn't be included in the test's timings. there's no reason to not measure it. on the command line. we could add a '--detailed' flag. or an alternate reporter.", "emilecantin yeah i agree. i think a reporter would be the cleanest route. _dot_ and some of the others wouldn't really work. or maybe just a `--verbose` variant of _spec_ and _list_", 'different behavior on osx and linux. on my linux box when i execute this code in a mocha test:  browser.visit(":3000". function(err. browser) {          $ = browser.window.$;          networkcontroller = browser.window.requirejs(\'networkcontroller\');browser.window.$ and browser.window.requirejs are defined. on osx they are not. on osx only the initial html page seems to be downloaded. none of the javascript on that page is. is there something different about zombie on osx i need to be aware of?', 'update: false alarm i reinstalled zombie via npm and it is working now.', "if you have mocha installed you should be able to just do 'mocha' from the project root", 'hey wangmzdl i just ran the tests that are present in this repo. it seem to run correctly. did you write a new test? as the .connect() function does not have "config". this was a test for the constructor.', "what kind of updates are you looking for? no mocha-phantomjs doesn't have an option to dump a screenshot on failure or anytime currently.pull requests are welcome.", 'i have no setup yet actually. i am just trying to figure out a good way to get all the features that i need from phantomjs.', "ast-like ouput for custom formatters. the default format of the test output is great. but it would be awesome to have something like json or tap output so that the community can create custom formatters (like mocha's dot or spec  outputs).i wanted to open the conversation to see what some ideas could be.", "you know what. this isn't an issue and belongs on the mailing list instead.i'll close and put there if it needs to be.", "thanks for the feedback bootstraponline. i'll look into a mocha test for this feature. good opportunity for me to familiarize myself with the test suite.", 'the strange thing is that the module is already there```jimb:jima jima$ ls -al node_modules/total 0drwxr-xr-x  12 jima  staff  408 30 may 08:19 .drwxr-xr-x  10 jima  staff  340 30 may 09:02 ..drwxr-xr-x   4 jima  staff  136 30 may 08:19 .bindrwxr-xr-x  11 jima  staff  374 30 may 08:19 clean-css-brunchdrwxr-xr-x  11 jima  staff  374 30 may 08:19 coffee-script-brunchdrwxr-xr-x  11 jima  staff  374 30 may 08:19 css-brunchdrwxr-xr-x   7 jima  staff  238 30 may 08:19 expect.jsdrwxr-xr-x  11 jima  staff  374 30 may 08:19 handlebars-brunchdrwxr-xr-x  11 jima  staff  374 30 may 08:19 javascript-brunchdrwxr-xr-x  19 jima  staff  646 30 may 08:19 mochadrwxr-xr-x  11 jima  staff  374 30 may 08:19 stylus-brunchdrwxr-xr-x   9 jima  staff  306 30 may 08:19 uglify-js-brunch```', "the cli runner with jsdom test environment is working now. see paulmillr/brunch-with-chaplin#10actually i'm using the mocha api. because i've found no way to defer the execution of the tests until jsdom env is loaded (except modifying mocha's `--require` option)", "added 'brunch test' command. finally. the `brunch test` command is here ;)it may need some polish though:- i got a strange bug when calling `watch()` directly (the process exited and didn't wait for callbacks). so i call `brunch build` now with a child process (not very nice)- hardcoded `javascripts/tests.js` path- i modified `generatedfile` to append `this.require('test/initialize');` at the end of the tests.js fileand as an enhancement allow custom mocha reporters and interfaces. but that will be easy to implement", 'looks cool. thanks', "> i modified generatedfile to append this.require('test/initialize'); at the end of the tests.js filewhy is this needed? doesn't requiring stuff in `run-tests.html` work?", "what does the `persistent` option do?i thought that's the parameter to tell the watcher to keep watching (`brunch watch`) or. if set to `false`. to stop after one compile (`brunch build`)", "andihit oh. i see. you're not using chokidar directly.does `brunch.watch(configpath. callback)` work for you?**edit**: `brunch.watch({configpath: ...}. callback)`", "`persistent` isn't needed because it's binded to `watch` function in `commands/index.coffee`.", "i'm requiring `./watch.coffee` directly. because `commands/index.coffee` requires `test.coffee`. and i guess that would be a circular reference. so i got no `.bind()` magicbut i still don't get this `persistent` param. because in `index.coffee` it's bound to `no` on `build` - but then i get this bug. with persistent = yes it works.", "got it. hope this won't break things. thanks.", "the `generatedfile` thing: mocha's api exposes a function called `addfile` which i pass the `tests.js` file. and this file should expose tests. i don't think there is a way to pass code instead of files to mocha.passing a new file with just this `this.require('test/initialize')` won't work either because it has no reference to the `tests.js` file.", "test coverage report. a test coverage report would be great (mocha supports this)i guess a coverage report for app.js will be easy to implement. but then we 'll have just one single file in the report.to display multiple files. we have to- create seperate .js files. run jscov over them. concat  or- run jscov on app.js and change the filename of the coverage counting code  or- add our own coverage code... any ideas?", "yes> run jscov on app.js and change the filename of the coverage counting codeyes.creating separate js files is a mess. it's easier for debugging. but only until we'll support source maps. it sucks it all other ways.", "ok.well. i just looked at the generated jscoverage output - it's a bit more to do ;-)- change line numbers as well- split up source (source code gets stored inside the global `_$jscoverage` variable)probably it 's better to jscoverage each single file before brunch does the concenating. but jscoverage only accepts source-dir and destination-dir as parameters... this will be hacky (create temp files etc).another issue here: we 're showing the coverage of the javascript. not coffeescript.", "> but jscoverage only accepts source-dir and destination-dir as parametersthat's the design flaw of jscov. i think we should open an issue for this in jscov bugtracker.", "yea. also we'll need to add mocha support there. ain't we?", "remove jsdom from the dependencies list. if a user runs `brunch test`. check if jsdom is installed. and if not. show a notice to install it with `npm install -g jsdom`. and if it's a windows user. show note about ms vs and python dependency.> i propose `test-helper.coffee`yes. this is fine too ;) it will be the same as mocha's `--require` option", "+1 for this feature. also it would be pretty cool if calling `require('6to5/register')` would respect these files if no argument is specified. i.e. not if i write: `require('6to5/register')({...})`. this would allow easy integration with e.g. mocha", 'make removal of extension in default formatter optional/configurable. hi.i have (mocha) specs which have the same filename as the subject under test and only another extension. example: subject.js and subject.spec.js. since the amd and the system formatter inherit from the default formatter all file extensions are removed. this results in duplicate module ids. how about making the removal of the file extension or configurable? so that either i have module ids matching the filenames or that just the last "extension" is removed.thanks', '+1.  mocha use case', ':+1:', 'i really don\'t like worrying about the various entry points to my application (node? browserify? mocha? nodemon? general fiddling around in the repl? etc) so i compile all my files in a build step and prepend `"use strict"; require(\'my/polyfill\')` to each of the compiled files. module caching ensures we don\'t setup more than once.this strategy is especially nice if you decide to switch out `6to5/polyfill` for something else. or if you need to use non-default transpiler options. for example. i prefer to use bluebird instead of the core.js promise shim.with this setup you\'d test your application like you would any other mocha application.']