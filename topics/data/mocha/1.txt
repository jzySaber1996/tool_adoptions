['also with latest mocha you can return promise instead of calling `done`', "debugging no longer has access to to full dev tools. debugging is great in electron-mocha with `--debug-brk` flag. with the #82 fix though. you lose some of this functionality. you can still set break points and step through the code. but since the window isn't focusable. you lack the ability to interact with the running code via the console. which is very helpful at times.does it seem reasonable that. if you are running in debug mode. you'd want electron-mocha to steal focus? would it be amenable if we set the window properties conditionally on the flag? if so. i can make a pull request with the change.", "yes. i think that's fine... i mean. if you want to use the debugger. you want to focus the window obviously.", 'debugging unit tests. please provide better documentation on how electron-mocha unit tests can be debugged. right now it is completely non-obvious.', 'debugging main process. should the electron-mocha launch a debugger by default when debugging the main process?debugging the renderer process works fine. but when i try to debug the main process electron-mocha just seems to hang at the first breakpoint. how can i see/launch the debugger?', "html files. like mocha-phantomjs?. phantomjs' entry point is an html file. unlike electron. so i can understand why there is either no support or no mention of support for using an html file as an entry point with this module. however. the nice thing about [mocha-phantomjs]( doing so is that we can also run those tests in real browsers.", 'fix exception tests in mocha', 'i think it would be better if this pr added mocha tests that create battles in which immunities are involved to see if the immunity results are those we expect.', "just as fyi for the next dev who comes along this. it appears there is work going to add a `--order random` option to mocha (mochajs/mocha#902). then you could just add that into your `npm test` command. (i was kind of surprised that wasn't already in there.)", 'fix very small bug with pluginmanager tests.. ## what did you implement:a super small bugfix. the \'test\' code actually always runs. since describe blocks are always executed. so for example if you did `mocha test -g "..."` even if it does not match this test. the test still runs. mocha also doesn\'t treat it as a test failure but rather it interferes with the entire test run.## how did you implement it:i changed a single word.## how can we verify it:run `npm test`. still works :d## todos:- [x] write tests- [x] write documentation- [x] fix linting errors- [x] make sure code coverage hasn\'t dropped- [x] provide verification config/commands/resources- [x] leave a comment that this is ready for review once you\'ve finished the implementation', 'this is ready for review.', 'thanks!', "replace spectron with puppeteer. spectron (webdriverio) fails often while ci with no obvious reason. also. it can't simulate hotkeys. let's move our functional tests to puppeteer.we can't test desktop ide features with puppeteer. but among them. we only test fs interaction. let's preserve these tests but move them from functional to integrational category and simply use `mocha-electron` for them without simulating full ide launch.### how to implement- move universal `func-test`'s from `xod-client-electron` to `xod-client`. rewrite them with puppeteer.- move fs-related `func-test`'s in `xod-client-electron` to `test`. rewrite them to `mocha-electron`", 'fwiw. that warning seems to come from mocha. not domino.', "for those who don't have `make`. i wrote a simple batch file to run the tests:``` batchecho offsetlocalset mocha_opts=--check-leaksset reporter=dotset node_env=testcall node_modules\\.bin\\mocha --reporter %reporter% %mocha_opts%call node_modules\\.bin\\mocha --reporter %reporter% %mocha_opts% test/acceptanceendlocal```", 'this is interesting: i\'ve got some mocha tests running with babel but that _requires_ the `.babelrc` entry for presets. `mocha --compilers js:babel-register tests/`with that `.babelrc` file present (and like others. it\'s just the one entry for "es2015"). mocha runs its tests fine. but webpack fails. without the `.babelrc` file. webpack runs but mocha fails. facepalm.', 'nice!  +5', "fix intermitent failures in windows ci tests. we are observing intermittent failures in our windows ci tests. it's likely that this demonstrates actual race conditions in the node_redis client:``` sh 1) the node_redis client using options: detect_buffers: true;  using javascript and ipv4 unref exits subprocess as soon as final command is processed:     error: unref subprocess timed out      at error (native)      at null._ontimeout (c:\\projects\\node-redis\\test\\node_redis.spec.js:423:37)  2) the node_redis client using options: detect_buffers: true;  using javascript and ipv4 socket_nodelay true fires client.on('ready'):     uncaught assertionerror: null === 0      at childprocess.<anonymous> (c:\\projects\\node-redis\\test\\node_redis.spec.js:428:32)      at maybeclose (child_process.js:1015:16)      at process.childprocess._handle.onexit (child_process.js:1087:5)`````` sh  1) publish/subscribe using options:  using javascript and ipv4 subscribe handles sub_unsub_msg_sub:     typeerror: cannot read property '0' of undefined      at context.module.exports.serverversionatleast (c:\\projects\\node-redis\\test\\helper.js:99:24)      at context.<anonymous> (c:\\projects\\node-redis\\test\\pubsub.spec.js:139:59)      at callfnasync (c:\\projects\\node-redis\\node_modules\\mocha\\lib\\runnable.js:306:8)      at test.runnable.run (c:\\projects\\node-redis\\node_modules\\mocha\\lib\\runnable.js:261:7)      at runner.runtest (c:\\projects\\node-redis\\node_modules\\mocha\\lib\\runner.js:421:10)      at c:\\projects\\node-redis\\node_modules\\mocha\\lib\\runner.js:528:12      at next (c:\\projects\\node-redis\\node_modules\\mocha\\lib\\runner.js:341:14)      at c:\\projects\\node-redis\\node_modules\\mocha\\lib\\runner.js:351:7      at next (c:\\projects\\node-redis\\node_modules\\mocha\\lib\\runner.js:283:14)      at immediate._onimmediate (c:\\projects\\node-redis\\node_modules\\mocha\\lib\\runner.js:319:5)`````` sh  1) the node_redis client using options:  using javascript and ipv4 when connected when redis closes unexpectedly monitor monitors commands on all other redis clients:     error: redis connection gone from close event.      at redisclient.connection_gone (c:\\projects\\node-redis\\index.js:9:25044)      at socket.<anonymous> (c:\\projects\\node-redis\\index.js:9:5432)      at tcp.close (net.js:485:12)`````` sh1) the node_redis client using options: detect_buffers: true;  using javascript and ipv4 when connected when redis closes unexpectedly monitor monitors commands on all other redis clients:     error: redis connection gone from close event.      at redisclient.connection_gone (c:\\projects\\node-redis\\index.js:9:25044)      at socket.<anonymous> (c:\\projects\\node-redis\\index.js:9:5432)      at tcp._onclose (net.js:469:12)```we should put some time into squashing these bugs. since they are likely demonstrating real issues with the client that appear more easily in a windows environment.cc: brycebaril bridgear mranney erinspice blainsmith", "essentially yes. just in the reporting behavior. i'm thinking of how i run tests with mocha or rspec. and plan out new behavior with pending tests.", 'because of the security regulations. i have made a sample test suite to reproduce this issue.just executing test with mocha test runner. you can see it.``` javascriptdescribe(\'test suite\'. function() {  before(function(client. done) {    console.log("before!!");    client        .url("". function(){          done();        });  });  after(function(client. done) {    console.log("after!!");    client.end(function() {      done();    });  });  beforeeach(function(client. done) {    done();  });  aftereach(function(client. done) {    done();  });  describe(\'testa\'. function() {    it(\'uses bdd to run the google simple test\'. function(client) {      client.setvalue(\'input[type=text]\'. [\'nightwatch\'. client.keys.enter])          .pause(1000);      client.expect.element("must failed...!").to.be.present;    });  });  describe("testb". function(){    it(\'uses bdd to run the google simple test\'. function(client) {      client.setvalue(\'input[type=text]\'. [\'nightwatch\'. client.keys.enter])          .pause(1000);      client.expect.element("must failed...!").to.be.present;    });  });});```i found some hints related with this issue last night.when the following expect failed with mocha. the after hook was not executed. ``` javascript      client.expect.element("must failed...!").to.be.present;```so a browser window was reopened and the failed test suite was resumed. but before hook method was not executed.these flows are differ from default test runner\'s.', "no. test_worker has nothing to do with this issue.whether enabled it or disabled it. the same thing happened.i may have found why this happend.when i turn on bail of mocha options. this issue did not happen.``` -b. --bail                              bail after first test failure```it seems that mocha's retry policy is differ from nightwatch's when test case is failed.", 'i managed to get this working by just using`"test_runner":"mocha"`instead of`"test_runner": {"type": "mocha"}`', 'i am having the same problem. but i would like to use another reporter but when i add this to the config:```"test_runner" : {  "type" : "mocha".  "options" : {    "ui" : "tdd".    "reporter" : "nyan"  }}```this setting is taken from the docs (except for \'nyan\'). but it doesn\'t work. only with:```"test_runner" : "mocha"```', "another good thing about restructure is that it's got lots of mocha tests (a total of 234).", 'update a bunch of packages. we no longer need `os-tmpdir`. and aside from `mocha` everything else is just minor updates.', 'let me get some clarity: are we talking about test coverage for the generator? or. for a newly _generated_ project? i misspoke earlier and i apologize. `generator-angular-fullstack` uses mocha for its own testing.', 'i would like to unify them. i prefer mocha and chai for both front and backend. but i think we should support jasmine as well.', "daftmonk i've got a branch based on `canary` + #482 that uses mocha + chai + sinon for server and client side tests. i've included promise support in the server tests and reduced their code due to removing callbacks and such... also i switched to using chai should assertions since they don't need globals(jshint) or a `var expect = require('chai').expect` in every test. let me know if thats a problem. one thing that i see is the test included in `generator-ng-component` would need to be updated if we were to keep those changes. in implementing a prompt based testing framework selection. we would need to be able to maintain the choice with `.yo-rc.json` i'm guessing? then ng-component would need to be able to support jasmine or chai style assertions? sorry. i've not had much experience with the inner workings of the sub-generators.", 'hmm jshint is not liking the expressions in the mocha tests for the user model.  i needed to update some of the tests to be async.going to add``` javascript/*jshint expr: true*/```to the top of the file.', "kingcody i've got more experience with jasmine tbh. but i can give it a shot; no promises. but in any case thanks for your work on it! just a thought. maybe there could be a choice to use jasmine on its own. or. mocha + sinon + chai? i'm contemplating having to rip out all your good work in future projects ...lol", 'refactor(server-tests): use sinon-chai and `mocha.conf.js`. changes:- add `mocha.conf.js` and use it as a `require` in `mochatest` task- switch `should.js` for `mocha-chai`- change server-side test assertions to user chai assertionsbreaking changes:- should.js is no longer included. chai assertions should be used instead.', "also pentateu your build is failing because canary no longer uses `should.js` and instead uses chai assertions. if you look in `mocha.conf.js` you should see where `chai.should()` is initialize as well as defining expect. assert. and sinon as globals for the tests.you should be able to simply remove `var should = require('should');` from the tests to correct the issue.", "thanks! it's not what i thought the problem might be and i'm not familiar with mocha. so not sure i'll be able to add anything. but i'll do some mocha reading and have a look. i found this project from synaptic and looks like you've got some great stuff going on here.", 'kkoopa ronkorving still looking good for testing but i am seeing timeouts still. the default timeout for mocha is 2000ms. can we change this to say 5000ms or maybe even 10s so when travis is overloaded we wont get failures?  "--timeout <ms>" / "-t <ms>" in the makefile where mocha is called.', 'i uninstalled all modules and installed them one by one to check what causes the problem.it seems to be related to generator-mocha and all yeoman generators using mocha and generator-mocha modules (in my case. generator-backbone). i can reproduce the problem by uninstall and installing that particular module.', 'indentation test failing on windows (newline related?). i have the project checked out on windows using unix style line endings. running `npm test` on develop i see the following failure:```1 failing  1) indentation [size: 2]:      assertionerror: 8 == 0      + expected - actual      -8      +0      at c:\\users\\jclanton\\documents\\github\\sass-lint\\tests\\rules\\indentation.js:15:19      at object.module.exports.test (c:\\users\\jclanton\\documents\\github\\sass-lint\\tests\\rules\\_lint.js:33:3)      at context.<anonymous> (c:\\users\\jclanton\\documents\\github\\sass-lint\\tests\\rules\\indentation.js:12:10)      at callfnasync (c:\\users\\jclanton\\documents\\github\\sass-lint\\node_modules\\mocha\\lib\\runnable.js:306:8)      at test.runnable.run (c:\\users\\jclanton\\documents\\github\\sass-lint\\node_modules\\mocha\\lib\\runnable.js:261:7)      at runner.runtest (c:\\users\\jclanton\\documents\\github\\sass-lint\\node_modules\\mocha\\lib\\runner.js:417:10)      at c:\\users\\jclanton\\documents\\github\\sass-lint\\node_modules\\mocha\\lib\\runner.js:524:12      at next (c:\\users\\jclanton\\documents\\github\\sass-lint\\node_modules\\mocha\\lib\\runner.js:338:14)      at c:\\users\\jclanton\\documents\\github\\sass-lint\\node_modules\\mocha\\lib\\runner.js:348:7      at next (c:\\users\\jclanton\\documents\\github\\sass-lint\\node_modules\\mocha\\lib\\runner.js:281:14)      at immediate._onimmediate (c:\\users\\jclanton\\documents\\github\\sass-lint\\node_modules\\mocha\\lib\\runner.js:316:5)```this may be related to how `os.eol` is used in the indentation rule. but i have not yet had time to verify that.', 'fernando-silva thanks for the patch! can you please give an example. that can be added to the mocha tests?', "good catch. wonder why mocha isn't complaining about that.", "that was fast  i'll take a look at the tests and see if i can find something. i never used `mocha-webpack` before. is it so the webpack require's work? i usually use `rewire` for that. but i'll take a look later and let you know. thanks!", 'disable logging. is there a way to disable logging? some of the error messages are breaking the mocha tap output of my  unit tests. its kinda annoying. so a option like "quite" for the logger?', 'just realized the problem lies in sails-mysql which is logging errors directly with console.log... so this can be closed', 'the console.log entries should be commented out or removed. the console.log entries are breaking my testing output with mocha. i cant use the tap output of mocha this way... also its no good style. pass the errors through callbacks and let another layer handle them.', 'fix for policy mapping of actions with capitals. plus general integration test fixes.. fixed: bug in policy mapping for actions with capital letters.added: new test to verify the above.fixed: httphelper not properly detecting super startup.fixed: two tests in integration/policies.test.js not properly verifying error responses.added: integration/policies.test.js line to mocha.opts to actually run its tests now that they work.general note: mocha.opts only runs waterline tests. partial fix here now that policies test properly.', 'add ignorecliflags param. - this new param will allow the user to selectively disable the parsing of command line flags (`process.argv`). this is useful for testing environments like mocha.  - as a result. roosevelt will no longer selectively ignore cli flags under certain conditions. (closes #340)- flags are now parsed after params.', "nevermind. i see there's an issue with the linter. skipping that and running `npm run mocha` for my purposes.", "yeah looks like rwaldron made it possible to at least tweak the jshint settings to allow it.  kciccarello were you able to get tests to pass after running mocha directly? also be aware that i changed some values in the tests that may not be right. so i'd double check that i didn't royally screw stuff up :-p", 'makes sense. i was able to get the tests passing by running mocha directly. yes. will submit a pr once i get can get this done and verify it works. thanks', 'ack. run test in mocha + chrome +ff.no related to this commit:it is very strange that test take 90sec in the browser and 4sec in node!', 'move mocha to devdependencies. save a smidge of install time for react module (where recast is a dep of envify).', "another thing to be aware of with aliases is tests. just because webpack knows app as an ali's doesn't mean mocha or karma etc. will know how to resolve it", 'i have given up on this for now. using mocha reporter gives a similar view in the command line and is significantly faster.', 'thanks for the comments. working on them now', "chore(package): remove buster dep. remove buster as it's no longer needed.  all tests ported to mocha.", "i'm confused. are you running server side/node.js tests? this plugin is specifically for server side tests. also in the project you link to there is no `gruntfile`. this plugin is a grunt plugin.if you have a project that you are trying to integrate with grunt and grunt-mocha-test then i can take a look at that and see if i can get it to work.although i'm interested in requirejs. unfortunately i have very little experience with it", 'correct. the example is not using grunt but it was the only one i could find about running mocha tests with nodejs serverside and using requirejs. my project runs test with grunt-mocha using nodejs. i just hand my test index.html (which i use for client-side testing in a browser while developping) to grunt-mocha which then performs them automatically using nodejs. phantomjs on the server. however i have no idea about the magic it does in order to get it working... i "just" want to add a coverage system to the project and struggeling with the how ;)', "i have restructured it to fit my development style a little. eg. i added a `vagrantfile` so i could use vagrant to do development in a vm with a known environment. also i moved some source files around to fit in with the coverage stuff so that i could more easily exclude the tests from being instrumented for coverage data (which i wouldn't want).i changed `readme.md` because i cut out all the browser related stuff which wouldn't work anyway.the important stuff i haven't changed - ie. the test files are the same and the source files are the same (just moved to `lib/src`)the old `node_runner.js` is no longer used so i removed it. instead i adjust the global object using `globals.js` and specify that with the mocha require option so that it gets run first.", "the `baseurl` is important because the paths to the libraries change when they are dropped in `lib-cov` with coverage data. it may be possible to get rid of that and use paths relative to the root of the project if you instrument the source with blanket on the fly (as demonstrated in the `grunt-mocha-test` docs) but tbh i don't like doing that anymore as it can be tricky to set the pattern to match only your own source files. alternatively i think you can remove the `baseurl` and refer to libraries in the tests as `lib-cov/lib/src/main` etc as that is relative to the default `baseurl`. however the downside is that the tests could then only be run with coverage data and not from the original location.unfortunately the way blanket and the mocha coverage reporters work they don't really see files that are not touched at all. however if you ensure that all your source files are at least required at some point then that should ensure they are included in the report even if nothing in them is called as requiring a file evaluates it", 'setting working directory. my tests need to be run from a different working directory than the one where my gruntfile resides. is there a way to run mocha through this plugin with a different working directory?', 'not currently. if you have tests that depend on a particular path have you tried using an environment variable or something.i put things like this in `package.json` and run grunt using `npm test````...  "config": {    "home": "./mypath"  }.  "scripts": {    "test": "grunt"  }...```in my tests i can access the config using```var home = process.env.npm_package_config_home;```another option if you need your source to run in a different directory is to change the directory in the test before and after handlers using `process.chdir(directory)`worst case scenario you could use `spawn` or `exec` in your tests', "in my particular case process.chdir in my test setup file is a great solution. thanks!one thing i am stuck on now. though. is that when i do 'grunt mochatest' it does not return me to the command prompt after running through my tests. so. the tests run fine now but it seems like mochatest is just sitting there waiting for input. how can i get it to end the process once the tests are complete?", "hmm. i haven't seen that before. is it possible that all the tests completed but there is still something running - like an http server still listening?", 'actually my bad. i was mocking process.exit in one of my unit tests and never set it back to the original function. interesting that it worked when i ran mocha from the command line but not when i use grunt-mocha-test. regardless. an easy change on my side.thanks for the help once again!', "hey man. yeah it works fine when running with mocha directly. i'll try to put together a some code and sent it your way!", 'implemented with #182 :)', 'include also files in `spec` folder by default?. mocha.js supports both tdd and bdd styles. in bdd documents are called specifications. not tests. putting "specifications" inside of folder called "test" looks a little strange. it would be nice if it would be possible to call that folder `spec` or `specs`. i.e. if mocha.js **by default** include not only files in `test` folder but also in `spec` folder.what do you think?', 'this.timeout() inside describe() doesn\'t work for me. this below js snippet is from the mocha.js website docs. "suite specific timeouts":``` javascriptdescribe(\'a suite of tests\'. function(){  this.timeout(500);  it(\'should take less than 500ms\'. function(done){    settimeout(done. 300);  })  it(\'should take less than 500ms as well\'. function(done){    settimeout(done. 200);  })})```this code example is a bit confusing. when i put the "this.timeout()" call like this i get:```c:\\dev\\github\\alexlatchford\\adfuser\\src\\test\\api\\v1\\target_groups.js:274                this.timeout(0); // extend the timeout for this suite because we\'re insertin                     ^typeerror: object #<object> has no method \'timeout\'    at c:\\dev\\github\\alexlatchford\\adfuser\\src\\test\\api\\v1\\target_groups.js:274:8    at module.exports.suite.on.context.describe.context.context (c:\\users\\alatchford\\appdata\\roaming\\npm\\node_modules\\mocha\\lib\\interfaces\\bdd.js:72:7)    at c:\\dev\\github\\alexlatchford\\adfuser\\src\\test\\api\\v1\\target_groups.js:272:2    at module.exports.suite.on.context.describe.context.context (c:\\users\\alatchford\\appdata\\roaming\\npm\\node_modules\\mocha\\lib\\interfaces\\bdd.js:72:7)    at object.<anonymous> (c:\\dev\\github\\alexlatchford\\adfuser\\src\\test\\api\\v1\\target_groups.js:15:1)    at module._compile (module.js:449:26)    at object.module._extensions..js (module.js:467:10)    at module.load (module.js:356:32)    at function.module._load (module.js:312:12)    at module.require (module.js:362:17)    at require (module.js:378:17)    at mocha.loadfiles (c:\\users\\alatchford\\appdata\\roaming\\npm\\node_modules\\mocha\\lib\\mocha.js:137:27)    at array.foreach (native)    at mocha.loadfiles (c:\\users\\alatchford\\appdata\\roaming\\npm\\node_modules\\mocha\\lib\\mocha.js:134:14)    at mocha.run (c:\\users\\alatchford\\appdata\\roaming\\npm\\node_modules\\mocha\\lib\\mocha.js:278:31)    at object.<anonymous> (c:\\users\\alatchford\\appdata\\roaming\\npm\\node_modules\\mocha\\bin\\_mocha:324:7)    at module._compile (module.js:449:26)    at object.module._extensions..js (module.js:467:10)    at module.load (module.js:356:32)    at function.module._load (module.js:312:12)    at module.runmain (module.js:492:10)    at process.startup.processnexttick.process._tickcallback (node.js:245:9)```it works if i put it inside my before() for that group of tests. which incidentally was what i intended anyway. but i think either the docs need clarifying or the error message investigating :)cheers.alex', 'web workers support. the environment in web workers is slightly different from the standard browser environment. `document` is not defined. the global object is `self` not `window`. and some extra apis are available. such as `filereadersync`. given these differences. it is desirable to be able to run test suites in a web worker environment.this change makes mocha work in web workers. most of it is changing `window` references in `support/tail.js`. i added a `postmessage` reporter that relays test results to the worker\'s "master" via `postmessage`. using the same format as the json reporter.i also added a test for web workers to the `browser/index.html` suite. unfortunately. this makes it fail when opened as a regular file in chrome. this can be worked around by opening it from a http server in chrome. or by running the browser tests in firefox.i hope that you will consider merging this pr. and i\'ll be happy to make any changes based on your feedback.', '--require expect.js doesn\'t work. hi. so when i include expect.js over the --require parameter. it doesn\'t work. i also tried putting this option on mocha.opts--require expect.jsbut i still getting "referenceerror: expect is not defined"does --require only work with should.js? or what do i missing?', 'likely something to do with your test/app code and not mocha itself (are you trapping sigint for anything?). not much i can do without a reproducible script but re-open if you can determine that it is mocha not your scripts', "seems more like a node issue not mocha. all my test suites use supertest but they're fine. that .close() shouldn't really be hanging anyway. i can't see why it would be. that's unrelated though", "the `--require` option doesn't inject/define variable(s) for you. what the `--require` option does for you is (excuse the crude example):``` jsrequire('expect');[ your code here ]```not:``` jsvar expect = require('expect');[ your code here ]```", 'so. what would it be good for? except for including "should.js" on the tests', "it's not good for much other than should really haha. i would remove it now if people weren't already using it", "nice work. jaredwinick! it would be great to have closer parity between the runner interfaces.one thing you can do to help get this merged: move your change into the `lib/interfaces/tdd.js` source file (`mocha.js` is a built file--you invoke `make` to generate it).if you're busy. i'd be happy to open a new pull request with this change. but i thought you might want a chance to fix it.", 'fix typo.. changed `mcoha` to `mocha`. github apparently added a newline to the end of the file automatically too.', 'converted this to a pull-request that gets mocha to ~2-3x slower than jasmine via low-hanging fruit. the slow part now is the dom manipulation in the html reporter.', "highlight something in red on failures. to make it more obvious without wasting eye-movement effort to look at the count haha. i prefer github.com/visionmedia/mocha-matrix for this reason but it's not a good fit as a default", 'i\'d like to see this merged in. ideally with a command line switch to enable/disable the behavior. alternatively. a "words" diff could be done and then. if that doesn\'t actually show any differences. a chars diff done. it\'s rather frustrating for mocha to report that the actual and expected were difference. but then not show any actual difference in the output.', "bcoe i'm buzzy this week and will look into the readme example and the tests during the weekend. for another project i'm using  along with mocha to generate test coverage reports on the fly which is extremely helpful while writing the tests. i will add it to my fork and send you another pull request if i have enough time ;)", 'mocha is not installed in any `node_modules` folder. i checked the docs for lerna. and this seems to be by design. from their readme:> note that devdependencies providing "binary" executables that are used by npm scripts still need to be installed directly in each package where they\'re used.they recommend pulling up the dependency to the root repo.not sure why it works for you on linux. maybe you have mocha installed globally?', "thanks assaf. is there a way to print out the dom to confirm this? i've not been able to do this. in my view. this is a critical feature for testing data-driven. single page web apps as dom updates based on ajax calls is common. your api design is good and it's a nice workflow to debug tests with mocha in my ide. unfortunately. this is pretty critical for the work i'm doing atm. thanks. peter", 'i would also add that linting would be a positive addition to automated testing. close to 100% of the prs are riddled with what would be pretty easily classifiable as style violations. currently these all involve manual call-outs. any of the dozens of popular linters can make this a one-line change.```"scripts": {  "pretest": "standard".  "test": "mocha test".}```', "choosing a testing framework. the current setup is mocha. i'm fine with that. but does anyone feel strongly that we use something else?(split out of #29 per fernando-mc's suggestion)", 'linusmarco mocha it is.', "mocha.process.stdout not working properly?. except when using json as reporter. i believe the mocha.process.stdout isn't working properly. for example in the mocha-phantomjs.coffee. even if i comment out the following code:page.onconsolemessage = (msg) -> system.stdout.writeline(msg)i should still see the test results from the following right?    page.oncallback = (data) =>      if data?.hasownproperty 'mocha.process.stdout.write'        output.write data['mocha.process.stdout.write']but instead. all test results / client side console messages seem to be getting captured by the  browser console. if i comment out the first line. nothing gets output on my terminal. (except when using json. json outputs fine) i'm trying to do this since the application i'm testing has a lot of noise on the client side (events firing. etc.) and i want to be able to block them out in my tests. also i believe this is causing all the test output to have no color formatting (green / red colors). just wondering. where is the code exactly telling mocha to output to mocha.process.stdout? i tried looking in individual reporter files but they all have the regular process.stdout.", 'see #114. #189. #161 . tl;dr is like you found that moat mocha reporters use `console.log` so its impractical to separate the noise out.', '+1', 'the errors.out and non-server from common.js are now extracted.', 'great! i am using q with mocha and phantomjs. and also in my application in parallel load synchronization.', "it's a start.  we still need to get electron-mocha using electron-compile instead of babel.  once we do that i'll be able to check the contents of the spawned window for `.cell` !!  this should catch lots of bugs before they appear.", 'aka electron-compile working on electron-mocha', "oh wow. very nice! thank you so much for showing me that. i'd never have found it otherwise. the `readme` is definitely misleading in that regard. as it makes no mention of mocha-only testing. can you show me a gist or something that would give me a very basic overview of how to implement mocha testing so that i can go ahead and get to work on my pr?thank you!", 'it\'s a "bring your own mocha" design ;-)just add mocha to your devdependencies and it works fine.', "bingo! add mocha to the `peerdependencies` in mochify's package.json?", 'register mocha as a dependency. fixes #31', ':+1:', "no. this is not the way forward. simply because it does not make a particularly nice api and also because not all the arguments make sense to be passed to mocha (e.g. `--debug` or `-w` since it need different handling in the mochify context). the same is true for browserify. i've started to work on this on a branch and already converted the arguments parsing to use `subargs`. but mainly to allow to pass arguments to custom transforms:```$ mochify --transform [ foo -x -y ]```in case of `--recursive` i'd prefer it to be passed down just like `-u` and `-r` are.", "using chai with mocha. not clear to me how would i use this assertion lib**update**i should blame myself for opening this ticketit was fairly easy to do so:```chai = require 'chai'chai.should()```", 'how to require a helper function to run before each test?. not sure how can i include helper function for mochait seems like there is missing option that default mocha provides `--require` package', 'i think `--require` (and the `-r` shorthand) could be supported by mochify. fortunately. browserify has the same option and it has the same effect :)anybody up for adding this in?', "i agree that it will mean you always accept `world` as argument. and that's an api change.i think that like mocha wich has `--ui exports` and `--ui tdd` and `--ui bdd` - the cucue can as well.it's basically a project variable that determines if steps are called/applied  on the world. or accept it as 1st argument.", 'you need to upgrade mocha.', "as i have been sayin'. transition to `mocha-phantomjs` and removal of `brunch test` is planned soon. mocha-phantomjs is a lot simpler and gives more real-world results.", 'plorent good stuff. need to try this one', '`babel/register` is now `babel-core/register` so try `mocha --compilers js:babel-core/register` instead', "have the same issue when running unittests with mocha```// mocha.opts--compilers js:babel-core/register```i particularly have this issue when exporting class```class wow { }export default class hey extends wow { ...}``````'this' is not allowed before super() (this is an error on an internal node. probably an internal error)```but this works ```class wow { }class hey extends wow { ...}export default hey;```", "introduce exec tests for plugin regressions. this makes it easier to catch regressions and to report plugin issues. ideally we'd have an input and expected files. but that would require changes to mocha-fixtures too. this is good enough for now.cc sebmck thejameskyle"]