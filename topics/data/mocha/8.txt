['hi rrrene looks interesting! at present it is parsing things like `mocha.js` and `ie8-shim.js` which should really be excluded from the evaluation. how would we configure that if we were to add this badge?', 'note. the mocha tests pass. but it is failing on creation of `index.js` ... i still need to look into this.  if anybody could offer any pointers. it would be appreciated.', 'error debugging mocha on windows. i\'m trying to debug my tests but get the following output and was wondering if someone could point me in the right direction```$ node-debug _mocha mmsprocessortests.jsnode inspector is now available from :8080/debug?port=5858debugging `_mocha`debugger listening on port 5858c:\\users\\jonathanchannon\\appdata\\roaming\\npm\\_mocha.cmd:1(function (exports. require. module. __filename. __dirname) { if exist "%~dp0                                                              ^syntaxerror: unexpected token illegal    at module._compile (module.js:439:25)    at object.module._extensions..js (module.js:474:10)    at module.load (module.js:356:32)    at function.module._load (module.js:312:12)    at module.runmain [as _ontimeout] (module.js:497:10)    at timer.listontimeout [as ontimeout] (timers.js:110:15)```', 'you trying to debug `_mocha.cmd`.try set a valid path to `mocha.js` file.', 'please see [how to debug node apps with node inspector]( last part of this video contains information about debugging mocha tests.', 'bajtos. how about add `.cmd` execution to node-debug?', 'bajtos . l189 of node-debug.js is a typo?', 'fix repl not being able to unlinksync files under mocha. no idea why it happened. but `unlinksync` returned without actually unlinking the file. so it sent repl into an infinite loop', "mocha requires `es5-sham`. so it's not really an option.", "great. i'd actually really love to get rid of mocha anyways in favor of tape :-)", '\'missingschemaerror: schema hasn\'t been registered for model "user".\'. i installed a fresh clone of this repo. but when i try to run`grunt mochatest`mocha literally explodes.i am on mac. which informations would you like me to provide in order to assess the issue?', 'did you do `npm install` first?', "normalize settings payloads in client serializer. closes #5117... gave up on writing tests for this so i could unblock acburdine. once i understand how ember-mocha works i'll do another pr with tests", 'implemented correctly. this works as expected:``` jsvar async = require(\'async\');describe(\'series\'. function() {    it(\'should complete\'. function (done) {        var mycallback = function(error.result) {            if(error) {                console.log("error: ".error."msg: ".result);            }            else {                console.log("mac is open. all action done");                done();            }        };        async.series([                async.ensureasync (                    function(callback) {                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        callback(null. 0);                    }).            //below function not be called                async.ensureasync (                    function(callback) {                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        callback(null. 0);                    })            ]. mycallback        );    });});``````$ mocha series.test.js   seriesmac is open. all action done     should complete  1 passing (8ms)```', "ugh. always new tools.  i'd be hesitant to switch to it. seeing as we're not even halfway through migrating to mocha.  mocha is also has really good adoption in the greater js world. so it's one less thing for a new contributor to learn most of the time.", '``` jsvar async = require(\'async\');describe(\'series\'. function() {    it(\'should complete\'. function (done) {        var mycallback = function(error.result) {            if(error) {                console.log("error: ".error."msg: ".result);            }            else {                console.log("mac is open. all action done");                done();            }        };        async.series([                async.ensureasync (                    function(callback) {                        console.log(0);                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        console.log(1);                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        console.log(2);                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        console.log(3);                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        console.log(4);                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        console.log(5);                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        console.log(6);                        callback(null. 0);                    }).            //below function not be called                async.ensureasync (                    function(callback) {                        console.log(7);                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        console.log(8);                        callback(null. 0);                    }).                async.ensureasync (                    function(callback) {                        console.log(9);                        callback(null. 0);                    })            ]. mycallback        );    });});``````$ mocha series.test.js   series0123456789mac is open. all action done     should complete  1 passing (8ms)```sounds like a problem with your debugger.', "another thing. i just noticed ava doesn't support browsers -- only jsdom.", "i didn't touch the `detectlimit` method between ff1e180 and 1f12a4f. so i don't know what could have caused it to fail. the timeout for mocha test for `detectlimit` did get shortened though.", "there aren't immediate plans for this. but it is somewhere on the roadmap. you can probably achieve this today by using a combination of jscoverage (to instrument the code) and a custom lcov reporter or using mocha which already has an lcov reporter built-in.hooking a function in the aftereach hook is also possible before `.end()` is being called.", 'i am still unable to get rid of the mocha\'s timeout error. i can\'t set the options to the "test_runner" setting because i\'m getting hooks undefined errors. any ideas on how to set a timeout with a value gt 2000ms ?update: **fixed the timeout issue by applying: this.timeout(0) in the before hook**yet again. the browser keeps closing after the first describe finishes running.the hooks i\'m using now are the following:```before(function(client. done) {    this.timeout(0);    client.perform(function() {        client            .url(url)            .resizewindow(1366. 768)            .waitforelementvisible(\'body\'. 100000)            .pause(5000. function() {                done();            });    });});``````after(function(client. done) {    client.end(function() {        done();    });});```as mentioned above. because the session is closed after the first suite of tests passes. in the console i receive the following error: `error: unable to locate element: ".element" using: css selector`', 'lkay i got a same problems with you and then i tried```"test_settings": {    "default": {      "launch_url": "".      "selenium_port": 4444.      "selenium_host": "localhost".      "silent": true.      "desiredcapabilities": {        "browsername": "chrome".        "javascriptenabled": true.        "acceptsslcerts": true      }    }  }."test_runner" : "mocha"```and it works well.', 'dblock i now have time to start working on this task. however before i begin i wanted to plan the task out a bit more. what exactly are we planning to achieve?   - do we want to only support promises for asynchronous tasks or should we support the usage of a `done` callback as well?  - should we still support the `return false` usage or just drop it completely and make a semver major change?', "this is just my 2c. but i think we don't have to support `done` callback if we don't want to. however we should support `false` for backward compatibility if it's not too difficult.", 'just seen this (sorry) but #133 seems like a good solution to this.', 'add repo.checkoutfile and repo.reset. was missing those. so i added them. getting into the mocha `beforeeach` and `before` was confusing but i think i made it work.', "i figured it out - i need to run `git init` on the copied repository to make it work. please don't wonder about your inbox by travis. i was a bad boy and `reset --hard` all the faulty trys i uploaded here. they would just pollute the history. :wink:", 'cool. much appreciated.', 'anything left you want me to change?', "you're right. there is a problem with the mocha test snifffing that it is doing right now", "however yadda doesn't check node_env anywhere in the codebase and doesn't require any 3rd party libraries that might either. i don't think mocha cares about node_env so i'd be happy to remove it.", 'always getting a timeout on after all hook with cucumber-boilerplate. error description : 1)  "after all" hook:    error: timeout of 25000ms exceeded. ensure the done() callback is being called in this test.     at null.<anonymous> (c:\\mobile_appium\\cucumber_boilerplate\\node_modules\\mocha\\lib\\runnable.js:215:19)i dont see any after all hook in implamentation ?', "yadda doesn't configure one. how are you running yadda? maybe an issue with cucumber boilerplate?", "thanks works great.in case anyone is using mocha integration or something similar to the mocha cucumber boilerplate. the change looks like this in init.js``` jsyadda.plugins.mocha.steplevelplugin.init()```to:``` jsyadda.plugins.mocha.steplevelplugin.init({    parser: new yadda.parsers.featurefileparser({                leftplaceholderchar: '<'.                rightplaceholderchar: '>'            })});```", 'sync/async mix. it\'d be awesome if steps worked the same way mocha tests do:where if i do```it(\'test\'. function(done) {  dosomeasyncstuff.then(done);});it(\'test\'. function() {  return dosomeasyncstuff();});it(\'test\'. function() {  return assert(true);});```it figures out magically that i gave it the `done` param. or if i return something. and if that return is a promise. it should wait for it to resolve.where as:```.given("$num green bottles are standing on the wall". function (num) {  return wall = new wall(num);});.given("$num green bottles are standing on the wall". function (num. done) {  wall = new wall(num);  done();});.given("$num green bottles are standing on the wall". function (num. done) {  return dosomeasyncstuff();})```all rely on different stuff in the```    scenarios(feature.scenarios. function (scenario) {      steps(scenario.steps. function (step. done) {        yadda.run(step);      });    });```frustratingly `yadda.run()` doesn\'t return what the step does. so i can\'t evaluate what the response is and run the done myself based on the response of the `yadda.run()`', 'hey!thanks for the speedy response. the `interpret` as you say is clearly the right place to put the logic as apposed to trying to shoehorn it into stuff around the `yadda.run`.i\'ll give your suggestion a go later. but it looks like it should make sense for most cases.async steps should ideally be able to return a promise and have the `next()` called in a `.then()` or maybe `.finally()` on the end of the promise chain.if async steps weren\'t able to return the promise. every \'promisey\' type step would have to look like:```.given("$num green bottles are standing on the wall". function (num. next) {  promise.resolve(\'foo\').finally(next);})```which is probably fine. it\'s just going to cause a lot of unnecessary imho duplication as opposed to:```.given("$num green bottles are standing on the wall". function (num) {  return promise.resolve(\'foo\');});```or in more succinct es6:```.given("$num green bottles are standing on the wall". num =>  promise.resolve(\'foo\'));```', "i'm not a fan of promises.", "sad face!even in the native es2015/es6 sense?if that's a no go. perhaps we/you could have a snippet to use in one's own `test.js` that would intercept to handle promises and run the `next()`?i'll try to put something together this evening and make a pr for you to consider.", 'all good. thanks for the prs.', 'always getting a timeout on after all hook with cucumber-boilerplate. error description :1) "after all" hook:error: timeout of 25000ms exceeded. ensure the done() callback is being called in this test.at null. (c:\\mobile_appium\\cucumber_boilerplate\\node_modules\\mocha\\lib\\runnable.js:215:19)i dont see any after all hook in implementation ?', "it's also possible you have code like the following somewhere in your test.```after(function(done) {   // does not call done()})```", 'hey thanks for the info. i will get back to you on this soon.', "so. appveyor seems a little underpowered which means i've increased the mocha timeout limit to 10 seconds to compensate for any of the file/directory reading we have to do and child process spawning as these were causing the build to fail. also pulled a few little issues out of some of our rules and updated our test matrices. all should be passing now but we'll wait for that lovely green tick on appveyor.this by no stretch of the imagination means sass-lint is rock solid on windows as we don't have any tests for crlf which we know causes gonzales to behave oddly or just refuse to behave at all. progress though at least!", "oh thanks.but it's a petition for consider this as a bug. if someone thinks like me.if that the case. i am willing to pull request and try to fix it!", "yes. this seems to conflict with the `colors` option in captain's log.  try just using the `-c` option for mocha instead.", "lirantal this pr just fixes underlaying error we stumbled upon while looking into the issue #1455. but doesn't fix the initial problem he/she was reporting: `.end()` doesn't get called if `.error()` happens. you'll need a fix for #1455 separately....at least we now know how to cause mocha error out easily. ;-)kudos for nicksellen for that semver fix btw. he made that for trustroots initially.", "testing modules. i was wondering how the team might be thinking about approaching the testing of modules (and i guess themes. too).i poked and played around with testing contenttypes and so far the awkwardness of trying to load modules in the mocha tests has gotten in my way.i know that for now. lib.core.module is just a stub -- and i suspect the goals of that file would be to test the module.js file -- not individual modules.so i guess my question is two-fold -- what to test in module.js. and how to test modules (be they core or otherwise).i realize this is a really open ended question. which is in fact why i'm asking it.  i'm hoping to start a discussion about testability in general and what could be done to move the ball forward!", 'good question. it crashes at the end of the report.ive run mochatest locally and it worked fine.looking at the stacktrace it doesnt even seem to be related to the codechange?maybe it crashed because i closed and reopened the pullrequest accidently while it was building?', "idea: change default mocha reporter to 'nyan'. this can be done by editing mocha.opts :)", 'tried using it for a while. and it sucks for development. closing...', 'any chance this feature request could include command: e2e as well as command: test ?', "use fulltitle of a suite in reporter. i have some nested describes in mocha and in junit reporter they look ugly because reporter takes name of inner describe only.here's suggested patch to take fulltitle of a suite so in report it will look nicer.we can make it optional if you want no to break anything.", '> they look uglycan you provide a screenshot of how the logs look before and after?', "dont start mocha if there are no files. i use grunt-mocha-test in combination with an watch event. to only run against the changed files/tests. therefore it can happen. that there are no associated tests for a given file.in these cases grunt-mocha-test runs with no files. which is not necessary.i've added a check against `this.filessrc.length` to stop the task without error on an empty list.", "haha. sorry. the word 'misled' may have been a bit heavy handed.i'd probably categorize my use case as pretty simple. as i've just got a script file in some directory and a test in another. but it's entirely possible that i'm just missing something really obvious with the configuration.with that said. i don't expect you to document blanket (or any other plugin) here. but i think it would be immensely useful if the example you gave had a bit more information about how it works. questions like where the tests are located. and where the script is that you're getting coverage on are ones of note.if there was. for example. a guide that users could follow step-by-step and generate a working then you'd be helping users of _this plugin_. it would be particularly neat if there was an example folder that users could directly reference. i don't think example configurations are always a necessity. but if the set up is as finicky as it sounds it might be a good idea in this case.i'd be more than willing to do all of this myself. but alas. i can't produce an example.i chose to raise this issue over here as it seemed to be an issue with its relationship with this plugin (the heavy coupling between the mochatest src and results returned from blanket suggested this). though. you're right. it could also be an issue with blanket (or solely with blanket).anyway. i appreciate your help. i'll check out the preprocessing. but i still think it's a good idea to update the readme regarding on-the-fly coverage :+1:", "you're right. it does match things `node_modules`. the issue was getting it to match a particular set of files (/lib and /tasks). i wasn't able to get it to get both of those.i wouldn't worry too much about my particular case anymore. though; i've switched over to grunt-mocha-cov. but if you think it's worthwhile to update the docs to help future users i totally support that idea :+1:", "heh. yeah i had browsed the source of blanket to see if i could figure more out about the pattern to get things working. i wasn't able to last night. but now that i've got grunt-mocha-cov working i've figured out a bit more about how it works. i'm thinking i'd probably be able to go back through and make it work with this task. but i'll prob. stick to grunt-mocha-cov just 'cause it's doing the task i set out to do.", 'lavrton any ideas when it will be released? maybe i can help?', 'what are the variables leaked? maybe jquery is conditionally leaking depending on a feature test? if you need to configure mocha in a specific way. custom test page is one way. another way is to just add a little bit of javascript to configure mocha.', 'is there a straightforward way to use a `mocha.opts` file for the web? seems like it is a command line thing.', "i can't see how testem has a part in causing this. i suggest you create an isolated scenario where jquery and mocha are the only players. and then isolate down to just mocha or just jquery.", "messed up test reporting with latest mocha. since 9587dee92fd38b1d6c087474e5251bb7d70b731d (update to latest mocha) the test reporting is a little messed up.if no test fails. the tab for each connected browser is not updated and only shows `0/0 `. moving through the tabs causes them to render correctly.the very last run test example (i.e. `it`) is not properly reported. it's not displayed along any other pending test. when itself is pending. if it fails. its assertion error is not displayed. instead pending tests will be displayed as if no test failed at all. when passing. everything is displayed fine.", 'confirmed. thanks for the report.', 'just tested the example with the recent mongodb. should and mocha. it works fine. if you insist. open this issue again. but provide detailed information on your specific case.', "code coverage doesn't cover files without tests. pretty self-explanatory. i have 20 or so files in app/ with zero coverage. and one test in test/. none of the files without tests are showing up in coverage.html```test:    mocha --reporter speccoverage: app-cov    code_coverage=1 mocha --reporter html-cov > coverage.htmlapp-cov:    jscoverage app app-cov.phony: test```", 'ignore explicitly exported globals. it would be nice if mocha ignored explicitly exported globals which are usually meant to be intentional.for ex (in browser):window.my_global = function(){...}(in node):global.my_global = function(){...}not sure how difficult this would be to do (probably very difficult without doing static analysis of the code itself)this would be a super useful feature because generally globals are intended when written like that... maybe the solution is to ignore global leak detection from mocha. and run a jshint on the files before hand and explicitly export the variable to global scope;', "this is already supported with by calling mocha with `mocha --globals jquery.yourlib` or``` html<script>    mocha.checkleaks();    mocha.globals(['jquery'. 'yourlib']);    mocha.run();  </script>```", "right. but my issue is different. i think it would be useful if globals that are assigned explicitly/purposefully by the developer (window.myglobal) be ignored by leak detection) i know you can add them piecemeal to the globals whitelist.> on oct 7. 2013. at 4:31 pm. travis jeffery notificationsgithub.com wrote:> > this is already supported with by calling mocha with mocha --globals jquery.yourlib or> > <script>>     mocha.checkleaks();>     mocha.globals(['jquery'. 'yourlib']);>     mocha.run();>   </script>> > --> reply to this email directly or view it on github.", "nah. having so many global variables that you can't list them doesn't seem to be a good thing to support.", 'thanks judahgabriel . your steps work', "hallas thank you. and yes -- i have tried multiple files. one for each config. a single call to mocha seems to run all the suites in parallel.in case it matters. here is how i call mocha on multiple files:```    ./node_modules/.bin/mocha \\        $(find test -name '*test.js') \\        --reporter list```", "what'd you run help2man on? definitely want to have a man page. but rather use makefile + ronn or something to make it programatically.", "actually after further testing. i find that this way of doing separate 'runlevels' that the instances of mocha appear to be running asynchronously. so the second set of tests begin while the first are still running.bummer.", 'i created a bug on firefox. they said that it is by specification. the "top" property is not available until we actually use it. thus. i think we shouldn\'t use keys function in this case.', "is this still on? generators or not. it's weird to ignore promises as then are pretty much standardised and i see them everywhere. the 2 year long demand in this thread seems to indicate they are a real thing. and it feels a bit counter-intuitive to have to rely on mocha-as-promised with the author-admitted hack. or splash boilerplate code all over the suite to make this work (as you'd expect dryness and safety in tests. especially in the runner itself).it would also improve reliability in all the mocha wrappers (like mocha-phantomjs. grunt-mocha and grunt-mocha-test).", "`it.promised()` doesn't sound like an appealing interface! if we need to be explicit about our use of promises anyway. putting it in mocha core doesn't provide much advantage over a simple decorator like this:``` javascriptfunction promised(fn) {  return function(done) {    fn.apply(this).then(function() {done();}. done);  }}```it's much friendlier for the regular `it()` to handle promise return values properly. as mocha-as-promised makes it do. and. again. it really doesn't take much code to achieve it.note that you _don't need q_ to enable promised tests; you don't need any promise library. since all that's needed to resolve a promised test case is the promise's `then` method. so adding promise support to mocha would not require adding a promise library as dependency.it would be _nice_ to have some kind of `mocha.use()` plugin system. but it'd also be a lot more complex than promise support alone. unless we have other use cases in mind. just adding the most-desired form of support is probably a better strategy than designing full-blown general plugin support.", "implementation details aside (plenty options there). i must say i'm warming to the separate method pattern: i think it has some practical benefits; like being able to assert if your promise-producing code is not accidentally returning undefined's instead of the expected promises (how would you catch this early in the 'overloaded' method?).as experiment i converted some of my code to this `it.promised()` decorator hack and it looks just as tidy as the mocha-as-promised based originals (little more explicit).another question: what would be needed of mocha would later support generator-based async? i have no idea about how it'd work. but maybe we should keep it in mind.if it requires custom code that doesn't mix with the regular code. old browsers or this promise code we can opt to also put it in its own method. like `it.awaits()` .it'll be extremely visible which case is running which async pattern (as no doubt people will mix).", 'many applications of promise-producing test cases involve situations where you will _definitely_ get a promise and not an `undefined`. for instance. all uses of chai as promised:``` javascriptreturn thing.should.become("awesome");return list.should.eventually.contain("pie");```it\'s certainly true that at times you might get an `undefined` slipping under the radar. though. so you\'ve a point there. whether or not `it.promised()` suites are as clean as overloaded-`it()` ones is pretty much entirely opinion; i think it\'s unnecessary overhead. personally. and currently with mocha-as-promised i use promise-returning suites almost exclusively so requiring a more complicated specification for promised test cases would be frustrating.also. "it will do the thing" is grammatical and "it promised will do the thing" is not. it feels kind of anti-bdd to mess up the sentence structure like that. especially for a modifier that certain codebases will be using _a lot_. something like `it.promises_that_it()` (or `it.promises.that.it()`) would preserve the sentence structure but also be even more annoyingly long.currently generator async schemes require a wrapper around the generator function. like `q.async()`; if that wrapper continues to be used for general generator-async use. then generators will work just fine with a promise-supporting mocha. if we (the js community) happen to shift to passing around generators directly instead of promises. there may need to be changes.', 'i personally don\'t use chai as promised so much as it will replace the detailed assertionerrors that might get thrown in the various callbacks with it\'s own generic \'expected xyz to resolve\' message. i\'d rather assert more specific stuff on the actual values and get the nice diffs and all. i only use chai as promised to assert exact rejection reasons (even then usually not. because it limits flexibly in making assertions).i don\'t think we can proscribe specific usage patterns. assume exclusive promise-returning suites or have mocha make the assumption there will be a promise as expected: we need to be pragmatic and support any usage style.if the name of the method in bdd is a blocking issue then it becomes a simple linguistic problem. i think i"ll borrow `eventually`:```it.eventually("returns a valid document". () => {    return testapi.request(args).then((res) => {        //assert fields and/or chain    });});```and `eventually` even works well as the alternative for `test` in the tdd interface.', '> i personally don\'t use chai as promised so much as it will replace the detailed assertionerrors that might get thrown in the various callbacks with it\'s own generic \'expected xyz to resolve\' message.> i\'d rather assert more specific stuff on the actual values and get the nice diffs and all. i only use chai as promised to assert exact rejection reasons (even then usually not. because it limits flexibly in making assertions).you _can_ assert specific stuff on the actual values while using chai as promised. using `.eventually.` or more simply `.become()`. though. i recognise that `.should.resolve` assertions produce a generic and not exactly useful result. but those assertions are not really the main draw of the plugin anyway!> i don\'t think we can proscribe specific usage patterns. assume exclusive promise-returning suites or have mocha make the assumption there will be a promise as expected: we need to be pragmatic and support any usage style.i\'m a little confused by this part. how is mocha making the assumption that there will be a promise. under the mocha-as-promised style? isn\'t it making _more_ of an assumption when you use something that makes it specifically expect a promise. like `it.eventually()`? and if we\'re going to support any usage style. why not support them implicitly if we can? we need an explicit `(done)` parameter for callback-based async. since otherwise the test case can\'t actually _call_ `done()`; we don\'t _need_ an explicit handling of promises. since mocha can quite easily detect that it got a promise as return value and handle it appropriately.if we really must use an explicit notation for promise cases. `it.eventually()` scans okay for me. certainly a much better sentence structure than `it.promised()` produces.the other problem i have with `it.eventually()` over the implicit mocha-as-promised method. though. is that a test case using promises is an implementation detail and not an external property of the test case. `it.only()` is a modifier that applies to mocha\'s external handling of the test case. as is `it.skip()`. `it.eventually()` instead signifies that the case internally operates differently; as such. i think that makes it worse than using a wrapper `it("does thing". promised(testcasefunc))`. since there is nothing externally fundamentally different between a case:``` javascriptit("does a thing". function(done) {  dothething().then(function() {done();}. done);});```and a case:``` javascriptit("does a thing". function() {  return dothething();});```', "domenic good to know! from design perspective. it's still an assertion library's job. the real problem is mocha does not publicly expose the hook?", "00davo well. you can argue this 'test case' vs 'function that tests case' difference if you really must. but i think it is academic and i doubt regular users will care for this distinction as long as they get proper promise support soon (which is what this whole discussion is all about).i really can't understand how `it.eventually()` could be considered so _dramatically_ ugly.it is almost identical as with mocha-as-promised you so admire. except it has just this simple injection of `.eventually` in the code (no hairy quotes. no long-range braces. no indents. no fancy syntax. just a dot and a identifier). regular `it()` is not happening and there is not a lot of alternative or boilerplate syntax that is cleaner then this approach.so let's stop arguing api uix concerns. they are not the main problem in getting promise support: it is policy and implementation technicalities that blocked the `it()` pull-request for 2 years (and gave us mocha-as-promised as desperation solution). and these are what my proposal could offer to solve in a slick and expressive way.i'll leave this as my attempt to get this rolling. awaiting alternate feedback.", "i'm -1 for more method names personally. that would complicate things more than the `return` duck-typing. especially since mocha usually doesn't do anything with return values from the `it` callbacks.", "reporter-specific options and support for the xunit reporter to output to a file. this is a less pervasive change to accomplish the same goal as #897 -- i.e. to have a way of separating the xunit reporter output from stdout so that it can be used in a ci system.in this approach i changed the mocha core to pass a set of reporter-specific options to the reporter class. as well as to call the reporter's done() method to give it a chance to clean things up.then the xunit reporter supports an output option to specify a filename. and flushes the file in done().", 'whoaa512 so what you want is a step further in the direction this code takes us..here is an example:you have tests:a. b. c and dtest a is a success test b fails on suitesetup (before). what i would expect is test c and d will continue to run so i can see the results of those files (each test should be isolated by suite). in reality what happens is mocha "end"(s) after b and no further tests are run. in the past there was a reporter bug that made it appear like those tests actually ran but they do not.does that clear it up?', "maybe something along the line:`it.if(condition. 'should do magic'. function()...)``it.skipif(condition. 'should do magic'. function()...)``skip(condition).it(..)`where `condition` is a boolean value. or a function returning true or false.", 'if you want environment or otherwise specific tests. you create those suits in different files / folders. so you can run them separately.', "hallas i have a suite of tests that run in browsers. i'd like to skip tests when some features are missing (for example. xhr level 2. or indexeddb). my tests are grouped by the features they cover in my library. and i'd really like to have the feature detection (and therefore skipping decision) right next to the test code.", "alright i hear you. let's see what happens", "run multiple tests in parallel. i am using mocha/supertest/chai to test an entire api framework. each time i run a full test (which includes about 40 '_mocha.js' test files)it take roughly 5 minutes to complete.  it would be far more efficient to run tests in parallel completing in roughly 30 seconds.  other testing frameworks i have used in the past are able to do this and have been great!  so question is. is it possible for mocha to also run tests in parallel?", 'not currently possible and no plans at the moment. in lots of cases async tests end up slower. you can always make your own tests faster.', 'travisjeffery that is not the behavior i have locally when i revert the changeset but that is on mocha as of a month~ ago when i submitted the patch... i will rebase and see what is going wrong.', "adding test-integration is fine. but look at how the other test-\\* (e.g. test-unit. test-compiler. test-requires) execute mocha from the makefile. where as your test-integration executes a node script and that executes mocha. so it'd be nice if test-integration was implemented as `.bin/mocha ...` rather than as it is now: `test/integration/hook_fail_before_each.js`", 'visionmedia does this look okay to you? is there anything else i can do to help get it merged?', "we also encounter these when we're using mocha for integration tests for deployed webapps.  i agree with jlipps that beforeeach() should be attempted again if your dealing with let's say a flaky api endpoint.jlipps  do you mind sharing. how are you currently getting around this mocha limitation in your apps?", 'although actually. you could just do:```beforeeach(function(done){  mystuffwithretrieshere(done)})```so it could be left out of mocha. or maybe we devise a little plugin thing so that this stuff can be easily altered from the outside', 'hmm mocha should be catching those with uncaughtexception and mapping them to the correct test case', "ooohhh i lke this a lot! i'm with tj on this... i forked mocha planning on breaking it up into smaller modules but stopped because of priorities. tj have you thought about making mocha into a github organization? that might be useful to help achieve your goals (simplification / maintenance) and then a lot of the mocha related packages could be put there.", "visionmedia i hadn't realized that mocha could be extended in this manner. i'll try to convert this to an npm module instead.jprichardson i think rspec does this too. the core is split into different projects inside an rspec organization. etc.", 'how to stress test mocha unit tests?. is there a trick or a way to tell mocha to run lots of same tests in parallel for a longer time? something like a stress test?', "no tricks up mocha's sleeves for that.", 'thx for that. does anybody else knows a recommended stress tool?', 'i totally understand why this exists. and for the 90% case i agree it\'s the absolutely the way to go in mocha to let it `process.exit()`.  i was just wondering if there was interest in making it _optional_ to skip this feature via a command line flag similar to how `--bail` will make the suite exit after the first test.  i apologize for probably being a bit vague in my first post.you\'re right most node libraries don\'t clean up connections & timers and all that and it _is indeed_ a huge burden to have to do that in tests.  i\'m probably not a normal case in that i\'d really like to use mocha to test node-postgres. but one of the things i need is deterministic proof the process exited cleanly on it\'s own.  since i\'m responsible for writing the code that does the actual cleaning up of database connections and connection pools and streams and all that crap i need to know it\'s working.  so the burden is on me to make sure things exit cleanly in my tests.  which means i\'d really love it if i could tell mocha "nah. it\'s okay. i don\'t want you to exit for me.  if the test hangs i\'ll consider it an error."  mostly because node-postgres is so freakin\' old i wrote it before mocha existed and it\'s just a `makefile` that runs individual `*-test.js` test files...every time i look at upgrading some of the tests to mocha i get stuck on the issue of mocha doing a `process.exit()` with no way to circumvent that behavior.i do see the other side that maybe some lower level libraries should use a lower level testing method...i\'ve just become spoiled on the niceness of mocha in all my apps for testing & would love to use it _everywhere._ :smile: either way thank you & the team & contributors for a great testing lib. :+1: an example would be like...``` bash$  mocha test/ --no-exit```to tell the suite explicitly "do not call process.exit under any circumstances"', 'i hope that this pr would be merged.i can fix our a few codes to suppress stdout as you say easily.but i think that. if mocha has a "format" option. to output a valid report (regardless of the test-case) would be a responsibility.', "can we have it merged? i want to use a custom interface which wraps `it` blocks in fibers. `mocha --require ./fiber-ui --ui fiber-ui` doesn't work (i update `mocha.interfaces` inside `./fiber-ui.js` but it seems to get the wrong instance of `mocha` module).", 'not sure though if it should mutate `exports.interfaces` global. maybe just setting `this._ui`?', "itaylor see #1022 -- it appears requires processed after setting an ui so even if i get right `mocha` instance this won't work", 'gonna go with #1022', "you can skip usage in detox-cli and use mocha directly.i think node 6 is the minimum even if you babel your code. since we use `require('url').url`", 'chore: remove unused devdependency: mocha', 'could we somehow remove `co-mocha` from devdependencies? jhen0409', '> could we somehow remove co-mocha from devdependencies?we can remove it. it looks unnecessary for now.', "adding options for helpers.creategenerator. adding options parameter to `helpers.creategenerator` so that we can pass options like **ui**. **coffee** etc while creatinggenerator for tests.```this.router = helpers.creategenerator('backbone-mocha:router'. [    '../../router']. ['temp']. {ui: 'tdd'});```", 'can you add a unit test to validate the behavior and prevent future regression?', 'sboudrias i have no idea. how to write tests for **test helpers** and where to get started. can you please help me to do it?', 'hey revathskumar.what you want to test is not if the `helpers.creategenerator()` return a truthy value. you want to assert the arguments/options you pass are correctly passed inside the generator.to do this. you should assert that the value received inside the generator (`unicorn`) constructor functions are correct.', "sboudrias i thought i just wanna make sure any argument will work. missing some argument doesn't break it. is this work as as you expected??``` jsvar unicorn = helpers.creategenerator('unicorn:app'. [    [unicorn. 'unicorn:app']  ]. ['temp']. {ui: 'tdd'});assert.equal(unicorn.options.ui. tdd);```", 'sboudrias but. what is the advantage of using self there? i am happy to learn and change my code.', 'each `describe` block have a `this` scope. but i made a typo using `self` in the `it` block (i edited).avantage here is to access the arguments passed to the constructor directly without relying on the part of the system assigning the arguments to the `options` property.', 'revathskumar like i said. the `self` in the `it` block is a typo. it should be `this`. i edited my previous comment.', 'yeah. because you need to use self inside the `unicorn` constructor. and i think you need to use `beforeeach` instead of `before`.let me know how it goes.', 'yeah. that looks good!', 'sboudrias  i just updated my tests. thanks for your time and correcting me.', "i was talking a look at the tests and got sick of manually running them every time.  i had seen this issue. so i figured i would just implement a solution for running tests.the grunt module for mocha that i chose supposedly has an integration with coverall's. though i haven't used it to see if it works.  so that should be helpful i suppose.also. i setup a dynamic config to register watch and test targets for each test file.  this is so that you can leave the watch task running in the background while you work and not have it take forever running the entire suite of tests.  do you guys like that idea?this is a start whichever way you all choose to move forward with this.  hope it helps.", "hi!thanks for the suggestion. for right now we're not seeing any performance issues with our current promise library. bluebird is indeed fast. but we're not bottlenecked by speed of promises at the current time.we'll likely eventually switch over to the newer mocha features that have been released after the time we shipped stripe-node. but for right now. they work just fine and aren't high enough priority to convert.let me know if you think there's a real-world performance problem with not immediately switching to bluebird. but in my limited profiling for stripe-node use-cases. i really haven't seen a compelling case for making the switch (and potentially changing something subtle that a user was relying on).thanks!", 'closing. as #205 adds this feature.', 'yes. this is the text going through a number of systems that treat it differently. this is why appium does not do anything to it. you. as developer and/or tester. need to make sure that both ends are the same. if you switch languages/test runners. the results may be different (i just did a test with javascript and mocha and the straight text works fine. for instance).', 'my mocha tests using `--compilers` also fail b/c i cannot pass the proper ignore. as .babelrc is not honoured. pls. consider merging this in. thank you.', 'appreciate the pr. but it was correct before. master was previously passing and `before_script` would be the right hook. not `before_install`. travis runs `npm test` as its script if no script is specified. grunt is required there (`grunt mochatest`) but not before `npm install`.', 'bendrucker. usually we discuss things on this repo before making changes (not so much on the other ones). we also prefer to have peer review and get feedback. let\'s revert the changes. but not because of what i just mentioned. i think my issue with this is that you\'re making our default geared towards non-grunt users. given that assemble is still a grunt task. and given that _idiomatic grunt_ users should have grunt-cli installed globally. i only see disadvantages in doing this.  "idiomatic node.js" and "idiomatic mocha" and "idiomatic" grunt are different things. and installing grunt-cli globally is clearly the _idiomatic grunt_ way of doing things or it wouldn\'t be the default and recommended way of installing grunt-cli. recommended at the top of the page you linked to. thanks!']