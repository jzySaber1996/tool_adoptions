["fyi: the travis test is failing. but it's not failing under mocha on my machine. sorry about that.", "workspaces on mac os x. on my mac. i like to keep my ide in a workspace by itself so i can quickly switch to and from it with a four-finger swipe on the touchpad. when i start electron with the electron-mocha package. despite no new window being displayed. it always pulls me back to the default workspace. which gets old when i'm using a file watcher to auto-run my tests each time i make a change. is there a way to make electron (specifically. the instance started by electron-mocha) not do this?", "support for `--watch`. the mocha option `--watch` currently doesn't seem to do anything. could that be added? besides that this is really great!", 'for us it worked great so far. especially because it integrates very well with the mocha compiler options (as the process is kept alive). so if it could be added without too much effort would be appreciated. even though i understand mocha wants to move away from it :)', "i'm against it as well for the same reason inukshuk stated. it may be easy to add. but the maintenance burden may add a lot. ultimately your decision inukshuk.", 'personally i would prefer to see verbatim options passing for wrapper tools like these. which pass anything not relevant for wrapper to the tool itself. eg. `electron-mocha --report -- --watch --reporter x **/*.js`. which leaves the maintenance burden to `mocha` and the risk to the `consumer`. instead of making a decision on watch before `mocha` does. i can imagine that in practice this is a little bit more tricky as mocha is started from js. so you would still need to parse options. but anyway. my 2 cents ;-).', "mweststrate want to give it a try? i'm happy to merge a pr if just passing the parameter through to mocha works fine in both processes without any extra effort.", 'gonna give it a shot tomorrow', '"mocha requires electron to be installed globally. hello.i used mocha to test my electron app and  got an error: ""can not find \'electron\' in the $path and $electron_path is not set. please either set $electron_path or \'npm install electron\'"". my workspace contains electron and not the machine itself. **is there a way i could circumvent the installation of electron on my build machine?** as. electron will in turn require node and npm on the build machine.thanks!"', "obviously. you need to install electron on the machine where you want to run electron-mocha.you can install electron without installing node/npm first: if you do that you need to make sure it is either on your $path or you have to set $electron_path to the electron executable (if you install via npm you don't have to do that).", 'thanks for your response.i do have electron in my node_modules directory of the current project i am working on. i do not want to install electron globally on my machine. is there a work around?', '"correct. electron-prebuilt is listed in my package.json. i am using electron-mocha for testing the electron app. like i mentioned earlier when i run the test using ""electron-mocha --renderer /mytestfilepath"" command. it gives me an error: ""can not find \'electron\' in the $path and $electron_path is not set. please either set $electron_path or \'npm install electron\'"". and i do not want to install electron globally. so am wondering how to run the tests."', 'prevent electron-mocha stealing focus from other applications. fixes #82', 'at the risk of spinning off on a tangent. my preference is to stick with mocha. but use bdd-style assertions', 'basic setup for tests with mocha (mochify)', 'move all tests to mocha + jsdom. all tests are moved to mocha with jsdom. this way they all run in one environment. which gives us the benefit of a more realistic coverage and also less dependencies.', 'jmagnusson since you seem to know more than i do about browserify: all it requires is a correctly setup commonjs module. right? if so. the way i migrated your tests to use jsdom without browserify should still suffice. correct? if so. i would merge this. thanks for your input.', 'works just fine for me in browserify :+1:', 'okay. thanks. :+1:', "cakefile: use locally installed mocha for tests. we have `mocha` in `devdependencies` in `package.json` so let's use it for running tests ?? this will not require mocha installed with `-g` flag.", "andreypopp  i'll merge this in to make you happy (and for anyone else that immediately checks `cake` for a test task). but note that you could already do this by running `npm test` :)", "awesome. thankssent from my iphoneon jul 5. 2013. at 10:46 am. sam notificationsgithub.com wrote:> andreypopp i'll merge this in to make you happy (and for anyone else that immediately checks cake for a test task). but note that you could already do this by running npm test :)> > ??> reply to this email directly or view it on github.", "ariya mikesherov. i'd be happy to investigate a test-runner like mocha or something simple that would allow tests to be run in the browser (aka devtools).", "mikesherov i think a lot of the questions are with the test style. i think it'll be simpler to focus on just the environments. ariya i'll probable go with the smallest possible changeset. i like mochas reporter. so hopefully we can do something simple and evolve the test style gradually. people have lots of good ideas in this thread.one potential concern i have with using html2js is that the content won't be copied over exactly. i.e. will be escaped poorly. i'll share if anything comes up there", 'paulmillr there have been a number of prs lately that have broken tests - can we get travis ci set up for this repo. to avoid obvious breakages?', 'yeah we should', "as the repo owner. you've got to do the travis setup. i can handle travis.yml etc as necessary once that's done :-)", 'done', 'do we really need browser phantomjs tests? isn??t just node ok?', '"compass sprite imports break kss parsing. - compass sprite imports can be of the form `import ""folder/*.png""`.- this matches the regex for multi-line comments and the rest of the  file would then be ignored.- new behaviour is to `continue` if we aren\'t already in a multi-line  comment if the line starts with import.- ran mocha test suite and still passed.- manually verified as well."', 'raszi i am open to that change. i am currently learning typescript and also have a setup here for gulp (also using typescript here) and mocha test cases implemented in typescript and so on...', 'raszi kiss principle make lint an option for now. do not integrate it with mocha. we will sort it out later.', 'raszi builds on appveyor are still failing due to an error in the _mocha.cmd.we might want to report this to the guys over at mocha.', 'mochatests. tests now run on mocha. generally more robust. search-index can be explicitly closed (todo: update docs)', 'should def. be covered by tests. wanted to have a look at how to test in browsers. without messing too much with our nice mocha setup :-)', '"it sounds like a problem you should fix when you have it. this code can be reverted if needed or you could simply set it in `package.json\':``` json""scripts"": {  ""test"": ""node_env=test mocha""}```"', 'update package.json to include missing fields. adds `contributors`. `keywords`. `directories`. and moves `mocha` to `devdependencies`. also adds `package-lock.json` as recommended by npm.', "an update:- erinspice and myself put a bunch of work into porting tests to mocha.- blainsmith has been putting a ton of work into closing old issues.- i've started hassling people who've submitted pull request to rebase with master and add tests.how do folks feel about starting to work on getting some of the long standing open pull-requests closed? what should the process look like. perhaps two people should sign-off. after issues are rebased and tests have passed?", 'add catch handlers to import tests.. **only changes tests**refs #3473- some tests are checking to make sure errors by using a  catch handler on the test.  when assertions fail done()  is never called and results in a mocha timeout. which makes  it harder to see the cause of the failure.', "i haven't been able to reproduce the errors in `import_spec.js` and the gist file only shows the mocha timeouts. not the actual errors.  adding the missing `.catch` handlers to the tests that check for error conditions should make it easier to see the errors if/when this failure comes back.", 'move to mocha and improve the build system. - [x] update readme', 'convert tests to mocha. aearly megawac just a proof of concept where you can run mocha tests in node and in the browser.works right along side the nodeunit tests. so could be transitioned over one by one.', "it's beautiful.  :joy:", 'what is the requirement to support `index.html`?', 'anyway. i say we merge this. and then start improving on it. :+1:', 'yes it does appear karma can run nodeunit. unsure if it can mocha and nodeunit at the same time though', 'added karma-mocha-reporter so we get nice output when karma runs tests.', "> what is the requirement to support index.html?i don't know i think its nice to be able run with `index.html`. mainly for people without node/npm installed/windows that can't install some modules", '> yes it does appear karma can run nodeunit. unsure if it can mocha and nodeunit at the same time thoughwould require 2 karma config files', 'convert compose tests to mocha. aearly megawac', "sweet. charlierudolph any chance you could set up coverage via karma? it'd be nice to get 100% coverage. the main reason it's not achieved presently is from code specific to older environments.", "i don't see much benefit from running the tests in parallel. each test fakes async operations with settimeout with low to no delay. there are no long running async operations.", '1 of those is 174 ms spent making sure forever can avoid a stack overflow.', '> 1 of those is 174 ms spent making sure forever can avoid a stack overflow.yes. and the majority of that time is spent waiting for recursive `setimmediates` to resolve', 'par chance. have you looked into how `jest` goes about it aearly', 'at a quick glance. it looks like they use a multi-process test runner.', 'maybe its just me.  but all points above aside.  `jest` just felt incredibly slow.the `mocha` approach also felt way more composable.  which is great for clarity and overall understanding.', 'hey maybe adding `--compilers js:babel/register` to mocha execution and the package babel so unit tests can be written in es6/7', "i've now added a basic regression test. also using mocha (but without babel).if you want i can merge this pr myself. or if you prefer you can update it by pulling from master.", "looks pretty good!some thoughts:- i agree with this being off by default.  there are too many use cases where it won't work to have the state all be in-memory. such as the common scenario of multiple server instances.- maybe it would be simpler to just clean expired records every time we do an add. instead of setting timer events?- it looks like when using `validateinresponseto`. a response without any `inresponseto` field is still allowed.  this seems like it errors a little bit on the side of usability at the expense of paranoia. but i think i agree with it since we should be making it easy to configure the library to be 'as locked down as my identity provider supports'. but still work on any identity providers that don't.- `npm run-script jshint` will run the jshint checks for you locally. in order to make sure you will pass the travis build checks (i always forget to do this though. should probably figure out how to wire it in to mocha)- it looks like you are parsing out `notbefore`/`notonorafter` fields in the subjectconfirmation but then not doing anything with them.  perhaps we should always be checking these (i.e.. as part of issue #35)?", "thanks! everything's working now. i just need to convert the tests to mocha. i haven't used mocha before. but hopefully it'll be ready by the end of the day.", '"add support for overriding config.reportdir with an environment variable. the config.reportdir may need to be overridable. if the environment variable awesome_dir is defined. then use that. else default to ""mochawesome-reports"" for the report directory."', 'are you simply looking to change the name of the reports directory? or would you want to save the report somewhere outside of your test project? as you have the reportdir is still relative to the current working directory.mocha added support for reporteroptions a little while back. this could be another way to go instead of an environment variable.', 'what would be the use case for different/shared vendor files?', "using callback pattern for asynchronous code. as of right now. the only way to do asynchronous things in the intent handler is to return false and then call res.send(). although this works and is documented in the readme. it is different from the commonly used design patter of using a callback function as the last parameter.  one example would be mocha and the 'done' pattern. also since internally the request handler uses a promise it would be nice to be able to return a promise from the intent handler. this would also allow for another commonly used pattern of writing asynchronous code. thoughts?", "i agree. this is a bit annoying. but i put it in there originally for backwards compatibility. in the previous releases. handlers were required to be sync. allowing for the return of an explicit promise (as opposed to false) was in my plans but i never got to it. i also wanted to keep it very simple to implement the most basic use cases. which are sync handlers. in that case. the developer never needs to worry about creating or fulfilling promises or remembering to call a 'done' function. just write some simple code and it works. my thought was that only more advanced functionality will be async in handlers. and at that point the developer can learn the additional requirements for that scenario. i didn't want to use a callback. because promises are supposed to avoid that ugly syntax. and forcing a callback parameter in method signatures makes it harder to add parameters later if necessary. promises are the way to go. imo.", "agreed. i'm all for promises. in my use of the library i used promises as well.  supporting the return of a promise shouldn't be too hard no? it can be treated similar to the return false check. check if the return object is a promise and if so attach a then which either calls `res.send()` or accomplishes that same behavior some other way.in terms of the `done` pattern we could investigate how mocha does that and replicate the behavior. other wise the the `return false` pattern can be kept for non-promise based asynchronous code. that would be your decision in terms of how you want you library to present its interface. either way i'd be happy to help with the changes.", 'running single feature more than once. hi.if i tag a specific feature like this:``` gherkinbrowser=chrome.safarifeature: mocha asynchronous example  scenario: a bottle falls from the wall    given 100 green bottles are standing on the wall    when 1 green bottle accidentally falls    then there are 99 green bottles standing on the wall```i want to run the same feature over the two browsers in mocha in series and have the option to run it concurrently.what would be the best way to approach this? btw great work so far with yadda!thanks.regards.riaan', 'ok cool will try it out!thanks.regards.riaan', 'added a gitbook', "one more.i want tsd accept this syntax. `tsd install angular-mocks mocha expectations --resolve --save`.i think it's useful to be able to specify multiple module.", 'just a note: i think we also want to include mocha as a dev dependency.', '> travis is per-repo so making other repos with travis is fine.perfect. i think we can definitely use that unless there is a completing reason not too. i have yet to really look at circleci. so not aware of any amazing features it may have.i think it will be as soon as we get the mocha dev dependency. all tests pass!', "i'm going to update this to add `mocha`. harlantwood is there a particular reporter we should be using for circleci? currently my plan is to just have the test script be `node_modules/.bin/moch`. is this all we need?", "replaces karma + jasmine with mocha + jsdom. hey there.our current test suites was pretty outdated so i switched to a faster stack with mocha and jsdom.i would like some help though if possible. i'm struggling to add materialize.js to the global namespace. currently i'm getting errors with `$(...).material_select() is not a function`help ?", 'never mind. solved this :)', "creynders just a heads-up as you're working on this that i switched geppetto's test framework from qunit/pavlov to mocha/chai.  pavlov was not being maintained. and mocha seems to be getting a lot more traction in the community than qunit.  the switch was pretty easy. so i went ahead with it.", 'calvinmetcalf you mentioned calling mocha directly but i dont think thats a good idea as the direct interface. its changable (we would have liked to / we can have `grep=basics npm run test-node` work despite the implementation just changing. also we will likely need to wrap this in future (configurable couch_host)i reckon we should have a simple `./bin/run-mocha` that deals with grep for nownolanlawson command line arguments dont work in npm run commands. but env vars pass fine', '(#1364) - jshint bin/ and tests/. i found this little convenient script `fixmyjs` which did a lot of the fixes for me so i went ahead an added tests/ to jshint as well.i changed .jshintrc to use mocha bdd style predefs only now so any old style tests should fail early.it passes the tests for me locally. i only had to do one minor change (see a46a82ba429cd5610d9f54e2b26e417837ac237b).', "oh and i'll squash this if you like but i figured you might want to verify the commits first.", 'my god it looks glorious.', "that's awesome. gonna save me a lot of time smacking the space bar every time i touch a test file.", '(#1546) - remove mocha-ui', 'show visual diffs for array matching.. currently the message is like`array length<1> to deeply eql array length<1>` which is really hard to debug. we need to add a visual diff like mocha does.', 'dill should be able to run a single test or a subset of tests via a cli flag. we can follow mochas pattern an allow people to pass a -g flag or something like this.another nice option would be to do`dill --only feature_file.feature:33`', 'should.deeply.eql is the solution. this is not a problem in dill', 'remove redux. related issue: #89- removed redux. and rewrite with react setstate- replaced the jest with mocha (#83)', 'improve test coverage. using mocha. chai and sinon to write tests.', 'i noticed on the dev branch. testing was changed to using tape instead of mocha. and there are a lot of tests there. i bet there are quite a few things in general we can use from the dev branch.', "floogulinc. i'm generally not into changing the lib used just like that (mocha in that case). but i'm all in favor for tests. erming. would you mind pring your tests from `dev` to `master`? also. pring `dev` early rather than late would be great as other contributors could be prepared for that. but that's a different topic :-)jocelyndelalande. yes. closing this and moving the labels over there. sorry i got too excited and forgot to use search field and to unlock caps :d", 'feature/mocha opts', 'fixed in tap-mocha-reporter', "oh it looks like the test runner doesn't fail when there's an error. would you be opposed to consolidating the tests into a single mocha run?", 'move test runner out of make. - make does not come on windows (by default)- we were doing nothing special with the make file for the tests- putting the mocha command inside of npm test is super portable- attaching tools like node-debug while running the tests is now as simple as `node-debug npm test`---tldr: make is not the best tool for node projects.', 'tests pass :shipit:', 'all updated panya thanks for pointing out that issue.(on a sidenote)  `jscoverage` is actually not represented in the dependency tree at all.', '"hey panya  ok let us try this again. i think i have never seen jscoverage ""working"" so it is a bit hard for me to know what is correct."', 'kk .. thanks again for working with me on this panya', 'samccone np. and one last fix :) move `stylus_cov=1` on the one line with `npm run-script test-cov` (e.g. `stylus_cov=1 npm run-script test-cov`)', ':+1:', 'thanks!', ':dancers: :dancer:', 'yeah i mostly just used mocha when testing the vdom stuff :-)never even crossed my mind to add it to npm test though!what is up with these failures? c++ for travis??', "hmm weird. when i try this branch locally none of the fuzzy finder tests work in chrome or mocha. ah well the vdom ones don't work in chrome anyway", 'run nodemon and mocha -w at the same time. i like to run both mocha -w and nodemon at the same time; when i run nodemon before mocha -w; it works ok.if i run mocha -w before nodemon; nodemon throws an address in use error...', "i've decided to??keep this pull??request closed.the tests part needed rewriting from??the??scratch even??since the??mocha??testing landed.the instructions part would better be separated to??its??own pull??request.", '(#148) - increase mocha timeout for travis. #144 timed out 2 times on the new test-express-pouchdb test now; this should help.', 'this has been replaced with #274 i take it.', 'test: allow longer async tests. some tests fail because of the mocha 2sec timeout...', 'massive thanks to douglasduteil.', 'feat(controller): throw async errors in function-tree. there is no test for this. because it is actually impossible to write one. this fix handles async errors thrown in function tree. since `assert.throws` does not work. as the error is async. mocha just says some error was thrown and halts.but this has been tested manually.', "add generatetestapp utility for dynamic test app.js creation. plus some other tweaks:- increase mocha timeout to 5000 accommodate for windows issues.- remove rimraf in favor of fs-extra's rimraf functionality. (doh!)", 'thanks moll. those settings helped. travisci is now set up correctly!', 'the coverage is around 80% using mocha and chai. individual issues for missing tests are in the tracker. so closing this.', 'move unit tests to mocha. - move tests to use mocha/chai- make tests more cross-platform compatible  - remove makefile  - change `npm test` to use mocha (recursive)', 'martindale did you forget to `git add util/index.js`? tests are broken (you can run them using `mocha`). also. this will need a rebase', '"yep. definitely some failures around `userfromparams` which doesn\'t seem to exist anymore. i also have to use `mocha --compilers coffee:coffee-script/register` to run tests. otherwise it doesn\'t parse the coffeescript and blows up. i studied it a bit. and one option is `echo ""--compilers coffee:coffee-script/register"" > test/mocha.opts`. that at least allows us to run just `mocha` without having to add the flag.then again. i\'m not a node-head and am used to the graces of rspec. so i could be missing something big here.i\'ll try and figure out the deal with `channelmapping`."', 'alistairjcbrown  :+1:  thanks for the fix!i am gonna setup some mocha tests for this guy soon as well.', 'add mocha back to travis. i removed mocha from travis and forgot to put it back. a couple of tests broke. this fixes them. runs mocha in travis again and simplifies the travis config so the build is faster.', 'converts all tests to es2015 import/export and setup mocha. - move all buster tests from `test/` to `test-buster-old`- setup configuration needed for testing the `test/` folder with mocha- converts *all* buster tests from commonjs to es2015 modules', 'chore(test): switch 1 existing mocha test to use briancavalier/assert. affects: most/core', ':shipit:', 'test(disposable): convert sink & disposable tests. convert disposable tests to mocha + briancavalier/assertconvert sink tests to mocha + briancavalier/assertaffects: most/core', 'test(combinator) convert combinator tests. convert combinator tests to mocha + briancavalier/assertaffects: most/corecloses #37', "is there a benefit of having a seperated config task?. i was wondering why there is both a `mochatest` main task as well as a `mochatestconfig` options-task. most grunt plugins don't do this but have the options inside the tasks targets as per convention. does this provide a benefit that would negate managing the duplicate multi-task names?", "here is a demo. the second test will error-crash grunt but not in command line mocha:```var expect = require('chai').expect;describe('async tests'. function () {    it('first passes'. function (done) {        process.nexttick(function () {            expect(true).to.equal(true);            done();        });    });    it('second fails'. function (done) {        process.nexttick(function () {            expect(true).to.equal(false);            done();        });    });    it('third passes'. function (done) {        process.nexttick(function () {            expect(true).to.equal(true);            done();        });    });});```", 'print stack traces when tests fail. when a test fails grunt quits with a simple error message. when i run the same test with mocha from the command line it gives me a stack trace. is there a way to get stack traces from this plugin?thanks for your contributions to open source!randy', 'keep going when a test fails. when i run a suite of tests from the mocha command line it will continue with other tests and give a complete report of all failures at the end. grunt-mocha-test appears to stop at the first failure. is there a way to make it continue?thanks!randy', '"should have mentioned that the test failure i was seeing in this case was a ""code blew up"" situation rather than an assertion failure. a unit test was attempting to connect to a server that didn\'t exist."', 'when i started. vows was the shit. looks pretty outdated now.would it be too hard to switch to mocha and blanket? :p', "i'm not following what's the issue. the voiceactive vs jitter buffer contents shouldn't have a race condition looking at the code.can you describe a test case how i could reproduce this? i wrote some mocha tests (and integrated these with travis-ci) but none of them seemed to reproduce this.(also yay we got base for regression tests now \\o/)", 'include chai.js in /public/testem/. you already include buster. jasmine. mocha and qunit. and i think many people use chai along with mocha.let me know if i should send in a pull request :)', "i think that's a good idea. i would configure it probably likeframework: mocha+chai", 'this has been addressed in the latest releases', 'after testing around and write minimal examples. i find out that mocha have a problem. if there are arbitary `*.js` files (like my `importer.js`) lies in the `/test/` directory...after moving them away or run `mocha test/test_sass`. it terminates normally.', "why mocha returns non-zero exit status for success result. i'm running `node_modules/.bin/mocha -r html-cov > coverage.html` it returns 23", 'problem using mocha watch with mongoose. getting this error ```error parsing instrumented code: overwritemodelerror: cannot overwrite `user` model once compiled.```', 'watch mode busts the require cache. so if a module relies on that state it wont work well. nothing we can do there', 'related to learnboost/mongoose#1251', 'reading -f / --config as suggested above would break option bundling.  inconsistent interfaces are bad.', "yeah i kinda still agree with roman-neuhauser. config coming from all over the place is a little meh. not to mention the ugly hack we have to do to get it to work. i'd just do some shell inception replacing `mocha` if you want to inject some args in", 'probably just that specific reporter', "oh if it exits 23 then you have 23 failures. html-cov just doesn't output them currently", "azer that's because mocha explicitly exits when it's complete. this prevents the dev from closing all connections and shutting down servers. intervals etc. which is almost impossible in node land. so there's no getting rid of that", 'i have 43 passing and 2 pending tests. sometimes they can fail (beacuase of external dependencies). but if it happens they all fail.', "hi.this would be very helpful. especially when integrating `mocha` with a system that doesn't provide color support - for example a ci system with text-only logs (eg. team city)either support for `--no-color`. or a custom `--unified-diff` type flag would be greatly appreciated.", "i dont think it's mocha. mocha probably just uncovers this bug. mocha itself does not touch anything else. no globals etc", "i've found a few situations where i need this. `this.whitelistglobals` or `this.globals` would make sense imho.", '"the object.keys of firefox has bug. the object.keys of firefox has bug. you can try like this in firefox:```<script>    console.log(object.keys(window));    if(top == window){}    console.log(object.keys(window));</script>```results here:```[""window"". ""document"". ""installtrigger"". ""console"". ""process"". ""global"". ""mocha"". ""mocha"". ""sinon"". ""expect"". ""location"". ""mouseevents"". ""mspointerevents"". ""keyevents"". ""uievents"". ""bubbleevents"". ""touchevents"". ""gestureevents"". ""before"". ""after"". ""beforeeach"". ""aftereach"". ""context"". ""describe"". ""xcontext"". ""xdescribe"". ""specify"". ""it"". ""xspecify"". ""xit"". ""getinterface""][""window"". ""document"". ""installtrigger"". ""console"". ""process"". ""global"". ""mocha"". ""mocha"". ""sinon"". ""expect"". ""location"". ""mouseevents"". ""mspointerevents"". ""keyevents"". ""uievents"". ""bubbleevents"". ""touchevents"". ""gestureevents"". ""before"". ""after"". ""beforeeach"". ""aftereach"". ""context"". ""describe"". ""xcontext"". ""xdescribe"". ""specify"". ""it"". ""xspecify"". ""xit"". ""getinterface"". ""top""]```some variables can\'t be read by object.keys. until the variable been used in code."', "not the right place for this sort of thing sorry!  i would recommend using a higher level http thing like supertest or mikeal's request module though. node's is very low level for the average test use-case", "+1 it's not ideal that moving to use requirejs means leaving mocha behind.", 'cannot reproduce it anymore. strange', 'add mocha.1 manual page. this could be quite useful to include for use on unix systems. it was generated with help2man with some modifications and additions.', 'mocha parses mocha.opts from requested folders. this fixes #451', 'could we have bold/normal for expected/actual ?', 'bold and color are both implemented using ansi codes and have the same issues.', "i had the same issue. solved it using a wrapper check(). this is an alternative to the modification of done() and is only slightly more verbose (7 chars including a space) that the proposed solution.``` javascriptfunction check( done. f ) {  try {    f()    done()  } catch( e ) {    done( e )  }}test( 'foo'. function( done ) {  myasyncfn( function ( err. result ) {    check( done. function () {      assert.ok( true );      assert.equal( result. 'bar' );  // mocha now reports the assert failure    } );  } );} );```", "or like this?```test('foo'. function (done) {  myasyncfn(function (err. result) {      assert.ok(true);      assert.equal(result. 'bar');  // mocha now reports the assert failure  }.dotry(done));});```", "yaniswang i love your solution. it prevents the additional function() {} and is very easy to comment out. or remove. if mocha provides a fix that works across all use cases. i'm gonna implement this write away.", 'yes. should be fine.', "improve tests. a few commits:- migrate tests to `mocha` and `chai`: that way it's easier to share knowledge between this project and `node-elm-compiler`.- lint all files: there were a bunch of unused variables. and references to undefined variables. we can discuss the specific rules if needed.- commit `elm-package.json`: as rtfeldman recommended. we now use the `cwd` option to run the compiler inside the `test/fixtures` folder. so i've committed the corresponding `elm-package.json` instead of ignoring it.- test adding dependencies: we had added the functionality to watch dependencies. but there were no tests for it.i've marked one test (`emits errors`) as pending. as it isn't really testing anything at the moment. `node-elm-compiler` outputs errors to `console.error`. but ideally we would be able to tell it to use webpack's `emiterror` function. i'll create a pull request for `node-elm-compiler`. and once that's done i'll fix the pending test here.rtfeldman can you please review?", 'migrate testing from qunit to mocha', 'this is an amazing effort!', 'we should still build a static test page so we can link people to the suite. should just generate the static files in the travis build', "yep - i realized that after i pushed it up yesterday. what is here is 98% static. the jade files should be compiled to html. and the ua-parser can't be served dynamically like it is currently. otherwise. we would be golden. the ua parsing thing may be a little more tricky. short term i think i will just revert to paul's browserified parser currently used. long term see if we can get uaparser browsified proper. so that we can include as a node module and update throughout time.", 'yep sounds good', 'after the static changes are made. are you :+1:?', 'yep :+1:', 'yep looks good. so `grunt copy:gh-pages` will just be ran manually after any changes to master?also appveyor failed due to phantomjs timing out. is this a blocker for merging?', 'also seeing 4 tests failing on fx35', 'ryanseddon what tests are you seeing failed on what system? i am all green on ff35 on yosemite', 'ryanseddon able to reproduce. weird caching thing i guess. one issue is related to this. three are not. i was calling `!!bool` rather than `bool.valueof()`. which meant that `new boolean(false)` objects where coming back as true. still debugging appveyor.', 'magic. you two.', 'hi. since there are now mocha tests in the project (thanks jsdevel). can you please add a test for this fix?', "get mocha to display diffs for fixture mismatches. at the moment. it is difficult to tell why a fixture doesn't match a real request. especially for cases where the bodies are non-trivial. it would be great if we could make use of mocha's `showdiff` error flag to show these diffs in a way that it is easy to figure out the reason for mismatches.", 'zombie prevents the use of iced coffee script. the line at `lib/zombie/scripts.js#7` prevents the use of iced coffee script in tests.for example. if i am using mocha with the `--compilers coffee:iced-coffee-script` flag. if `coffee-script` is required anywhere in tests. it will use the vanilla coffee-script interpreter for all required files.there should be a line to specify which coffee-script library to use.', "thanks to node's module caching. the runner _does_ have singleton-like characteristics even if it doesn't meet the complete technical definition. try changing the `before()` hook in one of the testcases to open a transaction and log whether you're in one or not from the runner. then run `mocha test` -- you'll see that everything from that point onward is executed within the transaction even as the succeeding testcase modules re-`require` and reconnect massive.", 'binhums the reason this resulted in problems was that `--timeout 5000` was missing from the mocha call', '#57 maybe a much broader range of browser testing using [testling-ci]()? it support non-webkit based browser like ie and opera. a migration from jasmine to mocha will make this easier ;)', '"hi and thanks for the contribution! the existing browser tests were just something i wrote ""ages ago"" and do not form a representative test set. but if we get to hook them up to ci and especially with multiple browsers (particularly one problem child). they will be worth at least something. and we can add more.i\'ve got no experience on testling-ci. so forgive me my stupid question. can we plug into testling-ci just like into travis-ci and get to run on ie etc? why would mocha make testling-ci easier?on the other hand i\'d probably pick mocha if i were to start writing those tests right now. so if there\'s any great wins to be gained by migrating. we should do it. shouldn\'t be a big deal really. as most tests use the expectstreamevents/expectpropertyevents wrappers. and if we could run _all_ the tests in all browsers. we\'d get a really good coverage.regarding the pr per se. i wish you included instructions in the readme: how to run browser tests from the command line. then we\'ll merge.very nice to get some help with testing!"', "yes. you can simply hook up with testing-ci as long as the test runner produce [tap output]( since testling-ci already has a mocha harness. so we don't need to worry about that.like you said. running all the test in real browsers sounds like a good idea.", "d00rman actually. i've found a use-case for this. when running tests. `npm test | node_modules/.bin/bunyan` looses mocha's color-coding and stuff. while it's still handy to see logs in pretty format in case a test is failing. so. adding this `pretty-out` mode to test configs would be a nice thing. what do you think?", "i'm also leaning towards keeping things simple. the mocha use case seems to be pretty borderline.", 'that log is way too verbose but its likely not the same issue. you probably have something else specificing a different mocha-phantomjs range. what is your deps in your `package.json`?', 'add/mocha cloud. test-cloud integration', 'restore back an original style stack for anyone else that cares (e.g. mocha). this was breaking mocha because it expects err.stack to be original style.', 'how was this breaking mocha? it works on my end for raven-node. or do you mean. when included in another project. it messes with mocha?', "if there's uncaught errors. mocha parses the stack trace to pretty-print it. they assume the stack trace has not been changed by anyone else and that it's the original format.not sure why you're not seeing the issues here. my guess it's because either 1) you've never had any errors in your test cases (we should all be so lucky) or 2) because of the way you structure your test cases. you never saw it.you would only see it for errors that were caught by both raven's uncaughtexception handler and mocha's uncaughtexception handler - raven's turns it into a structured stack trace and mocha still expects it to be a string.", "azylman that makes perfect sense. :)do you mind moving that parser code into it's own file? compat.js or something to separate it out. along with a comment/link to where it came from.thanks!", 'done!', 'awesome. thanks!', "fix tests on windows. on windows. mocha attempts to invoke the directory `test/bin`. and you can't exec a js file even with a shebang. can someone ensure this works on other platforms as well?", 'thanks to travis for volunteering!', 'excellent!', 'remove sleep as a dev-dependency. remove platform dependent sleep and use mocha done sync function for bootstrapping tests.', 'sebv: you run the test with mocha. right? what was the command to run it again?', '`device=android mocha test/functional/android/webview-specs.js`', 'add grunt option to mocha tests', '"might make sense to set an environment variable that sets verbose logging``` jsvar loggingenabled = !!process.env.debug`````` json{  ""scripts"": {    ""debug"": ""debug=1 mocha""  }}```"', '"we should add an `npm run watch` target.``` json ""watch"": ""mocha -w -r test/mocha-babel.js test/*.spec.js""```we may need to go back to using the `--compilers` flag for watch. from the mocha docs:> transpilers may be used by mapping the file extensions (**for use with --watch**) and the module name > _(emphasis added)_not sure what the mechanism is there. if it ends up being too complicated we could just set an environment flag when watching and throw inside `mocha-babel.js` if generators are not supported natively (forcing people to run `watch` on node >= 4)"', 'any ideas on how to add code coverage to brunch as well?', 'not sure if there??s any _super simple_ coverage tool available (like mocha-phantomjs)', 'you mean like `brunch test` command? it??s super shitty because of jsdom. i??m in process of migration to new software. suggest you to use mocha-phantomjs until them', 'so far it just tells you which browsers it fails on and leaves it up to you to do manual testing using those browsers.  getting better reports out of it is high on the priorities list though.  the plan is to store the html state of the web page at the end of its operation so you can view the mocha report exactly as if you had run the tests yourself in that web-browser.', "can't we just use babel as mocha compiler and use all the nice es2016 stuff for tests too?", 'something has changed in events flow. i guess you have updated dependencies. and mocha-frameworks now fires events differently than before.for. example for testcase `should report failed before-all hook` now our before hook are not considered as failed. and test is still run however it should not. i tried to return rejected promise instead of throwing error. and then it works.i think there is an issue in wdio-mocha-framework or maybe mocha itself regarding synchronous exception handling.i will come later with more detailed bug report.', 'looks like this issue has been addressed by the mocha test suite. and is safe to close?', "as an added benefit. i've finally killed off `nodeunit`; all unit tests get to be mocha moving forward :)", 'your use case is the same as mine.but your test is not built correctly. you are summarizing the number of task run in on of the nodes. you should save information of the task into a db(or back at redis). and verify it from there.i found mocha a bit weird for those type of integration tests. and i use docker and py.test.', "almost there : e705a99411a81d93adb96a964eeed72a15d71a55jos there is one test broken (don't know why the result is not what i expect). and a bunch of question marks. could you finish this up?", 'i think we can close this issue now and remove the `mocha` branch?', "if you cleaned up behind me. i guess yes :)of course. there's still some work to do to. but i guess that can be done little by little.", 'yes. there is a lot to be done to improve the tests (for example reorganize the tests for the parser). will work on that every now and then.', "bcoe know of a way i can quickly debug this on my mac? unfortunately the cycles are really slow right now and i don't have access to a windows machine/image. i also don't know why that specific test is _actually_ failing as opposed to just timing out...```> mocha --require=babel-register  exports    ??? exports the correct interface  map store    ??? applies the inputsourcemap from the coverage object if available  mapped coverage    ??? allows a path constructor. has all properties    ??? allows building object incrementally. resolving dups  transformer    1) maps statement locations  4 passing (32ms)  1 failing  1) transformer maps statement locations:     typeerror: cannot read property 'statementmap' of undefined      at context.<anonymous> (test\\transformer.test.js:69:56)```"]