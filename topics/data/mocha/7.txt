['support reporteroptions. add code (from mocha) to correctly parse and pass reporteroptions', 'can you add the new options line to `readme.md` as well? thanks!', ":+1: i don't have this functionality in my script. but really like to see coffescript and mocha integration - right now it's easier for me to use command-line debugger with `coffee --nodejs debug` and `mocha debug`", 'sidorares debugging mocha tests is easy:``` sh$ node-debug _mocha```supporting coffee script is more difficult. definitely out of scope of this pull request. can you use `coffee -c -w` as a workaround for now?sam-github thanks for review. i have added a couple of commits and replied to the rest of the comments. anything else to improve?', 'lgtm. passing to chris for final looks. since i think he has more mocha knowledge than i do.', "output context not working when using rich responses. so i got my basic intents setup with the actions on google client library on aws lambda. my app does some basic order inquiry and allows followup questions on resulting orders through the use of contexts. all of this was working fine. i recently added several rich response elements to the app. namely the basic card and the list. and they are also working. however. my output contexts aren't being received anymore. (the responses received by the simulator and other devices lack the output context section)## steps taken* i've taken a look at the responses from the actions on google simulator and they did not receive output context* checked the logs from google cloud platform and they also have not received output contexts* however. when i send in a test query to my lambda expression or api gateway. i receive the full response. simple responses. rich responses. output context and all.* not surprisingly. my own mocha test cases also get the full contexts.## thoughtsso it seems clear to me that something on the dialogflow end is cutting out my output contexts since i know for sure that all components of my intents work separately. i am wondering if this is intended behavior. that webhook responses cant provide both output contexts and rich responses. if this is intended behavior. then i can probably work around it using the user storage. but if it is not. i'd appreciate any help i can get looking into the issue.", "i'm sorry hoklaisung. i'm not exactly sure what the issue you're reporting is. it sounds like maybe the responses in the web simulator don't have the context included. but that your webhook always gets it. in that case. what's the actual problem?", "i was able to fix a seperate problem that got the intents that used output contexts working again. my problem originally was that these intents that rely on output contexts were not working. and i didn't see any output contexts in actions on google's simulator's request or response logs. so i assumed that was where the problem lay. i will say. it does look like the simulator does not show that information regardless(the recieved output context nor the output context being sent to followup intents). and that would be useful to see.", 'thanks for surfacing this.', "i'll mess around with it a bit more to see if i can give a bit more info.. i've not done much testing yet as far as tdd/bdd goes (getting started with it using mocha/chai).", '> in theory it would be better from ember-cli\'s perspective if the tests were in the "normal" locationi know we had this discussion a few months back regarding the location of ember tests. and i was in favor of the path of least resistance then (i.e.. locating them under `/client`). and i have to say that after working with ember-cli that i\'m _really_ in favor of doing it now.i was able to get all the client tests running (and passing!) via `ember test` in like 20 minutes using ember-cli-mocha and ember-mocha.  i wasted that much time just trying to guess what to change in our current customized setup (and didn\'t get anything close to working).**edit**also. that weird problem i\'ve been having where i can\'t test the rendered output of a component is gone when running the tests under ember-cli.', 'we test `lib/` with nodeunit and mocha using babel to compile the es modules.  we have a simple smoke-test for the compiled output (cjs. umd. and es formats).', 'modularization is now on master. so no weird branch to consider now!', 'thanks for the heads up. i will submit a new pr soon.', 'cool jorgebay. by the way. it might make sense to implement this via `async.some` as you can accomplish the same result with `some`', 'yeah. but heads up. we also want to change the arguments for `some` and family to take an error in the callback. #118', 'async.race module. based on the discussion from #568 .contains mocha-based tests and readme update.same as #1018 but using modules.', "i'm still :100: on this. but master has changed significantly.  can you re-do the work?  it also would be nice if you added a `mocha_test` too.", "sure. i'll redo this and add a mocha test as well :+1:", 're-did this to support the new master and added a mocha test. i did some refactoring as well to the original code to make it clearer.', 'thelordhighexecutioner thanks but we will update all dependencies. not just mocha.', "cve-2017-16042 - fix growl vulnerability. updates the `mocha` and `gulp-mocha` packages.  watch the build to ensure nothing's been broken elsewhere.", 'question: tags & mocha runner. is it possible to use nightwatch tags with the mocha test runner? if so. how?', 'not at the moment.', 'gurpreetatwal would love to see a pr. you got my attention now.', "i'll start working on it in about a week. are you taking over the maintenance of this repo now? i'd love to help with that if you like", "thanks. i'm just helping out. i do have committer rights and such. i know matt-kruse is considering making an org and expanding the circle of friends. so looking forward!", "i agree. these are mine.  out of curiosity do these reproduce for you locally?  i do not get them running mocha on my box (obviously or i wouldn't have put this up for pr to begin with).  i'm trying to decide if this is a build script issue. or my box issue and then a general code issue.", 'reduce mocha timeout. we could even go with a shorter timeout since we use `travis/appveyor_retry`.', "kulicuu isn't that something mocha has documented?", "that's a fun one. made more difficult because i took a shortcut with the jasmine plugin. it's really just the mocha plugin since their apis are so similar.a solution for now would be to set the default jasmine timeout to something much larger.going forward what to you think about specifying the timeout with an annotation at scenario level?```step-timeout=5000scenario: etc etc```this timeout would be applied to all steps. not perfect. but better than a global and without doing something crazy with the individual steps.", "done. but i'd like to check if the test is working fine... the test package lacks of documentation. could you give me a quick hint how to execute the tests? something like `mocha rdf-test-graph/spec.js rdf-graph-array/index.js` i guess? i get a `typeerror: rdf.namednode is not a function`. so the rdf-graph-array implementation is not specified correctly...br.", "the goal was to 'nodify' all the overheads of testing so you could just run `mocha` and the tests will run.", 'validating should return an instance of error object. returning an instance of an error object in the validation callback makes it more aligned with the whole node ecosystem.for example. when running mocha tests like this:``` javascriptmodel.validate(function(err) {  if (err) return done(err);  done();});```the simple error object will trigger an error with mocha itself: `error: done() invoked with non-error: [object object]`', 'just fyi. if you do something like this instead``` javascriptmodel.validate(function (err) {  should.not.exist(err);  done();});```you get a more reasonable error message. i.e.```assertionerror: expected { object (validationerror) } to not exist```', "set-cookie  for session for unlogged users.. hi.i like so much sails and i decided to use it. and cooperate in its evolution. congratulations!.i am using sails.js with passport.js with passport-local strategy. and use supergagent with mocha and chai for tdd.i expect the session cookie must be setted only on ok login api call.but it is setted on ok and wrong login api call. and on other apicalls that need to satisfy isauthenticated police when i send wrong session cookies. on apicalls sent with good session cookies. the session cookie isn't setted. it's ok for me.tests:1 ) if in the api call to login i send good credentials. the session cookie is setted ok. and works for api calls that need isauthenticated police. it's good.2 ) if in the api call to login i send wrong credentials. the session cookie is setted ( i expect no set-cookie for the session in this situation. ). but this session is wrong. and don't work for api calls that need isauthenticated police. it's so so.3 ) if i send wrong session cookie in the api calls that need isautheticated police. the session cookie is setted ( i expect no set-cookie for the session in this situation. ). but don't work if i use it in other api call that needs isauthenticated police ( i must add this additional test because the unspected set-cookie for session in unathorized apicalls )4 ) if i send ok session cookie ( obtained with a ok login prior api call ). the session cookie isn' t set ( it's ok ). and it works ok in futures api calls that need isauthenticated police. it's good.", "the failure comes from windows/nodejs 10. where the installation of `request mocha chai` for the tests complains about a missing module - i cannot reproduce this on my local machine.everything else is looking good. i'm going to change the paths for the release now. so the following build will most likely fail.", "last time i looked at the mongoose source. i believe it exported a singleton. combined with node's caching of require calls and running `mocha -r test`. i'm sure there is a recipe for disaster in there somewhere.", 'closed due to - not an issue', 'code: ackmocha: 3194 passingindex.html: passes: 3166', 'mocha tests: 245 passingcode: ack', "running without webpack. i am having a problem with importing highcharts/highstock without webpack.i am importing highstock like this```import reacthighstock from 'react-highcharts/bundle/reacthighstock.src';```and then using it like this (amongst other ways)```reacthighstock.highcharts.setoptions(theme);```this works correctly when bundled with webpack.when ran without it. via mocha. everything still works except the shown import. which does now equal some webpack object.i really need to run my tests directly without first running through webpack. how can i do that?", 'try require maybe instead of import?', "oh. i forgot to mention it but i also tried require and it seems it worked exactly as 'import'. no difference whatsoever.it took me some time to figure it out. but it is definitely very weird. no other component in a big project exhibited such behavior.", "that's harder than i thought. as i'm using random to generate a disambiguation id for the message. causing the fact that we may have messages delivered not in order.the 'stop the world' thing you are seeing is mocha trying to calculate the diff between two 16kb buffers.skip that test. i'll work on it.", "nested grunt configuration blocks do not work. when i configure grunt-mocha-test using``` javascriptmochatest: {  foo: {    options: [ ... ].    src: [ ... ]  }}```everything works fine. especially. i am able to run it by calling:```$ grunt mochatest:foo```if i now start to nest things. it doesn't work any more. e.g.. if i use``` javascriptmochatest: {  foo: {    bar: {      options: [ ... ].      src: [ ... ]    }  }}```and try to run it using```$ grunt mochatest:foo:bar```it does not work. it basically looks as if there were no tests defined. if you run grunt in `--verbose` mode you see that it only looks for `mochatest.foo`. and does not dive down into recursion.is this by design. or is this a bug? either way: how could i accomplish this?", 'no problem. thanks for closing ;)', 'lavrton any comments?', 'hello. i am already trying to merge request. now i have some failed tests. so i need time to look what is going on.', 'thanks. now need to create an tutorial for site.', 'lavrton yep. i try to do it in the near future.', 'wait for release', 'thanks. this is a recent breakage. will try to sort it out asap.', 'please test the fix.', '> i also noticed a new typescript program is created for each file. this might not be the fastest way...we are investigating it in context of the #1591', "i'd really like to use both jest and testcafe and typescript. and the currently problem regarding duplicate types (aka `types/jest/index.d.ts (23. 13): subsequent variable declarations must have the same type.  variable 'test' must be of type 'testfn'. but here has type 'it'`) is a show stopper.i think it would be helpful if testcafe could use a local test directory tsconfig.json that would allow specifying types.", "hotell ah. ok. i'll try your `tsc && ...` trick tomorrow. i can imagine it will work. thanks.", 'mike-packetwerk  cheers mate!', 'unexpected rule type "font-face"; looking for module header. in our sass files we define the font-face using a bourbon mixin.`include font-face(...)`and then assign that font to a variable and use it where need be.using `grunt mochacli` i am getting the error in the title. i imagine true is trying to interpret `include font-face` font-face as a rule or a test? do you guys have a workaround for this?', "this is related to #74 (true doesn't like arbitrary output) and would require improvements to the parsing logic used for mocha. carljm do you want to weigh in on that? i'd love to see a pr for it. 'cause it's outside my skillset. :p the workaround right now is that you should only import sass files without output. and only use mixins inside a test.", 'visionmedia you said your interested in this change.if i were to do i would be tempted to have the intermediate format be tap. so you could do `mocha --tap | reporter-dot` with tap on stdout & tap on stdinobviously there would be a js api and `mocha --dot` needs to work.the only breaking change would be "how to write custom reporters" and maybe default mocha to tap.alternatively we can have a json like tap interface on stdout & stdin.if i work on this i\'ll probably not do all reporters at the same time but do them a bunch at the time and get the ball rolling earlier.', "the problem with tap is that it encodes a fraction of the information that mocha provides and that mocha-reporters consume.  it wouldn't be that much of a stretch to envision a really nice format for structured test logs as newline delimited json.  that would be much easier to extend with all the additional information.", "yeah that's the thing you'd have to augment tap. making it super ugly and not very useful to tap consumers that aren't familiar with the format. i'd love the change but i don't think we should use tap. it would just end up being json-infused tap haha", "you could support tap by essentially doing tap + json comments.  i don't think there would be any real point though as the reporters wouldn't be tap compatible", "tough call. i think the best action to take would be to allow these assertion libraries to hook into mocha. i'm not a fan of the done(callback) sort of thing", "plus tap isn't really all that popular. node is about it. most cis don't consume tap. so we're not losing much. they all have their own crazy-ass weird format. it's too bad we don't have test-anything-json because then you could augment it at will without making the test labels super ugly", 'if anyone has a suggestion for the new line delimited json format i"ll use that.otherwise i\'ll use whatever mocha does. i\'ll probably get the reporters to understand tap as well since that will make them work with tape for my use case', 'visionmedia now with |test-integration| which will not use mocha itself to verify the sanity of mocha (just for this bug at the moment)', "i like the walking up idea. what about conflicting files: e.g. `mocha test/acceptance test/compiler`. each dir with its own mocha.opts? perhaps this case's behavior can be undefined or first mocha.opts found.", 'imo this should be done with complete process isolation. you could use json-stream or the json reporter and exec(). plus then that keeps mocha lighter. win-win situation :d', 'bitwiseman yep.mcandre you need to call the mocha in bin.', 'a (minor) disadvantage of doing it with exec is that the path to the executable ends up being different depending on whether mocha is globally or locally installed. for example. i could put mocha as a dependency in package.json and always put the exec path as "./node_modules/.bin/mocha". which would end up ignoring globally-installed mocha if the user has one.the bigger disadvantage is that if i just pipe the output out to my host process. i lose the colors and formatting. if i use the json reporter for the child process as you suggest. it is not possible to re-use mocha\'s existing reporters on the output and i\'d have to format it myself.i don\'t see how this change makes mocha not light. and given the above disadvantages i would like you to reconsider.', "exception in a reporter silently crashes mocha. if a reporter raises an exception. mocha just stops without any error message. an example reporter demonstrating the problem (needs a failing test in the suite):```module.exports = crash;var spec = require('mocha/lib/reporters/spec');function crash(runner) {    spec.call(this. runner);    runner.on('fail'. function(test. err){        throw new error();    });}crash.prototype.__proto__ = spec.prototype;```", 'a custom reporter using async functionality is not possible. currently. a third-party reporter using asynchronous calls is not possible. see the following example (failing tests required):```module.exports = async;var spec = require(\'mocha/lib/reporters/spec\');function async(runner) {    spec.call(this. runner);    runner.on(\'fail\'. function(test. err){        settimeout(function() {            console.log("this should be executed. even though the hook is done");                    }. 2000);    });}async.prototype.__proto__ = spec.prototype;```why this is needed: every kind of asynchronous reporting. from fetching screenshots from selenium to posting stuff to a test results web service.', "apparently. this is something node doesn't do -- will investigate more.", "i've changed the wiki. so this issue is done.", "env var likes this typically just check for any value for them to be on. e.g. `mocha_colors=1 mocha test`. and afaik. the process global object shouldn't need to be guarded.", 'expose only the specified ui in the browser. i\'m happy to add tests for this. but it doesn\'t look like there are any tests for the browser build--is this the case?commit message:> when instantiated in the browser. mocha registers the "bdd-style"> interface. since an explicit call to the browser-specific `mocha.ui` is> required. the original registration is invalid. prevent that ui from> reacting to the `pre-require` event (and exposing its api).', 'i think it would be great to have the filename in the test object.', 'what about just for now use `xcrun simctl io booted screenshot testid.png` in the mochajs tests?', 'rotemmiz i just download the detox demo . and run it with the guide. but **command failed: node_modules/.bin/mocha e2e --opts e2e/mocha.opts --configuration ios.sim.release** always happened', 'switch back to mocha from ava.', "lgtm. it's a test-only change.", 'fix bi mocha test timeout', 'seems fine. what do you mean by > would like to also wrap unit tests around the getseleniumhub function in check-started.js but need a little help getting my understanding of mocha kickstarted...? programmatic usage seems to be fine. you did not break anything. wonder how we could add a unit test for this.', "unfortunately i don't personally use any of those technologies (angular. karma. ~~mocha~~ (doh)). i'll leave this open in case anybody else can help and i'll try to take a deeper look at some point but i'm not sure how much help i can be.", 'ok so when you say "you write browser tests in mocha" you would just in your mocha tests work with the dom (window. ect). not the phantomjs page object?  yea i\'m probably needing casper or zombie...', "i think it would be very helpful to have more of an intro on your mocha-phantomjs page.  for someone new to this. you just dive into getting it installed and really don't explain the use case for using it or use cases.  i get that it allows you to run mocha tests in the browser. ok fine but then what's the use case around that with tests.  i think it would be helpful to show examples of mocha tests.  the tests that are core to moch-phantomjs lib doesn't work with any dom elements. etc. because it's core code. so having some additional test examples using mocha running in the .html would be nice.  just a suggestion", 'there is another point i forgot to mention - when i run the tests in browser (using mocha.run) it works fine. the stats on top of the html update fine. the problem appears only with running tests using command line - mochaphantomjs.run()i can safely say that there is no infinite loop. because commenting out any random test seems to get it working.also. the ci system killing is not a problem because i get the same problem when running it from command line.i will be looking to possibly debug this. any pointers in that direction will be very helpful.thanks!', 'edit package.json nocha -> mocha. fixing a minor typo in the package.json description.', 'yes it is.', 'we now use `ember-cli-mocha`', 'not quite. i ended up resorting to switching to electron-mocha which breaks coverage reporting.', "hi. guys!it took long time as i needed to wait for next release of opera for android.now the 'opera' device can be tested with tests for 'chrome' device with the following command:device=android browser_name=opera mocha test/functional/android/chromejlipps would you find some time to review this? :)"]