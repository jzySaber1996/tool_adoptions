["this is more of an  issue than a webtorrent one.it looks like we can support seeding folders (both via drag-and-drop and the file upload input) in chrome. the non-standard filesystem api makes this possible. other browsers don't have any mechanism to do this. as far as i can tell.i'm working on a pr to make this work in chrome right now.", "ugh. had a less than thrilling conversation about that.turns out they don't want the canonical schema to include `$schema` because... they think it provides sub-standard validation support. and you should be required to use a tool that supports swagger and not json.", 'i think it makes sense to keep things as similar to the current state as possible. or adhering to the standard (in the case of `src()` and `currentsrc()`).as an aside. the `blob:` url is a consequence of hls. right?', "add option for abbreviated units. this library is so excellent! after seeing that moment.js did not support granular display. i was very glad to see this.i am wondering if it wouldn't be too difficult to implement abbreviated units of time. for example:- s for seconds- m for minutes- h for hours- d for days- w for weeks- ? for months- y for years(i'm sure there's a standard for this somewhere).the reason why i'm asking is because i'm using this library for sending push notifications and it would save a lot of space if abbreviations could be used.", "you can do this by creating a humanizer with a new language. like so:``` jsvar shortenglishhumanizer = humanizeduration.humanizer({  language: 'shorten'.  languages: {    shorten: {      y: function() { return 'y' }.      mo: function() { return 'mo' }.      w: function() { return 'w' }.      d: function() { return 'd' }.      h: function() { return 'h' }.      m: function() { return 'm' }.      s: function() { return 's' }.      ms: function() { return 'ms' }.    }  }})shortenglishhumanizer(15600000)  // '4 h. 20 m'```does that help?", 'no worries!', "raineratspirit it is. but you have to realize. it has all the bindings. async/fromevent/promise/callback stuff in addition to standard operators.  thus you don't need to bring in multiple files.  i'd like to know which operators you think aren't needed.", "feature - better logging for loaders/plugins - compiler.messages. **do you want to request a *feature* or report a *bug*?**feature.**what is the current behavior?**there's no standard for providing loader/plugin diagnostics so people have to use ad hoc solutions.**what is the expected behavior?**there should be a pipe like `compiler.warnings` for generic diagnostic messages. maybe call it `compiler.messages` or so. one option would be to refactor the current api behind a single call that would accept message type. priority. message for filtering.**if this is a feature request. what is motivation or use case for changing the behavior?**the current behavior is confusing.", "it won't convert old commit messages ^^. you will need to introduce the standard to all repo's", "bebraw that's all there is to the implementation. aside from the standard `if (module.hot) module.hot.accept()` addition to client code. there's no react-hot-loader configured. just `webpack-dev-server` for page refreshes and style changes.i'd post a minimum reproducible repo. but i'm logged into a company github account on my local machine and it'd be a pain to switch local accounts with ssh and gpg configured.", 'sokra that is quite inconsistent. you assume. based purly on imports. what the use might want to target. but that is just a guess. in our case. the import statement is used. but the code itself is es5. so it\'s all valid. just because of the import pattern webpack shouldn\'t fall back to parse the file with an older standard. because you can\'t know the target environment.i won\'t say it\'s webpacks job to tell the user. that his code is properbly wrong. but i\'d say it\'s inconsistent to tell the user "well. the exact same code goes through 2 different chains in webpack. and one tells you the problem in advance. the other doesn\'t" just based on some unrelated import stuff. that just feels not right.btw the main problem is babel. transpiling code from `{await: function() {}}` to `{await: function await() {}}`. in webpack it\'s just the lack of consistency.', "question: how to bring a player back to `live` moment after pause?. hello.i'm working on non-standard feature for hls live playback.when a user clicks `pause` - a player stops buffering new data.but i need to bring user back to `live` moment (obviously `live` in terms of player. not clock time) by offering special custom button.i tried to approach this with `player.bufferedend()` and simply call `player.currenttime(player.bufferedend());`.unfortunately this approach resets player to 00:00 by unknown reason. also it does not really work. because as i mentioned above. after pause a player stops buffering and i don't know `the latest available time point` anymore in order to seek into live as close as possible.so my questions:- why player resets to 00:00 if i try to seek it into `bufferedend` point?- how to get `the latest time point`. which is the closest to live. so i can bring user back upon request after pause?thank you.", 'thanks for moving the issue here.can you elaborate on what you mean by the player reseting to 00:00 when you seek to `bufferedend`? is the new currenttime returning 0 or just the display of the control bar?perhaps what you actually want to use is `seekable` rather than `bufferedend`. and get seek to the end of the last seekable range available.', 'did that work for you?', 'yes. `seekable` is exactly what i need', 'awesome!', 'yass. thanks for this. just make sure to fix the styling of your code with `standard --fix`', 'try with this```json{  "fields": {    "name": {      "type": "string".      "label": "parent name".      "required": false    }.    "children": {      "type": "reference".      "settings": {        "collection": "children".        "multiple": true      }.      "label": "child".      "required": false    }.    "children_second": {      "type": "reference".      "settings": {        "collection": "children".        "multiple": true      }.      "label": "second child".      "required": false    }  }.  "settings": {    "cache": true.    "cachettl": 300.    "authenticate": true.    "compose": true.    "callback": null.    "displayname": "parencollection".    "storerevisions": true.    "storesearch": true.    "defaultfilters": null.    "fieldlimiters": null.    "allowextension": true.    "standardeditpage": true.    "allowdelete": true.    "count": 20.    "sort": "publicationdate".    "sortorder": "asc"  }}```and this```json{  "fields": {    "name": {      "type": "string".      "label": "child name".      "required": false    }  }.  "settings": {    "cache": true.    "cachettl": 300.    "authenticate": true.    "compose": true.    "callback": null.    "displayname": "childcollection".    "storerevisions": true.    "storesearch": true.    "defaultfilters": null.    "fieldlimiters": null.    "allowextension": true.    "standardeditpage": true.    "allowdelete": true.    "count": 20.    "sort": "publicationdate".    "sortorder": "asc"  }}```inserting these into **child_collection**```json[{"name" : "child"}.{"name" : "childtwo"}]```then insert this into **parent_collection**```json{  "name": "parent".   "children": [`{first_child_id}`].   "children_second": [`{second_child_id}`]}```observe the composed values resolving.now change the **parent document** to```json{  "name": "parent".   "children": null.   "children_second": [`{second_child_id}`]}```try and get the same document and see that no fields are resolved. if that doesn\'t happen. try switching round which field has a `null` value', 'pnpm installation strategies. see #552. #557. #117decide how to allow/support non-standard ways to do installation with pnpm.', '> installation of packages without package.jsoni think this will be easy to do> i think this can be solved by allowing configuring custom resolvers we can move out the current resolvers to separate packages to see what api we can support for the custom ones.the other points are harder to solve and probably will require a redesign of pnpm. which might be ok. but lets start with the easy stuff', 'yep. custom resolvers api is the closest thing we can get. but cudf is the most fruitful feature. i think.> we can move out the current resolvers to separate packages to see what api we can support for the custom ones.not sure about moving them to separate packages. should they be maintained separately? how hard would it be?', 'yeah. i already have a working implementation of resolver for opam scope. now moving it out of there and adding a plugin interface.', '> do you think it is a good idea to rewrite the standard behavior? given that i want to extend installation in a non-standard ways -- yes. in my case i want to assume that some scope is a *built-in* -- `opam/*` which fetches tarballs from opam registry and generates `package.json` on the fly. i think the same technique can be used to bridge any other package registry.', "> i think resolvers and fetchers should be different plugins. because there are more types of resolvers that use the same fetchers. like many resolve to tarball urls.totally agree. do you think we should refactor code to remove custom `fetch` function from `resolveresult`? also there's `src/resolve/fetch` which should probably be moved out of `src/resolve` dir. maybe into `fetchresolution`. thoughts?", 'hmcfabulous davezen1. what is the expectation here?', 'given an put with file type : <input name="myfile" type="file">the :focus style is not applied the same way as it is with other buttons which means it doesn\'t get the highlight to indicate where you are on the page.', 'i believe it followed the standard bootstrap markup using input-group and input-group-btn.  will confirm and provide markup once i get a chance', 'checkbox/radio replacement. it would be nice if the theme provided a simple checkbox/radio replacement to beautify and normalize those controls.  i know material is the current standard. but for those not using material. it would be nice to have something else.  a simple css replacement like what was done for the toggle switch.', 'nested npm run scripts. what are the thoughts on adding support to nest scripts?rough idea:``` json{ "scripts": {  "test": {    "tdd": { "js": "mocha --watch" }.    "lint": { "js": "standard". "css": "postcss". "html": "htmllint frontend" }.    "audit": "node-license-validator --deep"  }.  "dev": "npm run test.tdd & http-server".  "start": "npm run audit && forever"} }```this would avoid the repetition in property names that i see in many [substack-esque. pseudo-nested packages]( am not yet familiar with the `npm run` implementation but happy to take a look and do a pr if this idea is not deemed too terrible. :stuck_out_tongue_winking_eye:', "i'm a heavy user of npm scripts. and i don't really see myself using this feature. i usually just combine things together the pseudo nested way and its worked just fine.also from an implementation standpoint. adding this kind of complexity seems pretty hard.", 'src: standard now depends on lazy-cache. a simple change to deal with a new module showing up and confusing git.', 'rubberstamp :sheep:.', 'ehsalazar :+1: thanks!', 'new quickstarts.. ace-n sorry for the size of the pr. it should be a quick review. i added a few new quickstarts and brought the other quickstarts up to standard.', "note: circleci is failing. seemingly because `google-cloud/dns` doesn't exist.jmdobry is this something you can fix? (i'll review/comment on the pr in the meantime - but that way we can run the unit tests before merging.)", 'fixed. i forgot to add `dns` to the `scripts/install` file.', 'lgtm.', 'simplify translate samples and bring up to standard.. same changes as the recent cloud storage pr.', "supporting tile map service with different lods. i'm trying to make a start on being able to use a tiled map service which has different levels of detail than the arcgis online schema and i'm running into issues that i can't quite fathom.i've a tiled map service which shares the same schema as an arcgis online service. except that the scales at the different lods are different.i've updated the resolutions in the tilemaplayer.js to reflect the resolutions of this map service and whilst it would seem to initially work as you zoom in and out the geography changes. by that i mean you could zoom into france and as the map scale changes you are suddenly looking at australia - or worse the app is requesting tiles that don't exist (getting 404's)......tile also seem to arranged incorrectly (so a tile for australia may be put next to a tile from somewhere else so the map looks like gibberish)is there something in particular that i'm missing? can anyone offer any pointers?thanks. tonybtw. the reason we're looking to do this is that we have a corporate standard for lods that all of our leaflet apps are being written to use and so loosing the ability to use agol services is not a significant issue at this stage.  eventually i'd like to see if we can produce an update to the tilemaplayer.js that dynamically builds the necessary resolutions from the service's metadata each time a new layer is created / added - would this generally be of use?", 'ideal - thanks for the pointer.will update the thread on progress next week.', 'if you are messing with gremlin-hadoop dependencies then i would not only verify against the integration tests. but also against standalone servers of both hadoop and sparkserver as that is where the `<dependency>`-exclusion balancing act makes itself apparent. if everything still works (no weird classnotfound. methodnotfound. etc. exceptions) on standard gremlin olap queries. then it should be good to merge.', "> if i'm moving swap to .permutations then maybe the function itself and swap-inverse should be private. and swap-perm should be renamed to swap. then you'd recover the original as inverse.to swap <$> _. it doesn't really make sense to me to expose half of a permutation separately in a file that exposes the whole permutation anyway.generally we like to expose as much of the code as possible. who knows what uses other people may find for the functions. it's particularly irritating to find something useful in the standard library only to find out that it's private or in a `where` block for no particular reason.> as another point of discussion. in my previous commit i renamed punchini[?]i to i[?]punchini. and swapped the inequality around accordingly in the result. i did this thinking i wrote that function in the first place. but i now realise it was already there. so this would be a breaking change.yes. can you change it back please. we try to minimise any unnecessary non-backwards compatibility.> i also think that now these things are in their own module. it might make sense to rename removein- to something like removemember. the logic is that it removes a member of a permutation. which seems more descriptive that the existing name. when using the module. you'd probably import it qualified as perm or similar. so it'd be used as perm.removemember.yup. that sounds fine.> additionally. would it make sense to include some type synonyms. and additional definitions to make the use of permutations easier (without having to go through `function.inverse`).yes. great additions!> we might consider adding a combinator that shows that permutation' is really the same as permutation. too.haven't thought about it much. but do you need `permutation'`?  if yes. then yes that would be a good lemma to have.", "add injectivity proofs for `_++_` in `data.vec.properties`. concatenation is an injective function iff the length of the vectors are the same.my last pull request was a very nice experience. so i'll try again! this time i could not find anything on the mailing list talking about this. so the only known need for these proofs are my own. still. i think it is quite a natural thing to have in the standard library.", "> my last pull request was a very nice experience. so i'll try again!glad to hear it! i'm not sure it's universally true.thanks. excellent addition.", 'so a couple of points:- the first isn\'t really an argument against. but when i first started using the standard library. i definitely remember reading something somewhere that the standard library deliberately chooses not to use "advanced" features such as irrelevance or instance arguments. however i can\'t remember what the reason given for this was. or where it was written...- secondly i\'m not how practical this is to carry out **consistently** across the library... let\'s take `data.nat.properties` for example. if we take your approach of making all the `isx` proofs instances then we run into the problem that there are lots of the same type of proofs (e.g. `+-issemigroup`. `*-issemigroup`. `[?]-issemigroup`. `[?]-issemigroup`). it\'s pointless marking all of these as instances. as instances have to be unique right? therefore i would guess we shouldn\'t mark duplicates as instances. but then it\'s confusing for users not being able to guess what\'s an instance and what\'s not... same with `decidable` proofs. a lot of modules have multiple `decidable` proofs.thoughts?', "yup... it was inconsistent when i started. and as i've been going along i've been adding things prefix-free. as that seemed to the standard in `list.all` and `list.any` which is where most of the existing proofs of this form were.i'm not particularly wedded to either form. we should be consistent though. from a time perspective. i think going prefix-free would be easier?", "`make test` on a mac (line ending issues). right now. `make test` on a pristine clone of the standard library fails on `cabal exec -- generateeverything` with the error    generateeverything: src/algebra.agda is malformedi've tracked it down to all .agda files having `\\r\\n` line endings.  so of course the check in `generateeverything.hs` that (`all (== '-')` fails.what is the recommended fix?  i know about git's `autocrlf` settings. the point of asking here is that. once this gets settled. i'll add something to `hacking.md` for mac users. so that they don't run into this.[i'm trying to work on some of the low-hanging-fruit in my spare time]", 'i think the correct answer is: before doing a clone. make sure to have first executed    git config --global core.autocrlf inputi may have had this set to `true` by mistake before. which would have caused my problems.', 'pr #315 should fix this.', 'on 29/02/2016 20:19. max kunowski wrote:> per the docs:> > ```> the $http legacy promise methods success and error have been> deprecated. use the standard then method instead. if> $httpprovider.uselegacypromiseextensions is set to false then these> methods will throw $http/legacy error.> ```ok. thank you !', 'it was a decision we made about two years ago. to be fully compliant. meaning the use of data-\\* prefix instead of element names. etc.  i had a discussion with a team. and we decided to allow non standard (custom) elements. so as of now it is no longer an issue  for us.  after saying that. since most directives (or should i say features) in angular do provide an ability to be used as attributes instead of elements. it seems only logical to me. that slots will allow this too.', 'installing the npm module `types/webrtc` instead. solves the problem. not sure why a standard typings file produces the errors.', 'improve type definition for isomorphic-fetch. according to  the `requestinit` has more options.i really like typescript and `isomorphic-fetch` with which i can use `fetch` in both browser and node. but i need to disallow redirection in my project with `redirect` request option which does not exist in current definitions. so i supplement all the allowed options for `requestinit` according standard.', '_isomorphic-fetch/isomorphic-fetch.d.ts_to author (toddlucas). could you review this pr?:+1: or :-1:?checklist- [x] pass the travis ci test?', '> it might work maybe?unfortunately. no. because i have a lot of code. which written like this:``` tsdeclare function doloaddata(): promise<data>```as you can see. function returns `promise<t>`. which is standard `promsie`. not bluebird one. declaring `var promise: bluebird<any>` i will overload standard promise constructor. not interface.', 'why are there `isomorphic-fetch` and `whatwg-fetch` types together with duplicated interfaces? i think the former should just add a reference to the latter.', "we should probably consider unifying these saschanaz. or basing these on whatwg-fetch. if we can do so in a what that doesn't impact people using these definitions. then i'd be up for it.", 'i think `isomorphic-fetch` should just reference the definitions of `whatwg-fetch` too.  if possible.', "toddlucas if you will fix all the enums and incorporate the new fields. just ignore this pull request. and thanks. it'll be helpful for my project.", 'strictly typed component decorator support. i have updated the types with an additional generic type so that standard connect calls are not aware of the void call.i have also updated the tests to be more strict as the exisiting test did not attempt to render the component under test.addresses #9951', '_react-redux/react-redux.d.ts_to authors (tkqubo seansfkelley). could you review this pr?:+1: or :-1:?checklist- [ ] pass the travis ci test?', 'sheetalkamat hey. i was just about to review this. why did you merge without approval?', 'jprogrammer please create a new pr addressing the feedback.', "sheetalkamat can we just revert this and start again since it was so recent? also. why did you merge it without approval?edit: without approval and open for not even 24 hours. more accurately. i didn't even realize a pr was opened!", 'mhegazy  asked me to review the prs and merge them. this one looked ok to me hence merged.', 'mhegazy i applaud the desire to merge these faster. but we should still try to get community reviews from typings owners (within reason)!sheetalkamat thank you for reverting. i appreciate it!', 'jprogrammer sorry about the roller-coaster. want to try this again?']