['hello could you open this pr against master and add some tests? thanks!', 'rtmp live timed metadata. populate rtmp oncuepoint data to a in-band-metadata text track using webvtt standard.', "i open this pr against master branch as forbesjo requested.i couldn't figure out any test though. since it's a feature for live streams i don't know how i might test it. i could make flash tech to trigger a fake 'cuepoint' event and ensure the metadata texttrack is created. but. in my opinion. i would be testing eventemitter and texttrack rather than cuepoints feature its self. right? any suggestions?", 'thanks hartman this is what i have done as a temporary fix but it would be nice to have audio to be wrapped inside audio tag as a proper standard :-)', 'so would the api look something like this?``` jshumanizeduration(12345. {  language: "zh".  locale: "cn"})```and is there a standard for these pairs? i couldn\'t find `zh_cn` or `zh_tw` in any official iso standard.', 'sidenote:first just scratch all the stuff about repository awareness etc.  these were targeted more at the thought of docpad being something like the eclipse help system where you can drop in documentation plugins. and have them be integrated into the help system via extension points.  along the same lines i was thinking that people would have separate docpad documentation projects. that could later be assembled into a larger "delivery unit" by simply dropping them into the repository.  i think this may be interesting down the line. but for starters just using a standard docpad project as the "repository" is simple and possibly the best solution.end sidenoteyes - correct i\'d like to be able to change directory and file names and file location without causing url breakages.  off the top of my head link needs to:find all the documents that need to be generatedcheck for url "collisions"check for link id "collisions"create an in memory dictionary of the meta data provided link id to document urlresolve all link tags during document generationif i understand right 593 needs to:on each change to a file\'s url- save the new url to a dictionary that also contains the old url- redirect the consumers of the old url to the new urli think 593 would benefit from link or geturl type functionality.  if i understand correct the "slow moving article author" would:- update the title >> triggers update to url.  so if your original example goes from:  `[my referenced doc](/posts/post1)`  to   link(uniqueid)  then  [my referenced doc << gets automatically updated along with the corresponding new url on regeneration).', "i think this should probably be implemented on a per plugin and as needed basis. it is too early yet to be able to justify the value of such overhead in the core for a use case that we have experienced once. however. let's keep this here as a reminder for the future in case other plugins eventually require this.one way to implement this into plugins in a standardised way would be to allow us to specify our own collections for use in plugins. rather than plugins specifying their own or creating their own. i believe this is what the latest pull request for the dateurls plugin does. it will be cool to see how this technique developers over time.will close for now. but happy to keep the discussion going. and re-open once we have enough value to implement.", "standardize help text everywhere. - always say 'kafka'. not 'kafka' or 'heroku kafka' or 'the kafka cluster'- all commands that take a cluster argument have that in the examples- all commands that take a cluster argument just include  heroku_kafka_brown_url instead of using the haiku names.", 'closing this issue in-favor of the newly created #1086', 'feature/editorconfig. ## type of change- [x] code style update (formatting. local variables)## description of changeadded an editorconfig file to help developers stick to your coding standards.', 'happy to help but very confused on your question still! can you rephrase/be more concise? if you want adx reporting. this is available via your adx account (which can also be accessed via your dfp account per recent dfp updates)the metrics you are referencing are inherently flawed as far as accuracy and you should use the newer metric "ad server downloaded impressions" --- the others count impressions based on less accurate standards (they look at the <head> code and not the body or div tag of the dfp tag)', 'do you want me to give it a try with standardjs mkendall07 ?', "if it happens over standard http. can you put the segment with this issue somewhere public so we can see what's happening?", "that's outside standard hls behavior so it's outside of our focus today. sorry we can't be of more help.", "the hardcoded min-macosx flag causing this problem is i think actually coming from the gyp files in node core. node-gyp could override them but not sure if that is the best place. i'm not fully on mavericks yet myself so i've not yet taken the time to test all possible solutions. anyway. closing this issue since this has nothing specific to do with node-mapnik. the problem is generic: you cannot run multiple c++ libraries together unless they are built against the same standard library.", '+1 to this. orb triggers failures which are causing tests to fall with code outside of my control. until orb fix the errors i would like to mute them to get a more accurate view of the test results.', 'hi. jgravois i find the reason. my map coordinate system is to use 4326 standard. leafset does not support this projection system. i put the map service change. thank you.', 'is there anything blocking this pull request ?', 'added accesstoken.decode and removed a few lines for js standard.. proposed fix for #19', "don't merge this yet. the same needs to be done for idtoken.js", "i understand this works with gui's but what about github's desktop client?. i have installed node with the standard installer.i have husky working in the cli but github desktop client acts like there are no scripts to run.", 'maybe it is the problem with github desktop?', "hi.what's the output of `which node`? you're on os x?", "good to hear. i'm surprised protractor's `.then` doesn't support what i thought was the promise standard of being able to accept two arguments (first is onfulfill. second is onreject)", '> concerned that you might expect this to bring up the memberinfo section on the right-hand panel for yourself you already get the memberinfo section when clicking on yourself in the member list and having an action here display something in the member list just feels weird...> another related question is whether clicking on an avatar in general in the timeline should perform autocomplete on their name. or open up the memberinfo sectioni like the autocomplete... maybe not the most intuitive but as you say it\'s great for non ascii names. let\'s try this and see if people yell. i was about to say "we\'re going to have search in the member list anyway" but that won\'t be helpful with non-ascii. can we have double-click = autocomplete and single click = memberinfo? <- not entirely convinced myself given i\'m not sure double-click is standard on web. but want to hear your thoughts', "lgalfaso.consistency modelthis is not as simplistic as you have pointed out. enormous numbers of directives bypass this by entirely bypassing scope as soon as they require any level of 'bare metal' performance.  anything that executes outside the digest cycle currently has very limited options for restoring consistency after the completion of any given bare metal action. many take the easy route out and trigger something that calls $rootscope.$apply() in order to attempt to ensure consistency.  core angular code does this regularly.  90% of the time i see a digest cycle called it is absolutely unnecessary.  asynci do not understand why async operations done by a directive can't be done when the directive is suspended.  i suppose you might have a concurrency issue where an async operation could have the wrong data on the scope at the time of processing on a suspended scope. but you shouldn't be accessing scope from a non digest locked operation anyway. and if you are operating on a scope that is suspended the scope interacting portion of your async operation will not run until the scope is resumed.transcludeextending another directivecreating a directive on a standard html elementim starting to think that a directive is necessarily the proper place to be doing this kind of control.  it seems like something that should be reserved for use by your application controllers.  pattern wise it really isn't up to a directive to do this kind of application control.  in every situation where i have had the need for this it really should be handled by a controller.ownership of scopei'd argue that it is fairly clear that scope is a shared resource. except under certain circumstances.  isolate scopes are definitely owned by the directive that makes them.   when there is a controller for a section the scope should be under that controller's scope of control.i think i can agree that there are issues with this methodology being a public api and open to everyone to just extend.  however. the core capability absolutely must exist for angular to really be able to handle larger applications.  just today i implemented this in my application. the application needs to be able to quickly switch up a multiple annotations on a large grid of data.  using it in my controllers only. i was quickly able to decrease the points of ui thread lockout caused by digesting a much to large active digest tree.  i rewrote ng-show and ng-hide to make large numbers of hidden annotations not get digested. but still allowed the core html to be rendered in the initial render state so that displaying annotations could be done very efficiently even with the enormous dataset.tldr;  in the large majority of cases a modern browser can handle way more rendered dom than can be actively controlled by angular in a single cohesive scope tree.  isolating application layers such that global digests are controlled to only work on active code is essential.", "`json.parse(json.stringify(source))` is often a good method if you know it can handle your data (no circles. no functions. no objects other then string/number/plain-object/null). a standard `copy` method could never make those assumptions though. and detecting such a thing would require traversing the entire source object which would kill any performance gain. generally utility methods like this don't belong in angular anyway...", "refactor($compile): use indexof/splice instead of manually manipulating jquery object. jquery/jqlite objects have a `splice` method on them. and `indexof.call` works on them. so those 2 methods can be used instead of the double loop.the standard case (replacing one element) just does an assignment while other cases use `splice`. this could be changed to always use splice if wanted. but i thought the 99% case was worth it.(this is a subset of #9365 that can be done on it's own)", 'this looks interesting. would it be possible to get some numbers to know if there are any performance implications?', 'jbedard can you also try the performance on the case where multiple elements would need to be replaced?what remains at #9365. i think it would be best if they can be split into more prs (it you think that only one pr would be needed. then just rebase it once this lands)', "multiple elements seems to have the same result as removing the `if (removecount === 1)` case for single elements - it is a couple percent slower and a fraction of a percent more memory (because splice returns a new array. i assume).if you profile only the code changed on its own (`indexof`+`splice` vs the loop) the loop one is 1-2x faster. but compared to the document fragment and data calls in this method this is insignificant.think it's worth removing that loop?", "the other option would be adding `fn &&` in front of the `fn` wrapper methods. then `success`/`error` are more like the standard promise methods when it comes to null/undefined (i don't know what that behavior is. but i think consistency is good...).", "support `<content>` in templates in place of `ng-transclude`. `<content>` is the web-standards-compliant element that ng2 will be using for this sort of thing. it's really meant to be used in the context of shadow dom but i imagine it wouldn't be so bad to adopt it in ng1 to help ease migration. especially since it is the direct conceptual successor to ng-transclude.one difference. iirc. is that `<content>` element would be _replaced_ by transcluded content. rather than becoming the parent of the transcluded content. as ng-transclude does today.", "robertknight i think the right approach is to list all of the properties so that we get the benefits of typescript and the new freshness checking for catching typos. otherwise we're throwing that benefit away. it's been on my list of things to-do for a while now though so... it's just a matter of someone getting the bandwidth to actually make the change.", "enforce this package only installing on non-windows os's. when using this module in a cross-platform desktop application through a tool such as electron the `npm install` will fail (on windows) on this module due to the cpp imports not existing.  the standard way to fix this is to install this module as an `optionaldependency` and for this module to internally declare which os's it works on.  as far as i can tell that is everything other than windows"]