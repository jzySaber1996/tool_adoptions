['looks great!thanks for adding standard', 'my initial thought was that i think this probably falls inline more with a plugin or custom implementation. not core. this feels pretty similar to the argument for showing the big play button and poster at the end of a video...not a bad idea at all. just not "core".that being said. this feels pretty standard these days for "custom" players. the only real argument against is that this isn\'t the video element\'s behavior. but it feels like we\'ve strayed pretty far from that policy of late.', 'any update on this pr? any eta?', 'yep. for testing i just copied the standard oceans track and called it chapters.', 'i\'d certainly want to get as much stuff from the docpad core into modules as as possible. though for plugins that\'s a different choice. let me explain.things like routing (and perhaps even growl notifications in hindsight) are part of a core experience of docpad. our default routing can be turned off by the setting `extendserver: false` in your docpad configuration file. allowing you to over-ride it with what you want. the same applied to growl notifications. by setting `growl: false`. you get no notifications.the issue with putting these things into plugins. is that then it means they are optional. and optional things means that they have to be installed. things like routing. are definitely part of the core experience one would expect. whereas things like eco rendering. contact forms. aren\'t part of a core experience.we should probably formally define what the core experience is somewhere. but that would be digressing for now. for now. let\'s define it as "sensible defaults".in terms of the architecture though. modularisation of the core makes a lot of sense. tightly integrated. well tested. swappable. re-usable. units of code. versus our big monolithic current structure. is clearly beneficial. however. a pluginfied core. not so much.i\'ve been thinking about ways to abstract different parts. and it could work like this;- core experience  - docpad cli module  - docpad core module    - docpad generate module    - docpad plugin module    - docpad file model & collection module    - docpad block model & collection module  - docpad watching plugin  - docpad growl plugin- extra experience  - renderer plugins  - helper plugins  - importer plugins  - interface pluginsthis way. applications just wanting to use docpad as a rendering engine (a common. but incredibly underplayed use case of docpad) could be accomplished by a `npm install --save docpad-core`. whereas. the standard docpad experience we have now. would be the same `npm install docpad`i thought about having global plugins solve some of this problem. but that is another issue. with it\'s own precautions.-', "if i understand correctly. #404 is saying the opposite of what i'm suggesting here.  the primary goal behind the suggestion here is to have a standardized home for all resources that come with skeletons. so that we always know where to look for resources. effectively making the skeleton identical as far as resource taxonomy goes.from 50k feet the node community seems to be going through all the stages the java community went through before maven.  we have grunt. cake. etc. that give each project designer a great deal of flexibility in terms of project layout and processing.  so each time we checkout a new project. we have to come up to speed on the tasks for processing the project and the layout of various resources.  maven standardized this for java. and now almost all java projects use maven.", "you mean having a function which returns a random number?  you could tackle the eagerness by using the rx.observable.defer method. or if it's a standard function. you could use the rx.observable.start method.", 'it would be nice if there were standards support for a "weak reexport" that would say "i\'m exporting this thing. but it doesn\'t need to be evaluated unless someone uses it".  this would not change the semantics of loading except that a loader _could_ use it as a signal to do more aggressive optimization.  nothing prevents loaders from evolving this on their own as a comment or annotation or external configuration. but if there\'s value to it then having it in the language instead of being loader-specific would be better for everyone.obviously. if a naive weak reexport targets a module with default side-effects then you might see inconsistent behavior. but i don\'t think that risk means that a well-structured library like `lodash-es` shouldn\'t have the option to declare its own safety.  in systemjs where all this happens in the browser. it\'s rather important that reexports _not_ be eagerly fetched. but there\'s no way to avoid that today without drilling down to the individual files (`import {x} from \'lodash-es/x\'`) which is quite a bit less pleasant syntactically than plucking names out of a single lodash import (`import {x.y.z} from \'lodash-es\'`).  webpack doesn\'t have to be as concerned with when/if the dependency gets fetched (not that reading hundreds of lodash modules that it doesn\'t need to is a great thing). but it still would benefit from a clear signal that it can exclude something from the bundle.', "some of the adapters support defining the referring url. documented or not. e.g. both rubicon and appnexus support passing bid.params.referrer from the adunit.perhaps you could check the code for the adapters you're using and try passing the referrer param for any that support it?instead of having to pass this in for each bidder. we should be able to add referrer to the standard bidrequest. it would still be up to the adapter to use it.", "mjacobsonny - is this the way we want users to be able to override the standard ad server keys in the long run? e.g. to set hb_deal_rubicon. we'd instruct the publisher to turn off enablesendallbids() and turn on alwaysusebid for all bidders. this seems counter-intuitive. questioning the meaning of enablesendallbids.", "this is the way that the `optimist` package parses command line args. i agree that it's somewhat annoying. but i think it's better to go with the standard than implementing our own custom logic here. we can fix the cli help message though.", 'thanks for the input a-s-o. you definitely make a valid point!what we could do though is make the implementation flexible. but lock the api for the official packages. so if you create your own custom package you can use whatever mutation methods you want. but. the official cerebral-packages share a common mutation api to make it easy to change model-layer.so pstoica could build a custom immutable-js controller for the specific project or share on github. with mutation methods fitted for immutable-js. but the official `cerebral-immutable-js` project has the standard "set. push. pop" etc. methods.', "hey all! definitely wanted the first feature as soon as i copied over the react helpers. i did need a custom `shouldcomponentupdate` using `immutable.is` since i decided to pass the immutable objects to components without serializing with `tojs` (useful when dealing with larger objects as props). so there could be some cross-cutting concerns between the model and view layers.for the second. it could be good to have a consistent mutation api for the official packages and leave room for custom hooks. on the other hand. if we already select and receive data differently in the view layer. maybe it's okay for hooks to vary officially.immutable has its own gotchas that you should probably be familiar with if you choose it. for example:- `immutable.map().set('a'. {b: 1})` will have the plain. mutable object in 'a'. `merge` will actually turn it into an `immutable.map`. if example cerebral code uses set with a plain object. i'm not sure if that code should be portable or if the adapter needs to call `fromjs` or something.- you might also have different function names and signatures between immutable methods and cerebral methods. for example. immutable's `setin` already takes a path. which might make cerebral's `set` confusing.- immutable has some mutators that take functions. these won't be serializable. but there should be a way to warn if you try to use them. however. `updatein` is the most generic way to update a path. and there could be a way to make that serializable. e.g. `state.updatein(['a'. 'b']. 'pop')` would call `.pop()` on the item at that path.would typechecking be the proper solution for mutation hooks. just like in `output`? i'm starting to think cerebral should focus on making mutations serializable/deterministic without worrying about standardizing them. if we do that. the cerebral controller could easily passthrough the defined hooks to the immutable methods.i can try to come up with more immutable vs standard cerebral differences later if that would help more.", 'publish fields as standard. ### expected behaviorbake in publish state. date. expires date. publisher as standard.', "lovell i tried a couple of methods of finding a pointer that is constant between the constructor and `handleokcallback`. and didn't find something that worked. in 4c7f339 i made the mistake of not passing the buffer by reference. but fixing this. it appears that the iterator object is actually declared on the stack (from the memory address) and differs between range loops while the buffer element is on the heap. i wasn't aware that that's how c++11 range loops worked -- so i learned something. in e2cda35. i expected going to a standard for loop over the length of the `std::vector`. and getting the address of the vector element to work. however. it seems the referenced object has been copied at some point. i realize there is some ambiguity about which vector is being referenced in the constructor due to the class member `savebuffers` having the same name as the constructor argument. but i changed the names and the pointers still differed. i'm not sure if this has to do with some obscure fact of a `local<object>` object. or copying `std::vector`s but i couldn't find a solution and i'm out of time for tonight. the most recent commit goes back to the `buffercontainer` method of filling the vector.i think this is going a little off topic from the boolean operator. can we merge this one. and then work out a better system for passing in buffers to be saved in a later commit?i would like to be able to reference this mechanism. whatever it is. in a future commit to pass buffers in for other operators that take images.", 'summarise coverage of each standard. it would be helpful to summarise what is covered wrt each standard. without having to dig into the cucumber scenarios. just something more terse.', "othiym23 i think having style standards would definitely be good and beneficial for future contributors and scaling. i look forward to seeing a discussion on such (i don't feel i should be apart of it since i have not contributed in any means to this project other than through usage of npm).  thank you for your input on this pr though.", "i'd argue this should be opened again. at least for how the behaviour differs from windows for example. for what's essentially the same semantic (running global installs as admin).i have been using npm on windows for years. when i got my first macbook pro and installed node then tried to install my first global package i just halted.it should be standardized whether global packages are meant to be global within the same user profile (which makes most sense especially in hosted environments). or machine wide. this shouldn't change per os (or at least be documented in npm install or npm folders documentation sections).thanks a lot for reading this feedback. and for making npm in the first place.", 'the rooms order is not refreshed after sending some messages. steps to reproduce1 - in the rooms list ("standard" ones)room aroom broom c2- i send a message to the room bthe message is properly received but the rooms order is not updatedthe room b should move up because the latest message is more recent3- i refresh the webpagethe rooms order is still invalid.', 'dup #816', 'this is on my list of things to push to the standard library soon.', "so off the top of my head i'm struggling to come up with a generalised `zipwith-n` function which is both sufficiently general and easy to reason about. do you have such an implementation?i don't think `zip3with` is common or useful enough to warrant being included in the standard library.", "altering the `algebra` hierarchy so that it is parametrised by the carrier set would be an enormous change to how the standard library currently works and would cause _significant_ backwards compatibility issues with a large percentage of users.given this and the fact that the standard library does not currently make use of instance arguments. i'm afraid this looks unlikely to ever happen.", 'a "safe" subsection of the library. as discussed in #122 it is currently impossible to typecheck a development relying on the standard library with the --safe option because it does not isolate properly its uses of unsafe features.the agreed upon course of action is that there will be a safe.* subset of modules. the current module names will be kept the same and will re-export exactly what they currently contain. ensuring full backwards compatibility whilst making it possible to only rely on the subset that is recognised as being safe by agda.', "thank you for your pull request. sorry it's taken so long to get back to you! `data.fin.properties.subset` has undergone a several changes. including the style of how the proofs are scoped. given the small size and the age of your pull request. i thought it easier to simply add in your proofs manually rather than make you go to the effort of going back and rewriting them in the new style.the lemma will be available in the next release of the standard library.", '> there are notions like "monomorhism". "monomial" . mono-this. mono-that ...but none of them are relevant to `data.nat`. i think that context is key. for example there are at least 5 different `_+_` defined in the standard library but you know which one you are referring to in each instance by the module imports. similarly no one is going to think that something of the form `+-mono-<` refers to monomorphisms or monomials.ultimately i think the justification for this change is not strong enough to warrant the backwards compatibility issues it would introduce.> generally. uniformity is desirable. i agree. we will try and rename `_+-mono_` and `_*-mono_` to `+-mono-<=` and `*-mono-<=` respectively.', 'on wed. 2017-06-28 at 02:51 -0700. matthewdaggitt wrote:>         there are notions like "monomorhism". "monomial" . mono-this.>         mono-that ...>         > > but none of them are relevant to data.nat. i feel that context is key.> for example there are at least 5 different _+_ defined in the standard> library but you know which one they refer to by the module imports.> similarly no one is going to think that something of the form +-mono-<> refers to monomorphisms or monomials.formally. this is so.> ultimately i think the justification for this change is not strong> enough to warrant the backwards compatibility issues it would> introduce.agda  is not currently stable enough to care much for backwardscompatibility. the developers admit this.but it needs to care -- a bit.so that i do not care much about this "monot" affair. ------sergei>         generally. uniformity is desirable.>         > > i agree. we will try and rename _+-mono_ and _*-mono_ to +-mono-<= and> *-mono-<= respectively.> > --> you are receiving this because you authored the thread.> reply to this email directly. view it on github. or mute the thread.> >', "i quite like the idea of `.examples` modules but in this particular case these examples are demonstrating features of the agda language. not features of the standard library (the first one doesn't even have a dependency on the library!). surely they should live elsewhere?", 'right. general examples could go into readme. specific ones into a `.examples` module.examples for the agda language should not go into the standard library. but in the agda documentation.  however. maybe cartazio meant that the standard library does not make use of copatterns and maybe should.', '> but for the purpose of having a xorring where xor is defined more efficiently than by> ```xor x y = (x [?] y) [?] ! (x [?] y)```> this pattern is useful.that\'s interesting! when you say "efficiently" what do you mean? efficient in terms of definition size? in type checking time? in execution time?> i see this as part of the tension between minimal interfaces for economy of reasoning. and maximal interfaces (including what otherwise would be derived definitions as axioms) for the purpose of enabling specialised implementations.i agree that there is definitely a trade-off and loc saving is certainly not desirable if it comes at the cost of usability. the library should be aiming to make users\' lives as easy as possible!> in the places where i use this. i have a module containing default definitions. so that the new agda feature allowing record fields to be supplied by modules makes it cheap to to produce instances for the large interface by supplying definitions only for the small interface. and i consider the cost of additional fold/unfold proof steps inside the module with those additional parameters as tolerable. even though it is certainly a nuisance at the time of converting a derived definition into parameters.hypothetically. if i\'m understanding you correctly. the `replace-addition` and `replace-multiplication` lemmas would be an alternative way of obtaining the same effect? all proofs would be done with the "standard" definition and then the "efficient" definition could be substituted in afterwards? (although i feel that if they don\'t have the same effect. the lemmas would still be useful to have anyway).i guess i\'m just bemused about the fact that in the current configuration. despite the library having a whole module of proofs about it. the user doesn\'t actually have access to an definition of `xor`!', '> when you say "efficiently" what do you mean? efficient in terms of definition size? in type checking time? in execution time?for my main use cases. this is efficient in terms of execution time.however. i can also imagine uses where reasoning about specialised instances becomes easier due to the non-derived definitions which are then directly visible (via definitional equality).> > in the places where i use this. i have a module containing default definitions. so that the new agda feature allowing record fields to be supplied by modules makes it cheap to to produce instances for the large interface by supplying definitions only for the small interface. and i consider the cost of additional fold/unfold proof steps inside the module with those additional parameters as tolerable. even though it is certainly a nuisance at the time of converting a derived definition into parameters.>> hypothetically. if i\'m understanding you correctly. the `replace-addition` and `replace-multiplication` lemmas would be an alternative way of obtaining the same effect? all proofs would be done with the "standard" definition and then the "efficient" definition could be substituted in afterwards? (although i feel that if they don\'t have the same effect. the lemmas would still be useful to have anyway).in a fresh agda-stdlib clone.````sh $ grep replace- $(find . -name "*.agda")````only finds `replace-equality`. so i can only guess for `replace-addition` and `replace-multiplication`.i think that in general. these `replace-` lemmas would have the same effect for reasoning where definitional equality does not matter.however. where proofs are not irrelevant. which includes for typechecking. the adaptions-throughout in these `replace-` lemmas will have costs that matter. and where it\'s replacing operations. some derived operations might become or remain unexpectedly more expensive at run-time.but i agree that these `replace-` lemmas would still be useful to have anyway.> i guess i\'m just bemused about the fact that in the current configuration. despite the library having a whole module of proofs about it. the user doesn\'t actually have access to an definition of `xor`!(before the record-fields-from-modules feature. i would probably have been hesitant to actually write something as simple as the `xor-default` definition you presumably have in mind. and from that perspective can understand its absence.)', 'i think `all (\\x - f x [?] g x) xs` is preferable to `f [?] g on xs` in the standard library.  (agda will expand it anyway in your proofs.)', "thank you for your contribution! it would be great if you could submit some of it as a pull request rather than a zip file. if you need any pointers on creating a pull request please feel free to ask!as for the ordering `x <= y = x < y [?] x [?] y`. defining `_<=_` in terms of `_<_` is backwards with respect to the rest of the standard library. i'm reluctant to accept it as i feel its likely to cause confusions for users and further problems down the line. as i mentioned before. i'd be much more comfortable rewriting the implementation of `_<_` in terms of a new native `_<=_` relation.", "> as for the ordering x <= y = x < y [?] x [?] y. defining _<=_ in terms of _<_ is backwards with respect > to the rest of the standard library. i'm reluctant to accept it as i feel its likely to cause confusions >for users  and further problems down the line. as i mentioned before. i'd be much more > comfortable rewriting the implementation of _<_ in terms of a new native _<=_ relation.currently. bin has the following implementation to ``_<_ ``:``data _<_ (b1 b2 : bin) :  set where````    less : (lt : (nat._<_ on toN) b1 b2) - b1 < b2``do you suggest to replace this with``data _<=__ (b1 b2 : bin) :  set where````    leq : (le : (nat._<=__ on toN) b1 b2) - b1 <=_b2``and then. to define ``_<_`` as``   x < y =    x <= y   x   x [?] y``             ?", 'i cancel my complaint about restriction on .agda files for pull requests for standard library.so far. i propose the two main backwards compatible items for bin.their implementation needs several (backwards compatible) additions to nat.properties. nat.divmod.  i am going to do all this (may be. later. in august or such). and then. we shall see. i do not care much of adding things to standard library. i just use them as non-standard.but earlier i happened to make proposals there. and now suddenly have a response -- after  3-4 years. so that i do not know. may be it has sense to try to reach a result.', "i agree that it would be far better to prefix all the ordering properties in the ordering records with the  order and leave the equality properties with the standard name. for example `ispartialorder` would export publicly `refl : reflexive _[?]_` and `<=-refl : reflexive _<=_`. however changing this now would break almost every piece of agda code in existence. so unfortunately. unless someone important disagrees. i don't think this is going to get changed.", "> the denotation suc>0 is clear to everyone who knows what is suc. and (s<=s z<=n) is something special. the reader would take an effort to understand the meaning.okay i agree that it's more meaningful semantically. please could you rename it to `0<1+n` to follow the conventions in the `data.nat.properties`.> [?]-reasoning has a very strange parenthesis. it looks like ( but is not (. i think that my denotation is easier to operate with.i think that is a problem with the font that you are using. in most fonts it comes out as an angled bracket which is clearly distinguishable from a curved bracket.> 1* is much easier to read/understand in proofs than *-left-identityi think that's a matter of opinion. to me it looks like an identity function `1*_`! i'm afraid that. for better or worse. the proof already exists in the standard library and so you'll need to use the standard name.", ">>    1* is much easier to read/understand in proofs than *-left-identity>> i think that's a matter of opinion. to me it looks like an identity function 1*_! it is only in the proof part. so it cannot be undedrstood as ``id``.  >> i'm afraid that. for better or worse. the proof already exists in the standard library and so you'll >>  need to use the standard name.if you insist. then all right.do i and wolfram convince you about   ``+cong1``  and such?the matter is that  ``cong (_+ y)``often occurs like this:   ``cong (_+ ((x1 * x2 + a) * 2))``.and i write this as  ``+cong1``  by using hidden argument(though in abut half of the cases agda forces me to set the hidden argument).proofs are difficult to read when large expressions are copied from lhs to the part of  [?]< ... > .", "i would expect `+cong2` to be `cong2 _+_` given that `cong2` is already an existing notion in the standard library. using exponent `l` and `r` seems more appropriate here.also. if `(x1 * x2 + a) * 2` can be inferred then `cong (_+ ((x1 * x2 + a) * 2))` can simply be written `cong (_+ _)`. if it can't then the shorthand won't bring anything to the table.", "> i would expect +cong2 to be cong2 _+_ given that cong2 is already an existing notion in the > standard library. using exponent l and r seems more appropriate here.> also. if (x1 * x2 + a) * 2 can be inferred then cong (_+ ((x1 * x2 + a) * 2)) can simply be written > cong (_+ _). if it can't then the shorthand won't bring anything to the table.this all looks reasonable.concerning the ``cong``  denotations. i am going to try to follow matthew's solution. and then. to see.", "rwwangner90 knownasilya i tested it in ie. and it works as expected with this fix  and the event isn't getting double triggered in ie as well. the current implementation wasn't working in safari due to the order of the events that where being triggered. in chrome. the click event on the div triggers first. then the on change event. but on safari. the onchange event triggers first then the click event. this order causes the toggle to just toggle back and forth in safari.are you saying that you don't want to use the label anymore. and keep the clock event? i can work on that if that's the case.and not doing anything special. just a standard toggle with the action defined is enough. {{x-toggle value=model.ispublic ontoggle=(action (mut model.ispublic))}}this is in the simplify branch.", 'gtb104 can you confirm what sort of examples you tested? did you do the standard case. with no labels. the contextual component case with 1 label. the contextual component case with 2 labels. and the standard case with both 1 and 2 labels as well?i believe these hacks were just for certain cases on certain browsers.', "i'm fine with the checkin. just not sure about the trade off. so if that's standard. ok with me!"]